<!DOCTYPE html>
<html>
<head>
<title>array_index</title>
</head>
<body>
<div class="mw-parser-output">
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style>
<p class="mw-empty-elt">
</p>
<style data-mw-deduplicate="TemplateStyles:r1097763485">.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}</style><table class="box-More_citations_needed plainlinks metadata ambox ambox-content ambox-Refimprove" role="presentation"><tbody><tr><td class="mbox-image"></td><td class="mbox-text"></td></tr></tbody></table>
<p>In computer science, an <b>array</b> is a data structure consisting of a collection of <i>elements</i> (values or variables), each identified by at least one <i>array index</i> or <i>key</i>. An array is stored such that the position of each element can be computed from its index tuple by a mathematical formula.<sup class="reference" id="cite_ref-1">[1]</sup><sup class="reference" id="cite_ref-andres_2-0">[2]</sup><sup class="reference" id="cite_ref-garcia_3-0">[3]</sup> The simplest type of data structure is a linear array, also called one-dimensional array.
</p><p>For example, an array of ten 32-bit (4-byte) integer variables, with indices 0 through 9, may be stored as ten words at memory addresses 2000, 2004, 2008, ..., 2036, (in hexadecimal: <code>0x7D0</code>, <code>0x7D4</code>, <code>0x7D8</code>, ..., <code>0x7F4</code>) so that the element with index <i>i</i> has the address 2000 + (<i>i</i> × 4).<sup class="reference" id="cite_ref-4">[4]</sup>
The memory address of the first element of an array is called first address, foundation address, or base address.
</p><p>Because the mathematical concept of a matrix can be represented as a two-dimensional grid, two-dimensional arrays are also sometimes called "matrices". In some cases the term "vector" is used in computing to refer to an array, although tuples rather than vectors are the more mathematically correct equivalent. Tables are often implemented in the form of arrays, especially lookup tables; the word "table" is sometimes used as a synonym of array.
</p><p>Arrays are among the oldest and most important data structures, and are used by almost every program. They are also used to implement many other data structures, such as lists and strings. They effectively exploit the addressing logic of computers. In most modern computers and many external storage devices, the memory is a one-dimensional array of words, whose indices are their addresses. Processors, especially vector processors, are often optimized for array operations.
</p><p>Arrays are useful mostly because the element indices can be computed at run time. Among other things, this feature allows a single iterative statement to process arbitrarily many elements of an array. For that reason, the elements of an array data structure are required to have the same size and should use the same data representation. The set of valid index tuples and the addresses of the elements (and hence the element addressing formula) are usually,<sup class="reference" id="cite_ref-garcia_3-1">[3]</sup><sup class="reference" id="cite_ref-veldhuizen_5-0">[5]</sup> but not always,<sup class="reference" id="cite_ref-andres_2-1">[2]</sup> fixed while the array is in use.
</p><p>The term "array" may also refer to an array data type, a kind of data type provided by most high-level programming languages that consists of a collection of values or variables that can be selected by one or more indices computed at run-time. Array types are often implemented by array structures; however, in some languages they may be implemented by hash tables, linked lists, search trees, or other data structures.
</p><p>The term is also used, especially in the description of algorithms, to mean associative array or "abstract array", a theoretical computer science model (an abstract data type or ADT) intended to capture the essential properties of arrays.
</p>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"></span></h2>
<p>The first digital computers used machine-language programming to set up and access array structures for data tables, vector and matrix computations, and for many other purposes. John von Neumann wrote the first array-sorting program (merge sort) in 1945, during the building of the first stored-program computer.<sup class="reference" id="cite_ref-6">[6]</sup><sup>p. 159</sup> Array indexing was originally done by self-modifying code, and later using index registers and indirect addressing. Some mainframes designed in the 1960s, such as the Burroughs B5000 and its successors, used memory segmentation to perform index-bounds checking in hardware.<sup class="reference" id="cite_ref-7">[7]</sup>
</p><p>Assembly languages generally have no special support for arrays, other than what the machine itself provides. The earliest high-level programming languages, including FORTRAN (1957), Lisp (1958), COBOL (1960), and ALGOL 60 (1960), had support for multi-dimensional arrays, and so has C (1972). In C++ (1983), class templates exist for multi-dimensional arrays whose dimension is fixed at runtime<sup class="reference" id="cite_ref-garcia_3-2">[3]</sup><sup class="reference" id="cite_ref-veldhuizen_5-1">[5]</sup> as well as for runtime-flexible arrays.<sup class="reference" id="cite_ref-andres_2-2">[2]</sup>
</p>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"></span></h2>
<p>Arrays are used to implement mathematical vectors and matrices, as well as other kinds of rectangular tables. Many databases, small and large, consist of (or include) one-dimensional arrays whose elements are records.
</p><p>Arrays are used to implement other data structures, such as lists, heaps, hash tables, deques, queues, stacks, strings, and VLists. Array-based implementations of other data structures are frequently simple and space-efficient (implicit data structures), requiring little space overhead, but may have poor space complexity, particularly when modified, compared to tree-based data structures (compare a sorted array to a search tree).
</p><p>One or more large arrays are sometimes used to emulate in-program dynamic memory allocation, particularly memory pool allocation. Historically, this has sometimes been the only way to allocate "dynamic memory" portably.
</p><p>Arrays can be used to determine partial or complete control flow in programs, as a compact alternative to (otherwise repetitive) multiple <code>IF</code> statements. They are known in this context as control tables and are used in conjunction with a purpose built interpreter whose control flow is altered according to values contained in the array. The array may contain subroutine pointers (or relative subroutine numbers that can be acted upon by SWITCH statements) that direct the path of the execution.
</p>
<h2><span class="mw-headline" id="Element_identifier_and_addressing_formulas">Element identifier and addressing formulas</span><span class="mw-editsection"></span></h2>
<p>When data objects are stored in an array, individual objects are selected by an index that is usually a non-negative scalar integer. Indexes are also called subscripts. An index <i>maps</i> the array value to a stored object.
</p><p>There are three ways in which the elements of an array can be indexed:
</p>
<dl><dt>0 (<i>zero-based indexing</i>)</dt>
<dd>The first element of the array is indexed by subscript of 0.<sup class="reference" id="cite_ref-8">[8]</sup></dd>
<dt>1 (<i>one-based indexing</i>)</dt>
<dd>The first element of the array is indexed by subscript of 1.</dd>
<dt>n (<i>n-based indexing</i>)</dt>
<dd>The base index of an array can be freely chosen. Usually programming languages allowing <i>n-based indexing</i> also allow negative index values and other scalar data types like enumerations, or characters may be used as an array index.</dd></dl>
<p>Using zero based indexing is the design choice of many influential programming languages, including C, Java and Lisp. This leads to simpler implementation where the subscript refers to an offset from the starting position of an array, so the first element has an offset of zero.
</p><p>Arrays can have multiple dimensions, thus it is not uncommon to access an array using multiple indices. For example, a two-dimensional array <code>A</code> with three rows and four columns might provide access to the element at the 2nd row and 4th column by the expression <code>A[1][3]</code> in the case of a zero-based indexing system. Thus two indices are used for a two-dimensional array, three for a three-dimensional array, and <i>n</i> for an <i>n</i>-dimensional array.
</p><p>The number of indices needed to specify an element is called the dimension, dimensionality, or rank of the array.
</p><p>In standard arrays, each index is restricted to a certain range of consecutive integers (or consecutive values of some enumerated type), and the address of an element is computed by a "linear" formula on the indices.
</p>
<h3><span class="mw-headline" id="One-dimensional_arrays">One-dimensional arrays</span><span class="mw-editsection"></span></h3>
<p>A one-dimensional array (or single dimension array) is a type of linear array. Accessing its elements involves a single subscript which can either represent a row or column index.
</p><p>As an example consider the C declaration <code>int anArrayName[10];</code> which declares a one-dimensional array of ten integers. Here, the array can store ten elements of type <code>int</code> . This array has indices starting from zero through nine. For example, the expressions <code>anArrayName[0]</code> and <code>anArrayName[9]</code> are the first and last elements respectively.
</p><p>For a vector with linear addressing, the element with index <i>i</i> is located at the address <span class="nowrap"><i>B</i> + <i>c</i> × <i>i</i></span>, where <i>B</i> is a fixed <i>base address</i> and <i>c</i> a fixed constant, sometimes called the <i>address increment</i> or <i>stride</i>.
</p><p>If the valid element indices begin at 0, the constant <i>B</i> is simply the address of the first element of the array. For this reason, the C programming language specifies that array indices always begin at 0; and many programmers will call that element "zeroth" rather than "first".
</p><p>However, one can choose the index of the first element by an appropriate choice of the base address <i>B</i>. For example, if the array has five elements, indexed 1 through 5, and the base address <i>B</i> is replaced by <span class="nowrap"><i>B</i> + 30<i>c</i></span>, then the indices of those same elements will be 31 to 35. If the numbering does not start at 0, the constant <i>B</i> may not be the address of any element.
</p>
<h3><span class="mw-headline" id="Multidimensional_arrays">Multidimensional arrays</span><span class="mw-editsection"></span></h3>
<p>For a multidimensional array, the element with indices <i>i</i>,<i>j</i> would have address <i>B</i> + <i>c</i> · <i>i</i> + <i>d</i> · <i>j</i>, where the coefficients <i>c</i> and <i>d</i> are the <i>row</i> and <i>column address increments</i>, respectively.
</p><p>More generally, in a <i>k</i>-dimensional array, the address of an element with indices <i>i</i><sub>1</sub>, <i>i</i><sub>2</sub>, ..., <i>i</i><sub><i>k</i></sub> is
</p>
<dl><dd><i>B</i> + <i>c</i><sub>1</sub> · <i>i</i><sub>1</sub> + <i>c</i><sub>2</sub> · <i>i</i><sub>2</sub> + … + <i>c</i><sub><i>k</i></sub> · <i>i</i><sub><i>k</i></sub>.</dd></dl>
<p>For example: int a[2][3];
</p><p>This means that array a has 2 rows and 3 columns, and the array is of integer type. Here we can store 6 elements they will be stored linearly but starting from first row linear then continuing with second row. The above array will be stored as a<sub>11</sub>, a<sub>12</sub>, a<sub>13</sub>, a<sub>21</sub>, a<sub>22</sub>, a<sub>23</sub>.
</p><p>This formula requires only <i>k</i> multiplications and <i>k</i> additions, for any array that can fit in memory. Moreover, if any coefficient is a fixed power of 2, the multiplication can be replaced by bit shifting.
</p><p>The coefficients <i>c</i><sub><i>k</i></sub> must be chosen so that every valid index tuple maps to the address of a distinct element.
</p><p>If the minimum legal value for every index is 0, then <i>B</i> is the address of the element whose indices are all zero. As in the one-dimensional case, the element indices may be changed by changing the base address <i>B</i>. Thus, if a two-dimensional array has rows and columns indexed from 1 to 10 and 1 to 20, respectively, then replacing <i>B</i> by <span class="nowrap"><i>B</i> + <i>c</i><sub>1</sub> − 3<i>c</i><sub>2</sub></span> will cause them to be renumbered from 0 through 9 and 4 through 23, respectively. Taking advantage of this feature, some languages (like FORTRAN 77) specify that array indices begin at 1, as in mathematical tradition while other languages (like Fortran 90, Pascal and Algol) let the user choose the minimum value for each index.
</p>
<h3><span class="mw-headline" id="Dope_vectors">Dope vectors</span><span class="mw-editsection"></span></h3>
<p>The addressing formula is completely defined by the dimension <i>d</i>, the base address <i>B</i>, and the increments <i>c</i><sub>1</sub>, <i>c</i><sub>2</sub>, ..., <i>c</i><sub><i>k</i></sub>. It is often useful to pack these parameters into a record called the array's <i>descriptor</i> or <i>stride vector</i> or <i>dope vector</i>.<sup class="reference" id="cite_ref-andres_2-3">[2]</sup><sup class="reference" id="cite_ref-garcia_3-3">[3]</sup> The size of each element, and the minimum and maximum values allowed for each index may also be included in the dope vector. The dope vector is a complete handle for the array, and is a convenient way to pass arrays as arguments to procedures. Many useful array slicing operations (such as selecting a sub-array, swapping indices, or reversing the direction of the indices) can be performed very efficiently by manipulating the dope vector.<sup class="reference" id="cite_ref-andres_2-4">[2]</sup>
</p>
<h3><span class="mw-headline" id="Compact_layouts">Compact layouts</span><span class="mw-editsection"></span></h3>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<p>Often the coefficients are chosen so that the elements occupy a contiguous area of memory. However, that is not necessary. Even if arrays are always created with contiguous elements, some array slicing operations may create non-contiguous sub-arrays from them.
</p>

<p>There are two systematic compact layouts for a two-dimensional array. For example, consider the matrix
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle A={\begin{bmatrix}1&amp;2&amp;3\\4&amp;5&amp;6\\7&amp;8&amp;9\end{bmatrix}}.}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>A</mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow>
<mo>[</mo>
<mtable columnspacing="1em" rowspacing="4pt">
<mtr>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>2</mn>
</mtd>
<mtd>
<mn>3</mn>
</mtd>
</mtr>
<mtr>
<mtd>
<mn>4</mn>
</mtd>
<mtd>
<mn>5</mn>
</mtd>
<mtd>
<mn>6</mn>
</mtd>
</mtr>
<mtr>
<mtd>
<mn>7</mn>
</mtd>
<mtd>
<mn>8</mn>
</mtd>
<mtd>
<mn>9</mn>
</mtd>
</mtr>
</mtable>
<mo>]</mo>
</mrow>
</mrow>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle A={\begin{bmatrix}1&amp;2&amp;3\\4&amp;5&amp;6\\7&amp;8&amp;9\end{bmatrix}}.}</annotation>
</semantics>
</math></span><img alt="{\displaystyle A={\begin{bmatrix}1&amp;2&amp;3\\4&amp;5&amp;6\\7&amp;8&amp;9\end{bmatrix}}.}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e5ce1bbaec43174abf6887a29b8f3a3612d0b1f5" style="vertical-align: -4.005ex; width:17.473ex; height:9.176ex;"/></span></dd></dl>
<p>In the row-major order layout (adopted by C for statically declared arrays), the elements in each row are stored in consecutive positions and all of the elements of a row have a lower address than any of the elements of a consecutive row:
</p>
<dl><dd><table class="wikitable">
<tbody><tr>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td>9
</td></tr></tbody></table></dd></dl>
<p>In column-major order (traditionally used by Fortran), the elements in each column are consecutive in memory and all of the elements of a column have a lower address than any of the elements of a consecutive column:
</p>
<dl><dd><table class="wikitable">
<tbody><tr>
<td>1</td>
<td>4</td>
<td>7</td>
<td>2</td>
<td>5</td>
<td>8</td>
<td>3</td>
<td>6</td>
<td>9
</td></tr></tbody></table></dd></dl>
<p>For arrays with three or more indices, "row major order" puts in consecutive positions any two elements whose index tuples differ only by one in the <i>last</i> index. "Column major order" is analogous with respect to the <i>first</i> index.
</p><p>In systems which use processor cache or virtual memory, scanning an array is much faster if successive elements are stored in consecutive positions in memory, rather than sparsely scattered. Many algorithms that use multidimensional arrays will scan them in a predictable order. A programmer (or a sophisticated compiler) may use this information to choose between row- or column-major layout for each array. For example, when computing the product <i>A</i>·<i>B</i> of two matrices, it would be best to have <i>A</i> stored in row-major order, and <i>B</i> in column-major order.
</p>
<h3><span class="mw-headline" id="Resizing">Resizing</span><span class="mw-editsection"></span></h3>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<p>Static arrays have a size that is fixed when they are created and consequently do not allow elements to be inserted or removed. However, by allocating a new array and copying the contents of the old array to it, it is possible to effectively implement a <i>dynamic</i> version of an array; see dynamic array. If this operation is done infrequently, insertions at the end of the array require only amortized constant time.
</p><p>Some array data structures do not reallocate storage, but do store a count of the number of elements of the array in use, called the count or size. This effectively makes the array a dynamic array with a fixed maximum size or capacity; Pascal strings are examples of this.
</p>
<h3><span class="mw-headline" id="Non-linear_formulas">Non-linear formulas</span><span class="mw-editsection"></span></h3>
<p>More complicated (non-linear) formulas are occasionally used. For a compact two-dimensional triangular array, for instance, the addressing formula is a polynomial of degree 2.
</p>
<h2><span class="mw-headline" id="Efficiency">Efficiency</span><span class="mw-editsection"></span></h2>
<p>Both <i>store</i> and <i>select</i> take (deterministic worst case) constant time. Arrays take linear (O(<i>n</i>)) space in the number of elements <i>n</i> that they hold.
</p><p>In an array with element size <i>k</i> and on a machine with a cache line size of B bytes, iterating through an array of <i>n</i> elements requires the minimum of ceiling(<i>nk</i>/B) cache misses, because its elements occupy contiguous memory locations. This is roughly a factor of B/<i>k</i> better than the number of cache misses needed to access <i>n</i> elements at random memory locations. As a consequence, sequential iteration over an array is noticeably faster in practice than iteration over many other data structures, a property called locality of reference (this does <i>not</i> mean however, that using a perfect hash or trivial hash within the same (local) array, will not be even faster - and achievable in constant time). Libraries provide low-level optimized facilities for copying ranges of memory (such as memcpy) which can be used to move contiguous blocks of array elements significantly faster than can be achieved through individual element access. The speedup of such optimized routines varies by array element size, architecture, and implementation.
</p><p>Memory-wise, arrays are compact data structures with no per-element overhead. There may be a per-array overhead (e.g., to store index bounds) but this is language-dependent. It can also happen that elements stored in an array require <i>less</i> memory than the same elements stored in individual variables, because several array elements can be stored in a single word; such arrays are often called <i>packed</i> arrays. An extreme (but commonly used) case is the bit array, where every bit represents a single element. A single octet can thus hold up to 256 different combinations of up to 8 different conditions, in the most compact form.
</p><p>Array accesses with statically predictable access patterns are a major source of data parallelism.
</p>
<h3><span class="mw-headline" id="Comparison_with_other_data_structures">Comparison with other data structures</span><span class="mw-editsection"></span></h3>
<table class="wikitable">
<caption>Comparison of list data structures
</caption>
<tbody><tr>
<th rowspan="2">
</th>
<th rowspan="2">Peek <br/>(index)
</th>
<th colspan="3">Mutate (insert or delete) at …
</th>
<th rowspan="2">Excess space, <br/>average
</th></tr>
<tr>
<th>Beginning
</th>
<th>End
</th>
<th>Middle
</th></tr>
<tr>
<td>Linked list
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1), known end element;<br/>Θ(<i>n</i>), unknown end element
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Peek time + <br/>Θ(1)<sup class="reference" id="cite_ref-9">[9]</sup><sup class="reference" id="cite_ref-10">[10]</sup>
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td></tr>
<tr>
<td>Array
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">0
</td></tr>
<tr>
<td>Dynamic array
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1) amortized
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)<sup class="reference" id="cite_ref-11">[11]</sup>
</td></tr>
<tr>
<td>Balanced tree
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log n)
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log n)
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log <i>n</i>)
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log <i>n</i>)
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td></tr>
<tr>
<td>Random-<span class="nowrap">access list</span>
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log n)<sup class="reference" id="cite_ref-okasakiComparison_12-0">[12]</sup>
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—<sup class="reference" id="cite_ref-okasakiComparison_12-1">[12]</sup>
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—<sup class="reference" id="cite_ref-okasakiComparison_12-2">[12]</sup>
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td></tr>
<tr>
<td>Hashed array tree
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1) amortized
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(√<i>n</i>)
</td></tr></tbody></table>
<p>Dynamic arrays or growable arrays are similar to arrays but add the ability to insert and delete elements; adding and deleting at the end is particularly efficient. However, they reserve linear (Θ(<i>n</i>)) additional storage, whereas arrays do not reserve additional storage.
</p><p>Associative arrays provide a mechanism for array-like functionality without huge storage overheads when the index values are sparse. For example, an array that contains values only at indexes 1 and 2 billion may benefit from using such a structure. Specialized associative arrays with integer keys include Patricia tries, Judy arrays, and van Emde Boas trees.
</p><p>Balanced trees require O(log <i>n</i>) time for indexed access, but also permit inserting or deleting elements in O(log <i>n</i>) time,<sup class="reference" id="cite_ref-13">[13]</sup> whereas growable arrays require linear (Θ(<i>n</i>)) time to insert or delete elements at an arbitrary position.
</p><p>Linked lists allow constant time removal and insertion in the middle but take linear time for indexed access. Their memory use is typically worse than arrays, but is still linear.
</p>

<p>An Iliffe vector is an alternative to a multidimensional array structure. It uses a one-dimensional array of references to arrays of one dimension less. For two dimensions, in particular, this alternative structure would be a vector of pointers to vectors, one for each row(pointer on c or c++). Thus an element in row <i>i</i> and column <i>j</i> of an array <i>A</i> would be accessed by double indexing (<i>A</i>[<i>i</i>][<i>j</i>] in typical notation). This alternative structure allows jagged arrays, where each row may have a different size—or, in general, where the valid range of each index depends on the values of all preceding indices. It also saves one multiplication (by the column address increment) replacing it by a bit shift (to index the vector of row pointers) and one extra memory access (fetching the row address), which may be worthwhile in some architectures.
</p>
<h2><span class="mw-headline" id="Dimension">Dimension</span><span class="mw-editsection"></span></h2>
<p>The <i>dimension</i> of an array is the number of indices needed to select an element. Thus, if the array is seen as a function on a set of possible index combinations, it is the dimension of the space of which its domain is a discrete subset. Thus a one-dimensional array is a list of data, a two-dimensional array is a rectangle of data,<sup class="reference" id="cite_ref-14">[14]</sup> a three-dimensional array a block of data, etc.
</p><p>This should not be confused with the dimension of the set of all matrices with a given domain, that is, the number of elements in the array. For example, an array with 5 rows and 4 columns is two-dimensional, but such matrices form a 20-dimensional space. Similarly, a three-dimensional vector can be represented by a one-dimensional array of size three.
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1128808480">.mw-parser-output .portalbox{padding:0;display:table;box-sizing:border-box;max-width:175px}.mw-parser-output .portalborder{border:solid #aaa 1px;padding:0.1em;background:#f9f9f9}.mw-parser-output .portalbox-entry{display:table-row;font-size:85%;line-height:110%;font-style:italic;font-weight:bold}.mw-parser-output .portalbox-image{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portalbox-link{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}@media(min-width:720px){.mw-parser-output .portalleft{clear:left;float:left;margin:0.5em 1em 0.5em 0}.mw-parser-output .portalright{clear:right;float:right;margin:0.5em 0 0.5em 1em}}</style>
<style data-mw-deduplicate="TemplateStyles:r998391716">.mw-parser-output .div-col{margin-top:0.3em;column-width:30em}.mw-parser-output .div-col-small{font-size:90%}.mw-parser-output .div-col-rules{column-rule:1px solid #aaa}.mw-parser-output .div-col dl,.mw-parser-output .div-col ol,.mw-parser-output .div-col ul{margin-top:0}.mw-parser-output .div-col li,.mw-parser-output .div-col dd{page-break-inside:avoid;break-inside:avoid-column}</style>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1097025294">.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:#f9f9f9}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1}}@media(min-width:720px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}</style>
<link href="mw-data:TemplateStyles:r1097025294" rel="mw-deduplicated-inline-style"/>
<ul><li><img alt="" class="noviewer" data-file-height="400" data-file-width="400" decoding="async" height="16" src="//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/16px-Wikibooks-logo-en-noslogan.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/24px-Wikibooks-logo-en-noslogan.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/d/df/Wikibooks-logo-en-noslogan.svg/32px-Wikibooks-logo-en-noslogan.svg.png 2x" width="16"/> Data Structures/Arrays at Wikibooks</li></ul>




<!-- 
NewPP limit report
Parsed by mw2329
Cached time: 20221223235442
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.409 seconds
Real time usage: 0.596 seconds
Preprocessor visited node count: 2320/1000000
Post‐expand include size: 81231/2097152 bytes
Template argument size: 2318/2097152 bytes
Highest expansion depth: 16/100
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 52552/5000000 bytes
Lua time usage: 0.207/10.000 seconds
Lua memory usage: 7683612/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  444.644      1 -total
 30.32%  134.810      1 Template:Reflist
 14.97%   66.553      4 Template:Cite_web
 12.57%   55.893      2 Template:Navbox
 11.06%   49.178      1 Template:More_citations_needed
 10.60%   47.127      1 Template:Ambox
 10.20%   45.372      1 Template:Short_description
  9.75%   43.360      1 Template:Commons_category
  9.69%   43.086      2 Template:Sister_project
  9.32%   41.425      2 Template:Side_box
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:2052-0!canonical and timestamp 20221223235442 and revision id 1115591814.
 -->
</div></body>
</html>