<!DOCTYPE html>
<html>
<head>
<title>adjacency-matrix_representation</title>
</head>
<body>
<div class="mw-parser-output">
<p>In graph theory and computer science, an <b>adjacency matrix</b> is a square matrix used to represent a finite graph. The elements of the matrix indicate whether pairs of vertices are adjacent or not in the graph.
</p><p>In the special case of a finite simple graph, the adjacency matrix is a (0,1)-matrix with zeros on its diagonal. If the graph is undirected (i.e. all of its edges are bidirectional), the adjacency matrix is symmetric. 
The relationship between a graph and the eigenvalues and eigenvectors of its adjacency matrix is studied in spectral graph theory.
</p><p>The adjacency matrix of a graph should be distinguished from its incidence matrix, a different matrix representation whose elements indicate whether vertex–edge pairs are incident or not, and its degree matrix, which contains information about the degree of each vertex.
</p>

<h2><span class="mw-headline" id="Definition">Definition</span><span class="mw-editsection"></span></h2>
<p>For a simple graph with vertex set <span class="texhtml"><i>U</i> = {<i>u</i><sub>1</sub>, …, <i>u</i><sub><i>n</i></sub>}</span>, the adjacency matrix is a square <span class="texhtml"><i>n</i> × <i>n</i></span> matrix <span class="texhtml mvar" style="font-style:italic;">A</span> such that its element <span class="texhtml mvar" style="font-style:italic;">A<sub>ij</sub></span> is one when there is an edge from vertex <span class="texhtml"><i>u</i><sub>i</sub></span> to vertex <span class="texhtml"><i>u</i><sub>j</sub></span>, and zero when there is no edge.<sup class="reference" id="cite_ref-1">[1]</sup> The diagonal elements of the matrix are all zero, since edges from a vertex to itself (loops) are not allowed in simple graphs. It is also sometimes useful in algebraic graph theory to replace the nonzero elements with algebraic variables.<sup class="reference" id="cite_ref-2">[2]</sup> The same concept can be extended to multigraphs and graphs with loops by storing the number of edges between each two vertices in the corresponding matrix element, and by allowing nonzero diagonal elements. Loops may be counted either once (as a single edge) or twice (as two vertex-edge incidences), as long as a consistent convention is followed. Undirected graphs often use the latter convention of counting loops twice, whereas directed graphs typically use the former convention.
</p>
<h3><span class="mw-headline" id="Of_a_bipartite_graph">Of a bipartite graph</span><span class="mw-editsection"></span></h3>
<p>The adjacency matrix <span class="texhtml mvar" style="font-style:italic;">A</span> of a bipartite graph whose two parts have <span class="texhtml mvar" style="font-style:italic;">r</span> and <span class="texhtml mvar" style="font-style:italic;">s</span> vertices can be written in the form 
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle A={\begin{pmatrix}0_{r,r}&amp;B\\B^{\mathsf {T}}&amp;0_{s,s}\end{pmatrix}},}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>A</mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow>
<mo>(</mo>
<mtable columnspacing="1em" rowspacing="4pt">
<mtr>
<mtd>
<msub>
<mn>0</mn>
<mrow class="MJX-TeXAtom-ORD">
<mi>r</mi>
<mo>,</mo>
<mi>r</mi>
</mrow>
</msub>
</mtd>
<mtd>
<mi>B</mi>
</mtd>
</mtr>
<mtr>
<mtd>
<msup>
<mi>B</mi>
<mrow class="MJX-TeXAtom-ORD">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="sans-serif">T</mi>
</mrow>
</mrow>
</msup>
</mtd>
<mtd>
<msub>
<mn>0</mn>
<mrow class="MJX-TeXAtom-ORD">
<mi>s</mi>
<mo>,</mo>
<mi>s</mi>
</mrow>
</msub>
</mtd>
</mtr>
</mtable>
<mo>)</mo>
</mrow>
</mrow>
<mo>,</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle A={\begin{pmatrix}0_{r,r}&amp;B\\B^{\mathsf {T}}&amp;0_{s,s}\end{pmatrix}},}</annotation>
</semantics>
</math></span><img alt="{\displaystyle A={\begin{pmatrix}0_{r,r}&amp;B\\B^{\mathsf {T}}&amp;0_{s,s}\end{pmatrix}},}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/430809942e7874271970cab4abe5953c8a8237ca" style="vertical-align: -2.47ex; margin-bottom: -0.201ex; width:18.713ex; height:6.509ex;"/></span></dd></dl>
<p>where <span class="texhtml mvar" style="font-style:italic;">B</span> is an <span class="texhtml"><i>r</i> × <i>s</i></span> matrix, and <span class="texhtml">0<sub><i>r</i>,<i>r</i></sub></span> and <span class="texhtml">0<sub><i>s</i>,<i>s</i></sub></span> represent the <span class="texhtml"><i>r</i> × <i>r</i></span> and <span class="texhtml"><i>s</i> × <i>s</i></span> zero matrices. In this case, the smaller matrix <span class="texhtml mvar" style="font-style:italic;">B</span> uniquely represents the graph, and the remaining parts of <span class="texhtml mvar" style="font-style:italic;">A</span> can be discarded as redundant. <span class="texhtml mvar" style="font-style:italic;">B</span> is sometimes called the <i>biadjacency matrix</i>.
</p><p>Formally, let <span class="texhtml"><i>G</i> = (<i>U</i>, <i>V</i>, <i>E</i>)</span> be a bipartite graph with parts <span class="texhtml"><i>U</i> = {<i>u</i><sub>1</sub>, ..., <i>u</i><sub><i>r</i></sub>}</span>, <span class="texhtml"><i>V</i> = {<i>v</i><sub>1</sub>, ..., <i>v</i><sub><i>s</i></sub>}</span> and edges <span class="texhtml mvar" style="font-style:italic;">E</span>. The biadjacency matrix is the <span class="texhtml"><i>r</i> × <i>s</i></span> 0–1 matrix <span class="texhtml mvar" style="font-style:italic;">B</span> in which <span class="texhtml"><i>b</i><sub><i>i</i>,<i>j</i></sub> = 1</span> if and only if <span class="texhtml">(<i>u</i><sub><i>i</i></sub>, <i>v</i><sub><i>j</i></sub>) ∈ <i>E</i></span>.
</p><p>If <span class="texhtml mvar" style="font-style:italic;">G</span> is a bipartite multigraph or weighted graph, then the elements <span class="texhtml mvar" style="font-style:italic;">b<i><sub>i,j</sub></i></span> are taken to be the number of edges between the vertices or the weight of the edge <span class="texhtml">(<i>u</i><sub><i>i</i></sub>, <i>v</i><sub><i>j</i></sub>)</span>, respectively.
</p>
<h3><span class="mw-headline" id="Variations">Variations</span><span class="mw-editsection"></span></h3>
<p>An <span class="nowrap"><span class="texhtml">(<i>a</i>, <i>b</i>, <i>c</i>)</span></span>-adjacency matrix <span class="texhtml mvar" style="font-style:italic;">A</span> of a simple graph has <span class="texhtml"><i>A</i><sub><i>i</i>,<i>j</i></sub> = <i>a</i></span> if <span class="texhtml">(<i>i</i>, <i>j</i>)</span> is an edge, <span class="texhtml mvar" style="font-style:italic;">b</span> if it is not, and <span class="texhtml mvar" style="font-style:italic;">c</span> on the diagonal. The Seidel adjacency matrix is a <span class="texhtml"><span class="nowrap">(−1, 1, 0)</span></span>-adjacency matrix. This matrix is used in studying strongly regular graphs and two-graphs.<sup class="reference" id="cite_ref-3">[3]</sup>
</p><p>The <b>distance matrix</b> has in position <span class="texhtml">(<i>i</i>, <i>j</i>)</span> the distance between vertices <span class="texhtml mvar" style="font-style:italic;">v<sub>i</sub></span> and <span class="texhtml mvar" style="font-style:italic;">v<sub>j</sub></span>. The distance is the length of a shortest path connecting the vertices. Unless lengths of edges are explicitly provided, the length of a path is the number of edges in it. The distance matrix resembles a high power of the adjacency matrix, but instead of telling only whether or not two vertices are connected (i.e., the connection matrix, which contains boolean values), it gives the exact distance between them.
</p>
<h2><span class="mw-headline" id="Examples">Examples</span><span class="mw-editsection"></span></h2>
<h3><span class="mw-headline" id="Undirected_graphs">Undirected graphs</span><span class="mw-editsection"></span></h3>
<p>The convention followed here (for undirected graphs) is that each edge adds 1 to the appropriate cell in the matrix, and each loop adds 2.<sup class="reference" id="cite_ref-4">[4]</sup> This allows the degree of a vertex to be easily found by taking the sum of the values in either its respective row or column in the adjacency matrix.
</p>
<table class="wikitable" style="text-align: center; width: 700px;">
<tbody><tr>
<th>Labeled graph
</th>
<th>Adjacency matrix
</th></tr>
<tr>
<td><img alt="6n-graph2.svg" data-file-height="410" data-file-width="375" decoding="async" height="219" src="//upload.wikimedia.org/wikipedia/commons/thumb/2/28/6n-graph2.svg/200px-6n-graph2.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/2/28/6n-graph2.svg/300px-6n-graph2.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/28/6n-graph2.svg/400px-6n-graph2.svg.png 2x" width="200"/>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\begin{pmatrix}1&amp;1&amp;0&amp;0&amp;1&amp;0\\1&amp;0&amp;1&amp;0&amp;1&amp;0\\0&amp;1&amp;0&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;0&amp;1&amp;1\\1&amp;1&amp;0&amp;1&amp;0&amp;0\\0&amp;0&amp;0&amp;1&amp;0&amp;0\end{pmatrix}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mrow>
<mo>(</mo>
<mtable columnspacing="1em" rowspacing="4pt">
<mtr>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
</mtr>
<mtr>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
</mtr>
<mtr>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
</mtr>
<mtr>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
</mtr>
<mtr>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
</mtr>
<mtr>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>1</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
<mtd>
<mn>0</mn>
</mtd>
</mtr>
</mtable>
<mo>)</mo>
</mrow>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\begin{pmatrix}1&amp;1&amp;0&amp;0&amp;1&amp;0\\1&amp;0&amp;1&amp;0&amp;1&amp;0\\0&amp;1&amp;0&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;0&amp;1&amp;1\\1&amp;1&amp;0&amp;1&amp;0&amp;0\\0&amp;0&amp;0&amp;1&amp;0&amp;0\end{pmatrix}}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\begin{pmatrix}1&amp;1&amp;0&amp;0&amp;1&amp;0\\1&amp;0&amp;1&amp;0&amp;1&amp;0\\0&amp;1&amp;0&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;0&amp;1&amp;1\\1&amp;1&amp;0&amp;1&amp;0&amp;0\\0&amp;0&amp;0&amp;1&amp;0&amp;0\end{pmatrix}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1a801c1edd8efe61bcadfcb174cf8d9a487dd00a" style="vertical-align: -9.005ex; width:23.406ex; height:19.176ex;"/></span>
<p><br/>Coordinates are 1–6.
</p>
</td></tr>
<tr>
<td><img alt="Symmetric group 4; Cayley graph 1,5,21 (Nauru Petersen); numbers.svg" data-file-height="748" data-file-width="748" decoding="async" height="250" src="//upload.wikimedia.org/wikipedia/commons/thumb/2/27/Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28Nauru_Petersen%29%3B_numbers.svg/250px-Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28Nauru_Petersen%29%3B_numbers.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/2/27/Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28Nauru_Petersen%29%3B_numbers.svg/375px-Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28Nauru_Petersen%29%3B_numbers.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/27/Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28Nauru_Petersen%29%3B_numbers.svg/500px-Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28Nauru_Petersen%29%3B_numbers.svg.png 2x" width="250"/>
<p><br/>Nauru graph
</p>
</td>
<td><img alt="Symmetric group 4; Cayley graph 1,5,21 (adjacency matrix).svg" data-file-height="744" data-file-width="744" decoding="async" height="250" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28adjacency_matrix%29.svg/250px-Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28adjacency_matrix%29.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/17/Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28adjacency_matrix%29.svg/375px-Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28adjacency_matrix%29.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/17/Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28adjacency_matrix%29.svg/500px-Symmetric_group_4%3B_Cayley_graph_1%2C5%2C21_%28adjacency_matrix%29.svg.png 2x" width="250"/>
<p><br/>Coordinates are 0–23.
<br/>White fields are zeros, colored fields are ones.
</p>
</td></tr></tbody></table>
<h3><span class="mw-headline" id="Directed_graphs">Directed graphs</span><span class="mw-editsection"></span></h3>
<p>The adjacency matrix of a directed graph can be asymmetric. One can define the adjacency matrix of a directed graph either such that 
</p>
<ol><li>a non-zero element <span class="texhtml mvar" style="font-style:italic;">A<sub>ij</sub></span> indicates an edge from <span class="texhtml mvar" style="font-style:italic;">i</span> to <span class="texhtml mvar" style="font-style:italic;">j</span> or</li>
<li>it indicates an edge from <span class="texhtml mvar" style="font-style:italic;">j</span> to <span class="texhtml mvar" style="font-style:italic;">i</span>.</li></ol>
<p>The former definition is commonly used in graph theory and social network analysis (e.g., sociology, political science, economics, psychology).<sup class="reference" id="cite_ref-5">[5]</sup> The latter is more common in other applied sciences (e.g., dynamical systems, physics, network science) where <span class="texhtml mvar" style="font-style:italic;">A</span> is sometimes used to describe linear dynamics on graphs.<sup class="reference" id="cite_ref-6">[6]</sup>
</p><p>Using the first definition, the in-degrees of a vertex can be computed by summing the entries of the corresponding column and the out-degree of vertex by summing the entries of the corresponding row. When using the second definition, the in-degree of a vertex is given by the corresponding row sum and the out-degree is given by the corresponding column sum.
</p>
<table class="wikitable" style="text-align: center; width: 700px;">
<tbody><tr>
<th>Labeled graph
</th>
<th>Adjacency matrix
</th></tr>
<tr>
<td><img alt="Symmetric group 4; Cayley graph 4,9; numbers.svg" data-file-height="812" data-file-width="812" decoding="async" height="250" src="//upload.wikimedia.org/wikipedia/commons/thumb/8/86/Symmetric_group_4%3B_Cayley_graph_4%2C9%3B_numbers.svg/250px-Symmetric_group_4%3B_Cayley_graph_4%2C9%3B_numbers.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/8/86/Symmetric_group_4%3B_Cayley_graph_4%2C9%3B_numbers.svg/375px-Symmetric_group_4%3B_Cayley_graph_4%2C9%3B_numbers.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/8/86/Symmetric_group_4%3B_Cayley_graph_4%2C9%3B_numbers.svg/500px-Symmetric_group_4%3B_Cayley_graph_4%2C9%3B_numbers.svg.png 2x" width="250"/>
<p><br/>Directed Cayley graph of S<sub>4</sub>
</p>
</td>
<td><img alt="Symmetric group 4; Cayley graph 4,9 (adjacency matrix).svg" data-file-height="744" data-file-width="744" decoding="async" height="250" src="//upload.wikimedia.org/wikipedia/commons/thumb/2/22/Symmetric_group_4%3B_Cayley_graph_4%2C9_%28adjacency_matrix%29.svg/250px-Symmetric_group_4%3B_Cayley_graph_4%2C9_%28adjacency_matrix%29.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/2/22/Symmetric_group_4%3B_Cayley_graph_4%2C9_%28adjacency_matrix%29.svg/375px-Symmetric_group_4%3B_Cayley_graph_4%2C9_%28adjacency_matrix%29.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/2/22/Symmetric_group_4%3B_Cayley_graph_4%2C9_%28adjacency_matrix%29.svg/500px-Symmetric_group_4%3B_Cayley_graph_4%2C9_%28adjacency_matrix%29.svg.png 2x" width="250"/>
<p><br/>Coordinates are 0–23.
<br/>As the graph is directed, the matrix is not necessarily symmetric.
</p>
</td></tr></tbody></table>
<h3><span class="mw-headline" id="Trivial_graphs">Trivial graphs</span><span class="mw-editsection"></span></h3>
<p>The adjacency matrix of a complete graph contains all ones except along the diagonal where there are only zeros. The adjacency matrix of an empty graph is a zero matrix.
</p>
<h2><span class="mw-headline" id="Properties">Properties</span><span class="mw-editsection"></span></h2>
<h3><span class="mw-headline" id="Spectrum">Spectrum</span><span class="mw-editsection"></span></h3>
<p>The adjacency matrix of an undirected simple graph is symmetric, and therefore has a complete set of real eigenvalues and an orthogonal eigenvector basis. The set of eigenvalues of a graph is the <b>spectrum</b> of the graph.<sup class="reference" id="cite_ref-7">[7]</sup> It is common to denote the eigenvalues by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{1}\geq \lambda _{2}\geq \cdots \geq \lambda _{n}.}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>≥<!-- ≥ --></mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>≥<!-- ≥ --></mo>
<mo>⋯<!-- ⋯ --></mo>
<mo>≥<!-- ≥ --></mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</msub>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{1}\geq \lambda _{2}\geq \cdots \geq \lambda _{n}.}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \lambda _{1}\geq \lambda _{2}\geq \cdots \geq \lambda _{n}.}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1dce0743ac341fe1f3553f10614b9863a83efecc" style="vertical-align: -0.671ex; width:20.058ex; height:2.509ex;"/></span>
</p><p>The greatest eigenvalue <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{1}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{1}}</annotation>
</semantics>
</math></span><img alt="\lambda _{1}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/571a423bece8f29bcd1b48572f18dd4f6213dce2" style="vertical-align: -0.671ex; width:2.409ex; height:2.509ex;"/></span> is bounded above by the maximum degree. This can be seen as result of the Perron–Frobenius theorem, but it can be proved easily. Let <span class="texhtml mvar" style="font-style:italic;">v</span> be one eigenvector associated to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{1}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{1}}</annotation>
</semantics>
</math></span><img alt="\lambda _{1}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/571a423bece8f29bcd1b48572f18dd4f6213dce2" style="vertical-align: -0.671ex; width:2.409ex; height:2.509ex;"/></span> and <span class="texhtml mvar" style="font-style:italic;">x</span> the component in which <span class="texhtml mvar" style="font-style:italic;">v</span> has maximum absolute value. Without loss of generality assume <span class="texhtml mvar" style="font-style:italic;">v<sub>x</sub></span> is positive since otherwise you simply take the eigenvector <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle -v}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo>−<!-- − --></mo>
<mi>v</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle -v}</annotation>
</semantics>
</math></span><img alt="-v" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/05d12e513906523af26c5372b10aee063aa11926" style="vertical-align: -0.505ex; width:2.936ex; height:2.176ex;"/></span>, also associated to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{1}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{1}}</annotation>
</semantics>
</math></span><img alt="\lambda _{1}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/571a423bece8f29bcd1b48572f18dd4f6213dce2" style="vertical-align: -0.671ex; width:2.409ex; height:2.509ex;"/></span>. Then
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{1}v_{x}=(Av)_{x}=\sum _{y=1}^{n}A_{x,y}v_{y}\leq \sum _{y=1}^{n}A_{x,y}v_{x}=v_{x}\deg(x).}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<msub>
<mi>v</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>x</mi>
</mrow>
</msub>
<mo>=</mo>
<mo stretchy="false">(</mo>
<mi>A</mi>
<mi>v</mi>
<msub>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>x</mi>
</mrow>
</msub>
<mo>=</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>y</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msub>
<mi>A</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>x</mi>
<mo>,</mo>
<mi>y</mi>
</mrow>
</msub>
<msub>
<mi>v</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>y</mi>
</mrow>
</msub>
<mo>≤<!-- ≤ --></mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>y</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<msub>
<mi>A</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>x</mi>
<mo>,</mo>
<mi>y</mi>
</mrow>
</msub>
<msub>
<mi>v</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>x</mi>
</mrow>
</msub>
<mo>=</mo>
<msub>
<mi>v</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>x</mi>
</mrow>
</msub>
<mi>deg</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{1}v_{x}=(Av)_{x}=\sum _{y=1}^{n}A_{x,y}v_{y}\leq \sum _{y=1}^{n}A_{x,y}v_{x}=v_{x}\deg(x).}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \lambda _{1}v_{x}=(Av)_{x}=\sum _{y=1}^{n}A_{x,y}v_{y}\leq \sum _{y=1}^{n}A_{x,y}v_{x}=v_{x}\deg(x).}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/88d6f85c5b9942be62f5b1753287f21c96a8719c" style="vertical-align: -3.338ex; width:53.258ex; height:7.176ex;"/></span></dd></dl>
<p>For <span class="texhtml mvar" style="font-style:italic;">d</span>-regular graphs, <span class="texhtml mvar" style="font-style:italic;">d</span> is the first eigenvalue of <span class="texhtml mvar" style="font-style:italic;">A</span> for the vector <span class="texhtml"><span class="nowrap"><i>v</i> = (1, …, 1)</span></span> (it is easy to check that it is an eigenvalue and it is the maximum because of the above bound). The multiplicity of this eigenvalue is the number of connected components of <span class="texhtml mvar" style="font-style:italic;">G</span>, in particular <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{1}&gt;\lambda _{2}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>&gt;</mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{1}&gt;\lambda _{2}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \lambda _{1}&gt;\lambda _{2}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3dc9ff31d5f3eff2381c8822914675d766c09771" style="vertical-align: -0.671ex; width:7.917ex; height:2.509ex;"/></span> for connected graphs. It can be shown that for each eigenvalue <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{i}}</annotation>
</semantics>
</math></span><img alt="\lambda _{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/72fde940918edf84caf3d406cc7d31949166820f" style="vertical-align: -0.671ex; width:2.155ex; height:2.509ex;"/></span>, its opposite <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle -\lambda _{i}=\lambda _{n+1-i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo>−<!-- − --></mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>=</mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
<mo>+</mo>
<mn>1</mn>
<mo>−<!-- − --></mo>
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle -\lambda _{i}=\lambda _{n+1-i}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle -\lambda _{i}=\lambda _{n+1-i}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9924575365eb273ebcec2d96c613db21a5a753ea" style="vertical-align: -0.671ex; width:13.582ex; height:2.509ex;"/></span> is also an eigenvalue of <span class="texhtml mvar" style="font-style:italic;">A</span> if <span class="texhtml mvar" style="font-style:italic;">G</span> is a bipartite graph.<sup class="reference" id="cite_ref-8">[8]</sup> In particular −<span class="texhtml mvar" style="font-style:italic;">d</span> is an eigenvalue of any <span class="texhtml mvar" style="font-style:italic;">d</span>-regular bipartite graph.
</p><p>The difference <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda _{1}-\lambda _{2}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda _{1}-\lambda _{2}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \lambda _{1}-\lambda _{2}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/55c9656bfc37d834af914d883918e43982466d46" style="vertical-align: -0.671ex; width:7.659ex; height:2.509ex;"/></span> is called the spectral gap and it is related to the expansion of <span class="texhtml mvar" style="font-style:italic;">G</span>. It is also useful to introduce the spectral radius of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle A}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>A</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle A}</annotation>
</semantics>
</math></span><img alt="A" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7daff47fa58cdfd29dc333def748ff5fa4c923e3" style="vertical-align: -0.338ex; width:1.743ex; height:2.176ex;"/></span> denoted by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda (G)=\max _{\left|\lambda _{i}\right|&lt;d}|\lambda _{i}|}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>λ<!-- λ --></mi>
<mo stretchy="false">(</mo>
<mi>G</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<munder>
<mo form="prefix" movablelimits="true">max</mo>
<mrow class="MJX-TeXAtom-ORD">
<mrow>
<mo>|</mo>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo>|</mo>
</mrow>
<mo>&lt;</mo>
<mi>d</mi>
</mrow>
</munder>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
<msub>
<mi>λ<!-- λ --></mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mrow class="MJX-TeXAtom-ORD">
<mo stretchy="false">|</mo>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda (G)=\max _{\left|\lambda _{i}\right|&lt;d}|\lambda _{i}|}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \lambda (G)=\max _{\left|\lambda _{i}\right|&lt;d}|\lambda _{i}|}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a260fb2486403a71d69adc77b25aa7ef9d5221da" style="vertical-align: -2.505ex; width:16.562ex; height:4.509ex;"/></span>. This number is bounded by <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \lambda (G)\geq 2{\sqrt {d-1}}-o(1)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>λ<!-- λ --></mi>
<mo stretchy="false">(</mo>
<mi>G</mi>
<mo stretchy="false">)</mo>
<mo>≥<!-- ≥ --></mo>
<mn>2</mn>
<mrow class="MJX-TeXAtom-ORD">
<msqrt>
<mi>d</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
</msqrt>
</mrow>
<mo>−<!-- − --></mo>
<mi>o</mi>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \lambda (G)\geq 2{\sqrt {d-1}}-o(1)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \lambda (G)\geq 2{\sqrt {d-1}}-o(1)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b0ddd0c3d72f4529cca9dcb5fdc6089c124279e5" style="vertical-align: -0.838ex; width:23.347ex; height:3.343ex;"/></span>. This bound is tight in the Ramanujan graphs, which have applications in many areas.
</p>
<h3><span class="mw-headline" id="Isomorphism_and_invariants">Isomorphism and invariants</span><span class="mw-editsection"></span></h3>
<p>Suppose two directed or undirected graphs <span class="texhtml"><i>G</i><sub>1</sub></span> and <span class="texhtml"><i>G</i><sub>2</sub></span> with adjacency matrices <span class="texhtml"><i>A</i><sub>1</sub></span> and <span class="texhtml"><i>A</i><sub>2</sub></span> are given. <span class="texhtml"><i>G</i><sub>1</sub></span> and <span class="texhtml"><i>G</i><sub>2</sub></span> are isomorphic if and only if there exists a permutation matrix <span class="texhtml mvar" style="font-style:italic;">P</span> such that
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle PA_{1}P^{-1}=A_{2}.}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>P</mi>
<msub>
<mi>A</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<msup>
<mi>P</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</msup>
<mo>=</mo>
<msub>
<mi>A</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle PA_{1}P^{-1}=A_{2}.}</annotation>
</semantics>
</math></span><img alt="PA_{1}P^{-1}=A_{2}." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6b51b8853d371bc9ef909bf3f2adcfdb20e3acc9" style="vertical-align: -0.671ex; width:15.24ex; height:3.009ex;"/></span></dd></dl>
<p>In particular, <span class="texhtml"><i>A</i><sub>1</sub></span> and <span class="texhtml"><i>A</i><sub>2</sub></span> are similar and therefore have the same minimal polynomial, characteristic polynomial, eigenvalues, determinant and trace. These can therefore serve as isomorphism invariants of graphs. However, two graphs may possess the same set of eigenvalues but not be isomorphic.<sup class="reference" id="cite_ref-9">[9]</sup> Such linear operators are said to be isospectral.
</p>
<h3><span class="mw-headline" id="Matrix_powers">Matrix powers</span><span class="mw-editsection"></span></h3>
<p>If <span class="texhtml mvar" style="font-style:italic;">A</span> is the adjacency matrix of the directed or undirected graph <span class="texhtml mvar" style="font-style:italic;">G</span>, then the matrix <span class="texhtml"><i>A</i><sup><i>n</i></sup></span> (i.e., the matrix product of <span class="texhtml mvar" style="font-style:italic;">n</span> copies of <span class="texhtml mvar" style="font-style:italic;">A</span>) has an interesting interpretation: the element <span class="texhtml"><span class="nowrap">(<i>i</i>, <i>j</i>)</span></span> gives the number of (directed or undirected) walks of length <span class="texhtml mvar" style="font-style:italic;">n</span> from vertex <span class="texhtml mvar" style="font-style:italic;">i</span> to vertex <span class="texhtml mvar" style="font-style:italic;">j</span>. If <span class="texhtml mvar" style="font-style:italic;">n</span> is the smallest nonnegative integer, such that for some <span class="texhtml mvar" style="font-style:italic;">i</span>, <span class="texhtml mvar" style="font-style:italic;">j</span>, the element <span class="texhtml"><span class="nowrap">(<i>i</i>, <i>j</i>)</span></span> of <span class="texhtml"><i>A</i><sup><i>n</i></sup></span> is positive, then <span class="texhtml mvar" style="font-style:italic;">n</span> is the distance between vertex <span class="texhtml mvar" style="font-style:italic;">i</span> and vertex <span class="texhtml mvar" style="font-style:italic;">j</span>. A great example of how this is useful is in counting the number of triangles in an undirected graph <span class="texhtml mvar" style="font-style:italic;">G</span>, which is exactly the trace of <span class="texhtml"><i>A</i><sup>3</sup></span> divided by 6. We divide by 6 to compensate for the overcounting of each triangle (3! = 6 times). The adjacency matrix can be used to determine whether or not the graph is connected.
</p>
<h2><span class="mw-headline" id="Data_structures">Data structures</span><span class="mw-editsection"></span></h2>
<p>The adjacency matrix may be used as a data structure for the representation of graphs in computer programs for manipulating graphs. The main alternative data structure, also in use for this application, is the adjacency list.<sup class="reference" id="cite_ref-10">[10]</sup><sup class="reference" id="cite_ref-clrs_11-0">[11]</sup>
</p><p>The space needed to represent an adjacency matrix and the time needed to perform operations on them is dependent on the matrix representation chosen for the underlying matrix. Sparse matrix representations only store non-zero matrix entries and implicitly represents the zero entries. They can for example be used to represent sparse graphs without incurring the space overhead from storing the many zero entries in the adjacency matrix of the sparse graph. In the following section the adjacency matrix is assumed to be represented by an array data structure so that zero and non-zero entries in a matrix are all directly represented in storage.
</p><p>Because each entry in the adjacency matrix requires only one bit, it can be represented in a very compact way, occupying only |<i>V</i> |<sup>2</sup> / 8 bytes to represent a directed graph, or (by using a packed triangular format and only storing the lower triangular part of the matrix) approximately |<i>V</i> |<sup>2</sup> / 16 bytes to represent an undirected graph. Although slightly more succinct representations are possible, this method gets close to the information-theoretic lower bound for the minimum number of bits needed to represent all <span class="texhtml mvar" style="font-style:italic;">n</span>-vertex graphs.<sup class="reference" id="cite_ref-12">[12]</sup> For storing graphs in text files, fewer bits per byte can be used to ensure that all bytes are text characters, for instance by using a Base64 representation.<sup class="reference" id="cite_ref-13">[13]</sup> Besides avoiding wasted space, this compactness encourages locality of reference.
However, for a large sparse graph, adjacency lists require less storage space, because they do not waste any space to represent edges that are <i>not</i> present.<sup class="reference" id="cite_ref-clrs_11-1">[11]</sup><sup class="reference" id="cite_ref-gt_14-0">[14]</sup>
</p><p>An alternative form of adjacency matrix (which, however, requires a larger amount of space) replaces the numbers in each element of the matrix with pointers to edge objects (when edges are present) or null pointers (when there is no edge).<sup class="reference" id="cite_ref-gt_14-1">[14]</sup> It is also possible to store edge weights directly in the elements of an adjacency matrix.<sup class="reference" id="cite_ref-clrs_11-2">[11]</sup>
</p><p>Besides the space tradeoff, the different data structures also facilitate different operations. Finding all vertices adjacent to a given vertex in an adjacency list is as simple as reading the list, and takes time proportional to the number of neighbors. With an adjacency matrix, an entire row must instead be scanned, which takes a larger amount of time, proportional to the number of vertices in the whole graph. On the other hand, testing whether there is an edge between two given vertices can be determined at once with an adjacency matrix, while requiring time proportional to the minimum degree of the two vertices with the adjacency list.<sup class="reference" id="cite_ref-clrs_11-3">[11]</sup><sup class="reference" id="cite_ref-gt_14-2">[14]</sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"></span></h2>
<ul><li>Laplacian matrix</li>
<li>Self-similarity matrix</li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1097025294">.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:#f9f9f9}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1}}@media(min-width:720px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}</style>
<ul><li><span class="citation mathworld" id="Reference-Mathworld-Adjacency_matrix"><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation web cs1" id="CITEREFWeisstein">Weisstein, Eric W. "Adjacency matrix". <i>MathWorld</i>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MathWorld&amp;rft.atitle=Adjacency+matrix&amp;rft.au=Weisstein%2C+Eric+W.&amp;rft_id=https%3A%2F%2Fmathworld.wolfram.com%2FAdjacencyMatrix.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AAdjacency+matrix"></span></span></li>
<li>Fluffschack — an educational Java web start game demonstrating the relationship between adjacency matrices and graphs.</li>
<li>Open Data Structures - Section 12.1 - AdjacencyMatrix: Representing a Graph by a Matrix, Pat Morin</li>
<li>Café math : Adjacency Matrices of Graphs : Application of the adjacency matrices to the computation generating series of walks.</li></ul>



<!-- 
NewPP limit report
Parsed by mw2313
Cached time: 20221223231225
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.393 seconds
Real time usage: 0.569 seconds
Preprocessor visited node count: 3637/1000000
Post‐expand include size: 71703/2097152 bytes
Template argument size: 4729/2097152 bytes
Highest expansion depth: 16/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 48733/5000000 bytes
Lua time usage: 0.205/10.000 seconds
Lua memory usage: 7258419/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  422.025      1 -total
 39.97%  168.692      1 Template:Reflist
 21.41%   90.362      9 Template:Citation
 17.31%   73.032      1 Template:Short_description
 13.25%   55.939      2 Template:Navbox
 11.44%   48.270      2 Template:Pagetype
  9.86%   41.596      1 Template:Graph_representations
  7.93%   33.479      1 Template:Commons_category
  7.70%   32.513     35 Template:Math
  7.45%   31.437      1 Template:Sister_project
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:244463-0!canonical and timestamp 20221223231224 and revision id 1119322733.
 -->
</div></body>
</html>