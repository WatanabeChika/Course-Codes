<!DOCTYPE html>
<html>
<head>
<title>divide_and_marriage_before_conquest</title>
</head>
<body>
<div class="mw-parser-output">
<p>In computer science, <b>divide and conquer</b> is an algorithm design paradigm. A divide-and-conquer algorithm recursively breaks down a problem into two or more sub-problems of the same or related type, until these become simple enough to be solved directly. The solutions to the sub-problems are then combined to give a solution to the original problem.
</p><p>The divide-and-conquer technique is the basis of efficient algorithms for many problems, such as sorting (e.g., quicksort, merge sort), multiplying large numbers (e.g., the Karatsuba algorithm), finding the closest pair of points, syntactic analysis (e.g., top-down parsers), and computing the discrete Fourier transform (FFT).<sup class="reference" id="cite_ref-1">[1]</sup>
</p><p>Designing efficient divide-and-conquer algorithms can be difficult. As in mathematical induction, it is often necessary to generalize the problem to make it amenable to a recursive solution. The correctness of a divide-and-conquer algorithm is usually proved by mathematical induction, and its computational cost is often determined by solving recurrence relations.
</p>

<h2><span class="mw-headline" id="Divide_and_conquer">Divide and conquer</span><span class="mw-editsection"></span></h2>

<p>The divide-and-conquer paradigm is often used to find an optimal solution of a problem. Its basic idea is to decompose a given problem into two or more similar, but simpler, subproblems, to solve them in turn, and to compose their solutions to solve the given problem. Problems of sufficient simplicity are solved directly. 
For example, to sort a given list of <i>n</i> natural numbers, split it into two lists of about <i>n</i>/2 numbers each, sort each of them in turn, and interleave both results appropriately to obtain the sorted version of the given list (see the picture). This approach is known as the merge sort algorithm.
</p><p>The name "divide and conquer" is sometimes applied to algorithms that reduce each problem to only one sub-problem, such as the binary search algorithm for finding a record in a sorted list (or its analog in numerical computing, the bisection algorithm for root finding).<sup class="reference" id="cite_ref-CormenLeiserson2009_2-0">[2]</sup>  These algorithms can be implemented more efficiently than general divide-and-conquer algorithms; in particular, if they use tail recursion, they can be converted into simple loops.  Under this broad definition, however, every algorithm that uses recursion or loops could be regarded as a "divide-and-conquer algorithm".  Therefore, some authors consider that the name "divide and conquer" should be used only when each problem may generate two or more subproblems.<sup class="reference" id="cite_ref-3">[3]</sup> The name <b>decrease and conquer</b> has been proposed instead for the single-subproblem class.<sup class="reference" id="cite_ref-4">[4]</sup>
</p><p>An important application of divide and conquer is in optimization,<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><span title="An editor has requested that an example be provided. (October 2017)"><span style="font-style:italic; padding-right:0.15em;">example  needed</span></span></i>]</sup> where if the search space is reduced ("pruned") by a constant factor at each step, the overall algorithm has the same asymptotic complexity as the pruning step, with the constant depending on the pruning factor (by summing the geometric series); this is known as prune and search.
</p>
<h2><span class="mw-headline" id="Early_historical_examples">Early historical examples</span><span class="mw-editsection"></span></h2>
<p>Early examples of these algorithms are primarily decreased and conquer – the original problem is successively broken down into <i>single</i> subproblems, and indeed can be solved iteratively.
</p><p>Binary search, a decrease-and-conquer algorithm where the subproblems are of roughly half the original size, has a long history. While a clear description of the algorithm on computers appeared in 1946 in an article by John Mauchly, the idea of using a sorted list of items to facilitate searching dates back at least as far as Babylonia in 200 BC.<sup class="reference" id="cite_ref-Knuth3_5-0">[5]</sup> Another ancient decrease-and-conquer algorithm is the Euclidean algorithm to compute the greatest common divisor of two numbers by reducing the numbers to smaller and smaller equivalent subproblems, which dates to several centuries BC.
</p><p>An early example of a divide-and-conquer algorithm with multiple subproblems is Gauss's 1805 description of what is now called the Cooley–Tukey fast Fourier transform (FFT) algorithm,<sup class="reference" id="cite_ref-Heideman84_6-0">[6]</sup> although he did not analyze its operation count quantitatively, and FFTs did not become widespread until they were rediscovered over a century later.
</p><p>An early two-subproblem D&amp;C algorithm that was specifically developed for computers and properly analyzed is the merge sort algorithm, invented by John von Neumann in 1945.<sup class="reference" id="cite_ref-7">[7]</sup>
</p><p>Another notable example is the algorithm invented by Anatolii A. Karatsuba in 1960<sup class="reference" id="cite_ref-8">[8]</sup> that could multiply two <i>n</i>-digit numbers in <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n^{\log _{2}3})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>n</mi>
<mrow class="MJX-TeXAtom-ORD">
<msub>
<mi>log</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mn>3</mn>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n^{\log _{2}3})}</annotation>
</semantics>
</math></span><img alt="O(n^{\log _{2}3})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/770c7081e94ce7027c145a2f892341605e9b0272" style="vertical-align: -0.838ex; width:9.352ex; height:3.176ex;"/></span> operations (in Big O notation). This algorithm disproved Andrey Kolmogorov's 1956 conjecture that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \Omega (n^{2})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi mathvariant="normal">Ω<!-- Ω --></mi>
<mo stretchy="false">(</mo>
<msup>
<mi>n</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \Omega (n^{2})}</annotation>
</semantics>
</math></span><img alt="\Omega (n^{2})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c14304cd1cb8bf603cb59037b666c5a85cd8e7ae" style="vertical-align: -0.838ex; width:5.936ex; height:3.176ex;"/></span> operations would be required for that task.
</p><p>As another example of a divide-and-conquer algorithm that did not originally involve computers, Donald Knuth gives the method a post office typically uses to route mail: letters are sorted into separate bags for different geographical areas, each of these bags is itself sorted into batches for smaller sub-regions, and so on until they are delivered.<sup class="reference" id="cite_ref-Knuth3_5-1">[5]</sup> This is related to a radix sort, described for punch-card sorting machines as early as 1929.<sup class="reference" id="cite_ref-Knuth3_5-2">[5]</sup>
</p>
<h2><span class="mw-headline" id="Advantages">Advantages</span><span class="mw-editsection"></span></h2>
<h3><span class="mw-headline" id="Solving_difficult_problems">Solving difficult problems</span><span class="mw-editsection"></span></h3>
<p>Divide and conquer is a powerful tool for solving conceptually difficult problems: all it requires is a way of breaking the problem into sub-problems, of solving the trivial cases, and of combining sub-problems to the original problem. Similarly, decrease and conquer only requires reducing the problem to a single smaller problem, such as the classic Tower of Hanoi puzzle, which reduces moving a tower of height <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n}</annotation>
</semantics>
</math></span><img alt="n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;"/></span> to move a tower of height <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n-1}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n-1}</annotation>
</semantics>
</math></span><img alt="n-1" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fbd0b0f32b28f51962943ee9ede4fb34198a2521" style="vertical-align: -0.505ex; width:5.398ex; height:2.343ex;"/></span>.
</p>
<h3><span class="mw-headline" id="Algorithm_efficiency">Algorithm efficiency</span><span class="mw-editsection"></span></h3>
<p>The divide-and-conquer paradigm often helps in the discovery of efficient algorithms.  It was the key, for example, to Karatsuba's fast multiplication method, the quicksort and mergesort algorithms, the Strassen algorithm for matrix multiplication, and fast Fourier transforms.
</p><p>In all these examples, the D&amp;C approach led to an improvement in the asymptotic cost of the solution. For example, if (a) the base cases have constant-bounded size, the work of splitting the problem and combining the partial solutions is proportional to the problem's size <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n}</annotation>
</semantics>
</math></span><img alt="n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;"/></span>, and (b) there is a bounded number <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle p}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>p</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle p}</annotation>
</semantics>
</math></span><img alt="p" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/81eac1e205430d1f40810df36a0edffdc367af36" style="vertical-align: -0.671ex; margin-left: -0.089ex; width:1.259ex; height:2.009ex;"/></span> of sub-problems of size ~ <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n/p}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mi>p</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n/p}</annotation>
</semantics>
</math></span><img alt="n/p" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4b40bd0a1d3c9771117157039602170561e5902f" style="vertical-align: -0.838ex; width:3.727ex; height:2.843ex;"/></span> at each stage, then the cost of the divide-and-conquer algorithm will be <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n\log _{p}n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<msub>
<mi>log</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>p</mi>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n\log _{p}n)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle O(n\log _{p}n)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1ec332e6a1bd01306f96977220505689e4c578ec" style="vertical-align: -1.171ex; width:11.177ex; height:3.176ex;"/></span>.
</p>
<h3><span class="mw-headline" id="Parallelism">Parallelism</span><span class="mw-editsection"></span></h3>
<p>Divide-and-conquer algorithms are naturally adapted for execution in multi-processor machines, especially shared-memory systems where the communication of data between processors does not need to be planned in advance because distinct sub-problems can be executed on different processors.
</p>
<h3><span class="mw-headline" id="Memory_access">Memory access</span><span class="mw-editsection"></span></h3>
<p>Divide-and-conquer algorithms naturally tend to make efficient use of memory caches. The reason is that once a sub-problem is small enough, it and all its sub-problems can, in principle, be solved within the cache, without accessing the slower main memory. An algorithm designed to exploit the cache in this way is called <i>cache-oblivious</i>, because it does not contain the cache size as an explicit parameter.<sup class="reference" id="cite_ref-cahob_9-0">[9]</sup> Moreover, D&amp;C algorithms can be designed for important algorithms (e.g., sorting, FFTs, and matrix multiplication) to be <i>optimal</i> cache-oblivious algorithms–they use the cache in a probably optimal way, in an asymptotic sense, regardless of the cache size. In contrast, the traditional approach to exploiting the cache is <i>blocking</i>, as in loop nest optimization, where the problem is explicitly divided into chunks of the appropriate size—this can also use the cache optimally, but only when the algorithm is tuned for the specific cache sizes of a particular machine.
</p><p>The same advantage exists with regards to other hierarchical storage systems, such as NUMA or virtual memory, as well as for multiple levels of cache: once a sub-problem is small enough, it can be solved within a given level of the hierarchy, without accessing the higher (slower) levels.
</p>
<h3><span class="mw-headline" id="Roundoff_control">Roundoff control</span><span class="mw-editsection"></span></h3>
<p>In computations with rounded arithmetic, e.g. with floating-point numbers, a divide-and-conquer algorithm may yield more accurate results than a superficially equivalent iterative method. For example, one can add <i>N</i> numbers either by a simple loop that adds each datum to a single variable, or by a D&amp;C algorithm called pairwise summation that breaks the data set into two halves, recursively computes the sum of each half, and then adds the two sums.  While the second method performs the same number of additions as the first and pays the overhead of the recursive calls, it is usually more accurate.<sup class="reference" id="cite_ref-10">[10]</sup>
</p>
<h2><span class="mw-headline" id="Implementation_issues">Implementation issues</span><span class="mw-editsection"></span></h2>
<h3><span class="mw-headline" id="Recursion">Recursion</span><span class="mw-editsection"></span></h3>
<p>Divide-and-conquer algorithms are naturally implemented as recursive procedures. In that case, the partial sub-problems leading to the one currently being solved are automatically stored in the procedure call stack. A recursive function is a function that calls itself within its definition.
</p>
<h3><span class="mw-headline" id="Explicit_stack">Explicit stack</span><span class="mw-editsection"></span></h3>
<p>Divide-and-conquer algorithms can also be implemented by a non-recursive program that stores the partial sub-problems in some explicit data structure, such as a stack, queue, or priority queue.  This approach allows more freedom in the choice of the sub-problem that is to be solved next, a feature that is important in some applications — e.g. in breadth-first recursion and the branch-and-bound method for function optimization. This approach is also the standard solution in programming languages that do not provide support for recursive procedures.
</p>
<h3><span class="mw-headline" id="Stack_size">Stack size</span><span class="mw-editsection"></span></h3>
<p>In recursive implementations of D&amp;C algorithms, one must make sure that there is sufficient memory allocated for the recursion stack, otherwise, the execution may fail because of stack overflow.  D&amp;C algorithms that are time-efficient often have relatively small recursion depth.  For example, the quicksort algorithm can be implemented so that it never requires more than <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \log _{2}n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>log</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \log _{2}n}</annotation>
</semantics>
</math></span><img alt="\log _{2}n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d74677fc45e0d926639433586327cbc2982eae89" style="vertical-align: -0.838ex; width:5.808ex; height:2.676ex;"/></span> nested recursive calls to sort <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n}</annotation>
</semantics>
</math></span><img alt="n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;"/></span> items.
</p><p>Stack overflow may be difficult to avoid when using recursive procedures since many compilers assume that the recursion stack is a contiguous area of memory, and some allocate a fixed amount of space for it.  Compilers may also save more information in the recursion stack than is strictly necessary, such as return address, unchanging parameters, and the internal variables of the procedure.  Thus, the risk of stack overflow can be reduced by minimizing the parameters and internal variables of the recursive procedure or by using an explicit stack structure.
</p>
<h3><span class="mw-headline" id="Choosing_the_base_cases">Choosing the base cases</span><span class="mw-editsection"></span></h3>
<p>In any recursive algorithm, there is considerable freedom in the choice of the <i>base cases</i>, the small subproblems that are solved directly in order to terminate the recursion.
</p><p>Choosing the smallest or simplest possible base cases is more elegant and usually leads to simpler programs, because there are fewer cases to consider and they are easier to solve. For example, an FFT algorithm could stop the recursion when the input is a single sample, and the quicksort list-sorting algorithm could stop when the input is the empty list; in both examples, there is only one base case to consider, and it requires no processing.
</p><p>On the other hand, efficiency often improves if the recursion is stopped at relatively large base cases, and these are solved non-recursively, resulting in a hybrid algorithm. This strategy avoids the overhead of recursive calls that do little or no work and may also allow the use of specialized non-recursive algorithms that, for those base cases, are more efficient than explicit recursion. A general procedure for a simple hybrid recursive algorithm is <i>short-circuiting the base case</i>, also known as <i>arm's-length recursion</i>. In this case, whether the next step will result in the base case is checked before the function call, avoiding an unnecessary function call. For example, in a tree, rather than recursing to a child node and then checking whether it is null, checking null before recursing; avoids half the function calls in some algorithms on binary trees. Since a D&amp;C algorithm eventually reduces each problem or sub-problem instance to a large number of base instances, these often dominate the overall cost of the algorithm, especially when the splitting/joining overhead is low. Note that these considerations do not depend on whether recursion is implemented by the compiler or by an explicit stack.
</p><p>Thus, for example, many library implementations of quicksort will switch to a simple loop-based insertion sort (or similar) algorithm once the number of items to be sorted is sufficiently small. Note that, if the empty list were the only base case, sorting a list with <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n}</annotation>
</semantics>
</math></span><img alt="n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;"/></span> entries would entail maximally <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n}</annotation>
</semantics>
</math></span><img alt="n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;"/></span> quicksort calls that would do nothing but return immediately.  Increasing the base cases to lists of size 2 or less will eliminate most of those do-nothing calls, and more generally a base case larger than 2 is typically used to reduce the fraction of time spent in function-call overhead or stack manipulation.
</p><p>Alternatively, one can employ large base cases that still use a divide-and-conquer algorithm, but implement the algorithm for predetermined set of fixed sizes where the algorithm can be completely unrolled into code that has no recursion, loops, or conditionals (related to the technique of partial evaluation).  For example, this approach is used in some efficient FFT implementations, where the base cases are unrolled implementations of divide-and-conquer FFT algorithms for a set of fixed sizes.<sup class="reference" id="cite_ref-fftw_11-0">[11]</sup> Source-code generation methods may be used to produce the large number of separate base cases desirable to implement this strategy efficiently.<sup class="reference" id="cite_ref-fftw_11-1">[11]</sup>
</p><p>The generalized version of this idea is known as recursion "unrolling" or "coarsening", and various techniques have been proposed for automating the procedure of enlarging the base case.<sup class="reference" id="cite_ref-12">[12]</sup>
</p>
<h3><span class="mw-headline" id="Sharing_repeated_subproblems">Sharing repeated subproblems</span><span class="mw-editsection"></span></h3>
<p>For some problems, the branched recursion may end up evaluating the same sub-problem many times over.  In such cases it may be worth identifying and saving the solutions to these overlapping subproblems, a technique is commonly known as memoization.  Followed to the limit, it leads to bottom-up divide-and-conquer algorithms such as dynamic programming and chart parsing.
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1097025294">.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:#f9f9f9}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1}}@media(min-width:720px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}</style>
<ul><li>Akra–Bazzi method</li>
<li>Decomposable aggregation function</li>
<li>Fork–join model</li>
<li>Master theorem (analysis of algorithms)</li>
<li>Mathematical induction</li>
<li>MapReduce</li>
<li>Heuristic (computer science)</li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<p><br/>
</p>

<!-- 
NewPP limit report
Parsed by mw2379
Cached time: 20221224003213
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.260 seconds
Real time usage: 0.389 seconds
Preprocessor visited node count: 1159/1000000
Post‐expand include size: 29808/2097152 bytes
Template argument size: 1691/2097152 bytes
Highest expansion depth: 13/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 32809/5000000 bytes
Lua time usage: 0.148/10.000 seconds
Lua memory usage: 5320678/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  298.258      1 -total
 37.69%  112.422      1 Template:Reflist
 23.91%   71.306      3 Template:Cite_book
 16.14%   48.131      1 Template:Short_description
 14.61%   43.590      1 Template:Algorithmic_paradigms
 13.75%   41.004      1 Template:Navbox
 11.94%   35.621      1 Template:Commons_category
 11.33%   33.797      1 Template:Sister_project
 10.79%   32.176      1 Template:Side_box
  9.53%   28.411      1 Template:Examples
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:201154-0!canonical and timestamp 20221224003212 and revision id 1123297957.
 -->
</div></body>
</html>