<!DOCTYPE html>
<html>
<head>
<title>linked_list</title>
</head>
<body>
<div class="mw-parser-output">
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style>
<style data-mw-deduplicate="TemplateStyles:r1097763485">.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}</style><table class="box-More_footnotes plainlinks metadata ambox ambox-style ambox-More_footnotes" role="presentation"><tbody><tr><td class="mbox-image"></td><td class="mbox-text"></td></tr></tbody></table>

<p>In computer science, a <b>linked list</b> is a linear collection of data elements whose order is not given by their physical placement in memory. Instead, each element points to the next. It is a data structure consisting of a collection of nodes which together represent a sequence. In its most basic form, each node contains: data, and a reference (in other words, a <i>link</i>) to the next node in the sequence. This structure allows for efficient insertion or removal of elements from any position in the sequence during iteration. More complex variants add additional links, allowing more efficient insertion or removal of nodes at arbitrary positions. A drawback of linked lists is that access time is linear (and difficult to pipeline). Faster access, such as random access, is not feasible. Arrays have better cache locality compared to linked lists.
</p><p>Linked lists are among the simplest and most common data structures. They can be used to implement several other common abstract data types, including lists, stacks, queues, associative arrays, and S-expressions, though it is not uncommon to implement those data structures directly without using a linked list as the basis.
</p><p>The principal benefit of a linked list over a conventional array is that the list elements can be easily inserted or removed without reallocation or reorganization of the entire structure because the data items need not be stored contiguously in memory or on disk, while restructuring an array at run-time is a much more expensive operation. Linked lists allow insertion and removal of nodes at any point in the list, and allow doing so with a constant number of operations by keeping the link previous to the link being added or removed in memory during list traversal.
</p><p>On the other hand, since simple linked lists by themselves do not allow random access to the data or any form of efficient indexing, many basic operations—such as obtaining the last node of the list, finding a node that contains a given datum, or locating the place where a new node should be inserted—may require iterating through most or all of the list elements.
</p>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"></span></h2>
<p>Linked lists were developed in 1955–1956, by Allen Newell, Cliff Shaw and Herbert A. Simon at RAND Corporation as the primary data structure for their Information Processing Language. IPL was used by the authors to develop several early artificial intelligence programs, including the Logic Theory Machine, the General Problem Solver, and a computer chess program. Reports on their work appeared in IRE Transactions on Information Theory in 1956, and several conference proceedings from 1957 to 1959, including Proceedings of the Western Joint Computer Conference in 1957 and 1958, and Information Processing (Proceedings of the first UNESCO International Conference on Information Processing) in 1959. The now-classic diagram consisting of blocks representing list nodes with arrows pointing to successive list nodes appears in "Programming the Logic Theory Machine" by Newell and Shaw in Proc. WJCC, February 1957. Newell and Simon were recognized with the ACM Turing Award in 1975 for having "made basic contributions to artificial intelligence, the psychology of human cognition, and list processing".
The problem of machine translation for natural language processing led Victor Yngve at Massachusetts Institute of Technology (MIT) to use linked lists as data structures in his COMIT programming language for computer research in the field of linguistics. A report on this language entitled "A programming language for mechanical translation" appeared in Mechanical Translation in 1958.<sup class="noprint Inline-Template Template-Fact" style="white-space:nowrap;">[<i><span title="This claim needs references to reliable sources. (January 2019)">citation needed</span></i>]</sup>
</p><p>Another early appearance of linked lists was by Hans Peter Luhn who wrote an internal IBM memorandum in January 1953 that suggested the use of linked lists in chained hash tables.<sup class="reference" id="cite_ref-knuth_1-0">[1]</sup>
</p><p>LISP, standing for list processor, was created by John McCarthy in 1958 while he was at MIT and in 1960 he published its design in a paper in the Communications of the ACM, entitled "Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I". One of LISP's major data structures is the linked list.
</p><p>By the early 1960s, the utility of both linked lists and languages which use these structures as their primary data representation was well established. Bert Green of the MIT Lincoln Laboratory published a review article entitled "Computer languages for symbol manipulation" in IRE Transactions on Human Factors in Electronics in March 1961 which summarized the advantages of the linked list approach. A later review article, "A Comparison of list-processing computer languages" by Bobrow and Raphael, appeared in Communications of the ACM in April 1964.
</p><p>Several operating systems developed by Technical Systems Consultants (originally of West Lafayette Indiana, and later of Chapel Hill, North Carolina) used singly linked lists as file structures. A directory entry pointed to the first sector of a file, and succeeding portions of the file were located by traversing pointers. Systems using this technique included Flex (for the Motorola 6800 CPU), mini-Flex (same CPU), and Flex9 (for the Motorola 6809 CPU). A variant developed by TSC for and marketed by Smoke Signal Broadcasting in California, used doubly linked lists in the same manner.
</p><p>The TSS/360 operating system, developed by IBM for the System 360/370 machines, used a double linked list for their file system catalog. The directory structure was similar to Unix, where a directory could contain files and other directories and extend to any depth.
</p>
<h2><span class="mw-headline" id="Basic_concepts_and_nomenclature">Basic concepts and nomenclature</span><span class="mw-editsection"></span></h2>
<p>Each record of a linked list is often called an 'element' or 'node'.
</p><p>The field of each node that contains the address of the next node is usually called the 'next link' or 'next pointer'.  The remaining fields are known as the 'data', 'information', 'value', 'cargo', or 'payload' fields.
</p><p>The 'head' of a list is its first node. The 'tail' of a list may refer either to the rest of the list after the head, or to the last node in the list. In Lisp and some derived languages, the next node may be called the 'cdr' (pronounced <i>could-er</i>) of the list, while the payload of the head node may be called the 'car'.
</p>
<h3><span class="mw-headline" id="Singly_linked_list">Singly linked list</span><span class="mw-editsection"></span></h3>
<p>Singly linked lists contain nodes which have a 'value' field as well as 'next' field, which points to the next node in line of nodes. Operations that can be performed on singly linked lists include insertion, deletion and traversal.
</p>
<p>
The following code demonstrates how to add a new node with the "value" to the end of a singly linked list:</p>
<h3><span class="mw-headline" id="Doubly_linked_list">Doubly linked list</span><span class="mw-editsection"></span></h3>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<p>In a 'doubly linked list', each node contains, besides the next-node link, a second link field pointing to the 'previous' node in the sequence.  The two links may be called 'forward('s') and 'backwards', or 'next' and 'prev'('previous').
</p>

<p>A technique known as XOR-linking allows a doubly linked list to be implemented using a single link field in each node. However, this technique requires the ability to do bit operations on addresses, and therefore may not be available in some high-level languages.
</p><p>Many modern operating systems use doubly linked lists to maintain references to active processes, threads, and other dynamic objects.<sup class="reference" id="cite_ref-:0_2-0">[2]</sup> A common strategy for rootkits to evade detection is to unlink themselves from these lists.<sup class="reference" id="cite_ref-3">[3]</sup>
</p>
<h3><span class="mw-headline" id="Multiply_linked_list">Multiply linked list</span><span class="mw-editsection"></span></h3>
<p>In a 'multiply linked list', each node contains two or more link fields, each field being used to connect the same set of data records in a different order of same set (e.g., by name, by department, by date of birth, etc.). While doubly linked lists can be seen as special cases of multiply linked list, the fact that the two and more orders are opposite to each other leads to simpler and more efficient algorithms, so they are usually treated as a separate case.
</p>
<h3><span class="mw-headline" id="Circular_linked_list">Circular linked list</span><span class="mw-editsection"></span></h3>
<p>In the last node of a list, the link field often contains a null reference, a special value is used to indicate the lack of further nodes. A less common convention is to make it point to the first node of the list; in that case, the list is said to be 'circular' or 'circularly linked'; otherwise, it is said to be 'open' or 'linear'. It is a list where the last pointer points to the first node.
</p>

<p>In the case of a circular doubly linked list, the first node also points to the last node of the list.
</p>
<h3><span class="mw-headline" id="Sentinel_nodes">Sentinel nodes</span><span class="mw-editsection"></span></h3>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<p>In some implementations an extra 'sentinel' or 'dummy' node may be added before the first data record or after the last one. This convention simplifies and accelerates some list-handling algorithms, by ensuring that all links can be safely dereferenced and that every list (even one that contains no data elements) always has a "first" and "last" node.
</p>
<h3><span class="mw-headline" id="Empty_lists">Empty lists</span><span class="mw-editsection"></span></h3>
<p>An empty list is a list that contains no data records. This is usually the same as saying that it has zero nodes. If sentinel nodes are being used, the list is usually said to be empty when it has only sentinel nodes.
</p>
<h3><span class="mw-headline" id="Hash_linking">Hash linking</span><span class="mw-editsection"></span></h3>
<p>The link fields need not be physically part of the nodes. If the data records are stored in an array and referenced by their indices, the link field may be stored in a separate array with the same indices as the data records.
</p>
<h3><span class="mw-headline" id="List_handles">List handles</span><span class="mw-editsection"></span></h3>
<p>Since a reference to the first node gives access to the whole list, that reference is often called the 'address', 'pointer', or 'handle' of the list. Algorithms that manipulate linked lists usually get such handles to the input lists and return the handles to the resulting lists. In fact, in the context of such algorithms, the word "list" often means "list handle". In some situations, however, it may be convenient to refer to a list by a handle that consists of two links, pointing to its first and last nodes.
</p>
<h3><span class="mw-headline" id="Combining_alternatives">Combining alternatives</span><span class="mw-editsection"></span></h3>
<p>The alternatives listed above may be arbitrarily combined in almost every way, so one may have circular doubly linked lists without sentinels, circular singly linked lists with sentinels, etc.
</p>
<h2><span class="mw-headline" id="Tradeoffs">Tradeoffs</span><span class="mw-editsection"></span></h2>
<p>As with most choices in computer programming and design, no method is well suited to all circumstances. A linked list data structure might work well in one case, but cause problems in another. This is a list of some of the common tradeoffs involving linked list structures.
</p>
<h3><span class="mw-headline" id="Linked_lists_vs._dynamic_arrays">Linked lists vs. dynamic arrays</span><span class="mw-editsection"></span></h3>
<table class="wikitable">
<caption>Comparison of list data structures
</caption>
<tbody><tr>
<th rowspan="2">
</th>
<th rowspan="2">Peek <br/>(index)
</th>
<th colspan="3">Mutate (insert or delete) at …
</th>
<th rowspan="2">Excess space, <br/>average
</th></tr>
<tr>
<th>Beginning
</th>
<th>End
</th>
<th>Middle
</th></tr>
<tr>
<td>Linked list
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1), known end element;<br/>Θ(<i>n</i>), unknown end element
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Peek time + <br/>Θ(1)<sup class="reference" id="cite_ref-4">[4]</sup><sup class="reference" id="cite_ref-5">[5]</sup>
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td></tr>
<tr>
<td>Array
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">0
</td></tr>
<tr>
<td>Dynamic array
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1) amortized
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)<sup class="reference" id="cite_ref-6">[6]</sup>
</td></tr>
<tr>
<td>Balanced tree
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log n)
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log n)
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log <i>n</i>)
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log <i>n</i>)
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td></tr>
<tr>
<td>Random-<span class="nowrap">access list</span>
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(log n)<sup class="reference" id="cite_ref-okasakiComparison_7-0">[7]</sup>
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—<sup class="reference" id="cite_ref-okasakiComparison_7-1">[7]</sup>
</td>
<td class="table-na" data-sort-value="" style="background: #ececec; color: #2C2C2C; vertical-align: middle; text-align: center;">—<sup class="reference" id="cite_ref-okasakiComparison_7-2">[7]</sup>
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td></tr>
<tr>
<td>Hashed array tree
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1)
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-yes" style="background:#9EFF9E;vertical-align:middle;text-align:center;">Θ(1) amortized
</td>
<td class="table-no" style="background:#FFC7C7;vertical-align:middle;text-align:center;">Θ(<i>n</i>)
</td>
<td class="table-partial" style="background:#FFB;vertical-align:middle;text-align:center;">Θ(√<i>n</i>)
</td></tr></tbody></table>
<p>A <i>dynamic array</i> is a data structure that allocates all elements contiguously in memory, and keeps a count of the current number of elements. If the space reserved for the dynamic array is exceeded, it is reallocated and (possibly) copied, which is an expensive operation.
</p><p>Linked lists have several advantages over dynamic arrays. Insertion or deletion of an element at a specific point of a list, assuming that we have indexed a pointer to the node (before the one to be removed, or before the insertion point) already, is a constant-time operation (otherwise without this reference it is O(n)), whereas insertion in a dynamic array at random locations will require moving half of the elements on average, and all the elements in the worst case.  While one can "delete" an element from an array in constant time by somehow marking its slot as "vacant", this causes fragmentation that impedes the performance of iteration.
</p><p>Moreover, arbitrarily many elements may be inserted into a linked list, limited only by the total memory available; while a dynamic array will eventually fill up its underlying array data structure and will have to reallocate—an expensive operation, one that may not even be possible if memory is fragmented, although the cost of reallocation can be averaged over insertions, and the cost of an insertion due to reallocation would still be amortized O(1). This helps with appending elements at the array's end, but inserting into (or removing from) middle positions still carries prohibitive costs due to data moving to maintain contiguity. An array from which many elements are removed may also have to be resized in order to avoid wasting too much space.
</p><p>On the other hand, dynamic arrays (as well as fixed-size array data structures) allow constant-time random access, while linked lists allow only sequential access to elements. Singly linked lists, in fact, can be easily traversed in only one direction. This makes linked lists unsuitable for applications where it's useful to look up an element by its index quickly, such as heapsort. Sequential access on arrays and dynamic arrays is also faster than on linked lists on many machines, because they have optimal locality of reference and thus make good use of data caching.
</p><p>Another disadvantage of linked lists is the extra storage needed for references, which often makes them impractical for lists of small data items such as characters or boolean values, because the storage overhead for the links may exceed by a factor of two or more the size of the data. In contrast, a dynamic array requires only the space for the data itself (and a very small amount of control data).<sup class="reference" id="cite_ref-8">[note 1]</sup>  It can also be slow, and with a naïve allocator, wasteful, to allocate memory separately for each new element, a problem generally solved using memory pools.
</p><p>Some hybrid solutions try to combine the advantages of the two representations.  Unrolled linked lists store several elements in each list node, increasing cache performance while decreasing memory overhead for references. CDR coding does both these as well, by replacing references with the actual data referenced, which extends off the end of the referencing record.
</p><p>A good example that highlights the pros and cons of using dynamic arrays vs. linked lists is by implementing a program that resolves the Josephus problem. The Josephus problem is an election method that works by having a group of people stand in a circle. Starting at a predetermined person, one may count around the circle <i>n</i> times. Once the <i>n</i>th person is reached, one should remove them from the circle and have the members close the circle. The process is repeated until only one person is left. That person wins the election. This shows the strengths and weaknesses of a linked list vs. a dynamic array, because if the people are viewed as connected nodes in a circular linked list, then it shows how easily the linked list is able to delete nodes (as it only has to rearrange the links to the different nodes). However, the linked list will be poor at finding the next person to remove and will need to search through the list until it finds that person. A dynamic array, on the other hand, will be poor at deleting nodes (or elements) as it cannot remove one node without individually shifting all the elements up the list by one. However, it is exceptionally easy to find the <i>n</i>th person in the circle by directly referencing them by their position in the array.
</p><p>The list ranking problem concerns the efficient conversion of a linked list representation into an array. Although trivial for a conventional computer, solving this problem by a parallel algorithm is complicated and has been the subject of much research.
</p><p>A balanced tree has similar memory access patterns and space overhead to a linked list while permitting much more efficient indexing, taking O(log n) time instead of O(n) for a random access. However, insertion and deletion operations are more expensive due to the overhead of tree manipulations to maintain balance.  Schemes exist for trees to automatically maintain themselves in a balanced state: AVL trees or red–black trees.
</p>
<h3><span class="mw-headline" id="Singly_linked_linear_lists_vs._other_lists">Singly linked linear lists vs. other lists</span><span class="mw-editsection"></span></h3>
<p>While doubly linked and circular lists have advantages over singly linked linear lists, linear lists offer some advantages that make them preferable in some situations.
</p><p>A singly linked linear list is a recursive data structure, because it contains a pointer to a <i>smaller</i> object of the same type.  For that reason, many operations on singly linked linear lists (such as merging two lists, or enumerating the elements in reverse order) often have very simple recursive algorithms, much simpler than any solution using iterative commands.  While those recursive solutions can be adapted for doubly linked and circularly linked lists, the procedures generally need extra arguments and more complicated base cases.
</p><p>Linear singly linked lists also allow tail-sharing, the use of a common final portion of sub-list as the terminal portion of two different lists. In particular, if a new node is added at the beginning of a list, the former list remains available as the tail of the new one—a simple example of a persistent data structure. Again, this is not true with the other variants: a node may never belong to two different circular or doubly linked lists.
</p><p>In particular, end-sentinel nodes can be shared among singly linked non-circular lists.  The same end-sentinel node may be used for <i>every</i> such list.  In Lisp, for example, every proper list ends with a link to a special node, denoted by <code>nil</code> or <code>()</code>, whose <code>CAR</code> and <code>CDR</code> links point to itself.  Thus a Lisp procedure can safely take the <code>CAR</code> or <code>CDR</code> of <i>any</i> list.
</p><p>The advantages of the fancy variants are often limited to the complexity of the algorithms, not in their efficiency.  A circular list, in particular, can usually be emulated by a linear list together with two variables that point to the first and last nodes, at no extra cost.
</p>
<h3><span class="mw-headline" id="Doubly_linked_vs._singly_linked">Doubly linked vs. singly linked</span><span class="mw-editsection"></span></h3>
<p>Double-linked lists require more space per node (unless one uses XOR-linking), and their elementary operations are more expensive; but they are often easier to manipulate because they allow fast and easy sequential access to the list in both directions. In a doubly linked list, one can insert or delete a node in a constant number of operations given only that node's address. To do the same in a singly linked list, one must have the <i>address of the pointer</i> to that node, which is either the handle for the whole list (in case of the first node) or the link field in the <i>previous</i> node. Some algorithms require access in both directions. On the other hand, doubly linked lists do not allow tail-sharing and cannot be used as persistent data structures.
</p>
<h3><span class="mw-headline" id="Circularly_linked_vs._linearly_linked">Circularly linked vs. linearly linked</span><span class="mw-editsection"></span></h3>
<p>A circularly linked list may be a natural option to represent arrays that are naturally circular, e.g. the corners of a polygon, a pool of buffers that are used and released in FIFO ("first in, first out") order, or a set of processes that should be time-shared in round-robin order. In these applications, a pointer to any node serves as a handle to the whole list.
</p><p>With a circular list, a pointer to the last node gives easy access also to the first node, by following one link. Thus, in applications that require access to both ends of the list (e.g., in the implementation of a queue), a circular structure allows one to handle the structure by a single pointer, instead of two.
</p><p>A circular list can be split into two circular lists, in constant time, by giving the addresses of the last node of each piece. The operation consists in swapping the contents of the link fields of those two nodes.  Applying the same operation to any two nodes in two distinct lists joins the two list into one. This property greatly simplifies some algorithms and data structures, such as the quad-edge and face-edge.
</p><p>The simplest representation for an empty <i>circular</i> list (when such a thing makes sense) is a null pointer, indicating that the list has no nodes.  Without this choice, many algorithms have to test for this special case, and handle it separately.  By contrast, the use of null to denote an empty <i>linear</i> list is more natural and often creates fewer special cases.
</p><p>For some applications, it can be useful to use singly linked lists that can vary between being circular and being linear, or even circular with a linear initial segment. Algorithms for searching or otherwise operating on these have to take precautions to avoid accidentally entering an endless loop. One well-known method is to have a second pointer walking the list at half or double the speed, and if both pointers meet at the same node, you know you found a cycle.
</p>
<h3><span class="mw-headline" id="Using_sentinel_nodes">Using sentinel nodes</span><span class="mw-editsection"></span></h3>
<p>Sentinel node may simplify certain list operations, by ensuring that the next or previous nodes exist for every element, and that even empty lists have at least one node. One may also use a sentinel node at the end of the list, with an appropriate data field, to eliminate some end-of-list tests. For example, when scanning the list looking for a node with a given value <i>x</i>, setting the sentinel's data field to <i>x</i> makes it unnecessary to test for end-of-list inside the loop. Another example is the merging two sorted lists: if their sentinels have data fields set to +∞, the choice of the next output node does not need special handling for empty lists.
</p><p>However, sentinel nodes use up extra space (especially in applications that use many short lists), and they may complicate other operations (such as the creation of a new empty list).
</p><p>However, if the circular list is used merely to simulate a linear list, one may avoid some of this complexity by adding a single sentinel node to every list, between the last and the first data nodes.  With this convention, an empty list consists of the sentinel node alone, pointing to itself via the next-node link.  The list handle should then be a pointer to the last data node, before the sentinel, if the list is not empty; or to the sentinel itself, if the list is empty.
</p><p>The same trick can be used to simplify the handling of a doubly linked linear list, by turning it into a circular doubly linked list with a single sentinel node.  However, in this case, the handle should be a single pointer to the dummy node itself.<sup class="reference" id="cite_ref-9">[8]</sup>
</p>
<h2><span class="mw-headline" id="Linked_list_operations">Linked list operations</span><span class="mw-editsection"></span></h2>
<p>When manipulating linked lists in-place, care must be taken to not use values that you have invalidated in previous assignments. This makes algorithms for inserting or deleting linked list nodes somewhat subtle. This section gives pseudocode for adding or removing nodes from singly, doubly, and circularly linked lists in-place. Throughout we will use <i>null</i> to refer to an end-of-list marker or sentinel, which may be implemented in a number of ways.
</p>
<h3><span class="mw-headline" id="Linearly_linked_lists">Linearly linked lists</span><span class="mw-editsection"></span></h3>
<h4><span class="mw-headline" id="Singly_linked_lists">Singly linked lists</span><span class="mw-editsection"></span></h4>
<p>Our node data structure will have two fields.  We also keep a variable <i>firstNode</i> which always points to the first node in the list, or is <i>null</i> for an empty list.
</p>
<pre><b>record</b> <i>Node</i>
{
    data; <i>// The data being stored in the node</i>
    <i>Node</i> next <i>// A reference</i><sup class="reference" id="cite_ref-:0_2-1">[2]</sup> to the next node, null for last node<i></i>
}
</pre>
<pre><b>record</b> <i>List</i>
{
    <i>Node</i> firstNode <i>// points to first node of list; null for empty list</i>
}
</pre>
<p>Traversal of a singly linked list is simple, beginning at the first node and following each <i>next</i> link until we come to the end:
</p>
<pre>node := list.firstNode
<b>while</b> node not null
    <i>(do something with node.data)</i>
    node := node.next
</pre>
<p>The following code inserts a node after an existing node in a singly linked list. The diagram shows how it works. Inserting a node before an existing one cannot be done directly; instead, one must keep track of the previous node and insert a node after it.
</p>

<pre><b>function</b> insertAfter(<i>Node</i> node, <i>Node</i> newNode) <i>// insert newNode after node</i>
    newNode.next := node.next
    node.next    := newNode
</pre>
<p>Inserting at the beginning of the list requires a separate function. This requires updating <i>firstNode</i>.
</p>
<pre><b>function</b> insertBeginning(<i>List</i> list, <i>Node</i> newNode) <i>// insert node before current first node</i>
    newNode.next   := list.firstNode
    list.firstNode := newNode
</pre>
<p>Similarly, we have functions for removing the node <i>after</i> a given node, and for removing a node from the beginning of the list. The diagram demonstrates the former. To find and remove a particular node, one must again keep track of the previous element.
</p>

<pre><b>function</b> removeAfter(<i>Node</i> node) <i>// remove node past this one</i>
    obsoleteNode := node.next
    node.next := node.next.next
    destroy obsoleteNode
</pre>
<pre><b>function</b> removeBeginning(<i>List</i> list) <i>// remove first node</i>
    obsoleteNode := list.firstNode
    list.firstNode := list.firstNode.next <i>// point past deleted node</i>
    destroy obsoleteNode
</pre>
<p>Notice that <code>removeBeginning()</code> sets <code>list.firstNode</code> to <code>null</code> when removing the last node in the list.
</p><p>Since we can't iterate backwards, efficient <code>insertBefore</code> or <code>removeBefore</code> operations are not possible. Inserting to a list before a specific node requires traversing the list, which would have a worst case running time of O(n).
</p><p>Appending one linked list to another can be inefficient unless a reference to the tail is kept as part of the List structure, because we must traverse the entire first list in order to find the tail, and then append the second list to this.  Thus, if two linearly linked lists are each of length <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n}</annotation>
</semantics>
</math></span><img alt="n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a601995d55609f2d9f5e233e36fbe9ea26011b3b" style="vertical-align: -0.338ex; width:1.395ex; height:1.676ex;"/></span>, list appending has asymptotic time complexity of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n)}</annotation>
</semantics>
</math></span><img alt="O(n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34109fe397fdcff370079185bfdb65826cb5565a" style="vertical-align: -0.838ex; width:4.977ex; height:2.843ex;"/></span>.  In the Lisp family of languages, list appending is provided by the <code>append</code> procedure.
</p><p>Many of the special cases of linked list operations can be eliminated by including a dummy element at the front of the list.  This ensures that there are no special cases for the beginning of the list and renders both <code>insertBeginning()</code> and <code>removeBeginning()</code> unnecessary. In this case, the first useful data in the list will be found at <code>list.<b>firstNode</b>.next</code>.
</p>
<h3><span class="mw-headline" id="Circularly_linked_list">Circularly linked list</span><span class="mw-editsection"></span></h3>
<p>In a circularly linked list, all nodes are linked in a continuous circle, without using <i>null.</i> For lists with a front and a back (such as a queue), one stores a reference to the last node in the list. The <i>next</i> node after the last node is the first node. Elements can be added to the back of the list and removed from the front in constant time.
</p><p>Circularly linked lists can be either singly or doubly linked.
</p><p>Both types of circularly linked lists benefit from the ability to traverse the full list beginning at any given node. This often allows us to avoid storing <i>firstNode</i> and <i>lastNode</i>, although if the list may be empty we need a special representation for the empty list, such as a <i>lastNode</i> variable which points to some node in the list or is <i>null</i> if it's empty; we use such a <i>lastNode</i> here.  This representation significantly simplifies adding and removing nodes with a non-empty list, but empty lists are then a special case.
</p>
<h4><span class="mw-headline" id="Algorithms">Algorithms</span><span class="mw-editsection"></span></h4>
<p>Assuming that <i>someNode</i> is some node in a non-empty circular singly linked list, this code iterates through that list starting with <i>someNode</i>:
</p>
<pre><b>function</b> iterate(someNode)
    <b>if</b> someNode ≠ <b>null</b>
        node := someNode
    <b>do</b>
        do something with node.value
        node := node.next
    <b>while</b> node ≠ someNode
</pre>
<p>Notice that the test "<b>while</b> node ≠ someNode" must be at the end of the loop. If the test was moved to the beginning of the loop, the procedure would fail whenever the list had only one node.
</p><p>This function inserts a node "newNode" into a circular linked list after a given node "node".  If "node" is null, it assumes that the list is empty.
</p>
<pre><b>function</b> insertAfter(<i>Node</i> node, <i>Node</i> newNode)
    <b>if</b> node = <b>null</b>    // assume list is empty
        newNode.next := newNode
    <b>else</b>
        newNode.next := node.next
        node.next := newNode
    update <i>lastNode</i> variable if necessary
</pre>
<p>Suppose that "L" is a variable pointing to the last node of a circular linked list (or null if the list is empty).  To append "newNode" to the <i>end</i> of the list, one may do
</p>
<pre>insertAfter(L, newNode)
L := newNode
</pre>
<p>To insert "newNode" at the <i>beginning</i> of the list, one may do
</p>
<pre>insertAfter(L, newNode)
<b>if</b> L = <b>null</b>
    L := newNode
</pre>
<p>This function inserts a value "newVal" before a given node "node" in O(1) time. We create a new node between "node" and the next node, and then put the value of "node" into that new node, and put "newVal" in "node". Thus, a singly linked circularly linked list with only a <i>firstNode</i> variable can both insert to the front and back in O(1) time.
</p>
<pre><b>function</b> insertBefore(<i>Node</i> node, newVal)
    <b>if</b> node = <b>null</b>    // assume list is empty
        newNode := <b>new</b> Node(data:=newVal, next:=newNode)
    <b>else</b>
        newNode := <b>new</b> Node(data:=node.data, next:=node.next)
        node.data := newVal
        node.next := newNode
    update <i>firstNode</i> variable if necessary
</pre>
<p>This function removes a non-null node from a list of size greater than 1 in O(1) time. It copies data from the next node into the node, and then sets the node's <i>next</i> pointer to skip over the next node.
</p>
<pre><b>function</b> remove(<i>Node</i> node)
    <b>if</b> node ≠ <b>null</b> and size of list &gt; 1
        removedData := node.data
        node.data := node.next.data
        node.next = node.next.next
        <b>return</b> removedData
</pre>
<h3><span class="mw-headline" id="Linked_lists_using_arrays_of_nodes">Linked lists using arrays of nodes</span><span class="mw-editsection"></span></h3>
<p>Languages that do not support any type of reference can still create links by replacing pointers with array indices. The approach is to keep an array of records, where each record has integer fields indicating the index of the next (and possibly previous) node in the array. Not all nodes in the array need be used. If records are also not supported, parallel arrays can often be used instead.
</p><p>As an example, consider the following linked list record that uses arrays instead of pointers:
</p>
<pre><b>record</b> <i>Entry</i> {
    <i>integer</i> next; <i>// index of next entry in array</i>
    <i>integer</i> prev; <i>// previous entry (if double-linked)</i>
    <i>string</i> name;
    <i>real</i> balance;
}
</pre>
<p>A linked list can be built by creating an array of these structures, and an integer variable to store the index of the first element.
</p>
<pre><i>integer</i> listHead
<i>Entry</i> Records[1000]
</pre>
<p>Links between elements are formed by placing the array index of the next (or previous) cell into the Next or Prev field within a given element.  For example:
</p>
<table class="wikitable">
<tbody><tr>
<th>Index
</th>
<th>Next
</th>
<th>Prev
</th>
<th>Name
</th>
<th>Balance
</th></tr>
<tr>
<td>0
</td>
<td>1
</td>
<td>4
</td>
<td>Jones, John
</td>
<td>123.45
</td></tr>
<tr>
<td>1
</td>
<td>−1
</td>
<td>0
</td>
<td>Smith, Joseph
</td>
<td>234.56
</td></tr>
<tr>
<td>2 (listHead)
</td>
<td>4
</td>
<td>−1
</td>
<td>Adams, Adam
</td>
<td>0.00
</td></tr>
<tr>
<td>3
</td>
<td>
</td>
<td>
</td>
<td>Ignore, Ignatius
</td>
<td>999.99
</td></tr>
<tr>
<td>4
</td>
<td>0
</td>
<td>2
</td>
<td>Another, Anita
</td>
<td>876.54
</td></tr>
<tr>
<td>5
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td></tr>
<tr>
<td>6
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td></tr>
<tr>
<td>7
</td>
<td>
</td>
<td>
</td>
<td>
</td>
<td>
</td></tr></tbody></table>
<p>In the above example, <code>ListHead</code> would be set to 2, the location of the first entry in the list.  Notice that entry 3 and 5 through 7 are not part of the list.  These cells are available for any additions to the list.  By creating a <code>ListFree</code> integer variable, a free list could be created to keep track of what cells are available.  If all entries are in use, the size of the array would have to be increased or some elements would have to be deleted before new entries could be stored in the list.
</p><p>The following code would traverse the list and display names and account balance:
</p>
<pre>i := listHead
<b>while</b> i ≥ 0 <i>// loop through the list</i>
    print i, Records[i].name, Records[i].balance <i>// print entry</i>
    i := Records[i].next
</pre>
<p>When faced with a choice, the advantages of this approach include:
</p>
<ul><li>The linked list is relocatable, meaning it can be moved about in memory at will, and it can also be quickly and directly serialized for storage on disk or transfer over a network.</li>
<li>Especially for a small list, array indexes can occupy significantly less space than a full pointer on many architectures.</li>
<li>Locality of reference can be improved by keeping the nodes together in memory and by periodically rearranging them, although this can also be done in a general store.</li>
<li>Naïve dynamic memory allocators can produce an excessive amount of overhead storage for each node allocated; almost no allocation overhead is incurred per node in this approach.</li>
<li>Seizing an entry from a pre-allocated array is faster than using dynamic memory allocation for each node, since dynamic memory allocation typically requires a search for a free memory block of the desired size.</li></ul>
<p>This approach has one main disadvantage, however: it creates and manages a private memory space for its nodes. This leads to the following issues:
</p>
<ul><li>It increases complexity of the implementation.</li>
<li>Growing a large array when it is full may be difficult or impossible, whereas finding space for a new linked list node in a large, general memory pool may be easier.</li>
<li>Adding elements to a dynamic array will occasionally (when it is full) unexpectedly take linear (O(n)) instead of constant time (although it's still an amortized constant).</li>
<li>Using a general memory pool leaves more memory for other data if the list is smaller than expected or if many nodes are freed.</li></ul>
<p>For these reasons, this approach is mainly used for languages that do not support dynamic memory allocation. These disadvantages are also mitigated if the maximum size of the list is known at the time the array is created.
</p>
<h2><span class="mw-headline" id="Language_support">Language support</span><span class="mw-editsection"></span></h2>
<p>Many programming languages such as Lisp and Scheme have singly linked lists built in. In many functional languages, these lists are constructed from nodes, each called a <i>cons</i> or <i>cons cell</i>. The cons has two fields: the <i>car</i>, a reference to the data for that node, and the <i>cdr</i>, a reference to the next node. Although cons cells can be used to build other data structures, this is their primary purpose.
</p><p>In languages that support abstract data types or templates, linked list ADTs or templates are available for building linked lists.  In other languages, linked lists are typically built using references together with records.
</p>
<h2><span class="mw-headline" id="Internal_and_external_storage">Internal and external storage</span><span class="mw-editsection"></span></h2>
<p>When constructing a linked list, one is faced with the choice of whether to store the data of the list directly in the linked list nodes, called <i>internal storage</i>, or merely to store a reference to the data, called <i>external storage</i>. Internal storage has the advantage of making access to the data more efficient, requiring less storage overall, having better locality of reference, and simplifying memory management for the list (its data is allocated and deallocated at the same time as the list nodes).
</p><p>External storage, on the other hand, has the advantage of being more generic, in that the same data structure and machine code can be used for a linked list no matter what the size of the data is. It also makes it easy to place the same data in multiple linked lists. Although with internal storage the same data can be placed in multiple lists by including multiple <i>next</i> references in the node data structure, it would then be necessary to create separate routines to add or delete cells based on each field.  It is possible to create additional linked lists of elements that use internal storage by using external storage, and having the cells of the additional linked lists store references to the nodes of the linked list containing the data.
</p><p>In general, if a set of data structures needs to be included in linked lists, external storage is the best approach.  If a set of data structures need to be included in only one linked list, then internal storage is slightly better, unless a generic linked list package using external storage is available.  Likewise, if different sets of data that can be stored in the same data structure are to be included in a single linked list, then internal storage would be fine.
</p><p>Another approach that can be used with some languages involves having different data structures, but all have the initial fields, including the <i>next</i> (and <i>prev</i> if double linked list) references in the same location.  After defining separate structures for each type of data, a generic structure can be defined that contains the minimum amount of data shared by all the other structures and contained at the top (beginning) of the structures.  Then generic routines can be created that use the minimal structure to perform linked list type operations, but separate routines can then handle the specific data.  This approach is often used in message parsing routines, where several types of messages are received, but all start with the same set of fields, usually including a field for message type.  The generic routines are used to add new messages to a queue when they are received, and remove them from the queue in order to process the message.  The message type field is then used to call the correct routine to process the specific type of message.
</p>
<h3><span class="mw-headline" id="Example_of_internal_and_external_storage">Example of internal and external storage</span><span class="mw-editsection"></span></h3>
<p>Suppose you wanted to create a linked list of families and their members.  Using internal storage, the structure might look like the following:
</p>
<pre><b>record</b> <i>member</i> { <i>// member of a family</i>
    <i>member</i> next;
    <i>string</i> firstName;
    <i>integer</i> age;
}
<b>record</b> <i>family</i> { <i>// the family itself</i>
    <i>family</i> next;
    <i>string</i> lastName;
    <i>string</i> address;
    <i>member</i> members <i>// head of list of members of this family</i>
}
</pre>
<p>To print a complete list of families and their members using internal storage, we could write:
</p>
<pre>aFamily := Families <i>// start at head of families list</i>
<b>while</b> aFamily ≠ <b>null</b> <i>// loop through list of families</i>
    print information about family
    aMember := aFamily.members <i>// get head of list of this family's members</i>
    <b>while</b> aMember ≠ <b>null</b> <i>// loop through list of members</i>
        print information about member
        aMember := aMember.next
    aFamily := aFamily.next
</pre>
<p>Using external storage, we would create the following structures:
</p>
<pre><b>record</b> <i>node</i> { <i>// generic link structure</i>
    <i>node</i> next;
    <i>pointer</i> data <i>// generic pointer for data at node</i>
}
<b>record</b> <i>member</i> { <i>// structure for family member</i>
    <i>string</i> firstName;
    <i>integer</i> age
}
<b>record</b> <i>family</i> { <i>// structure for family</i>
    <i>string</i> lastName;
    <i>string</i> address;
    <i>node</i> members <i>// head of list of members of this family</i>
}
</pre>
<p>To print a complete list of families and their members using external storage, we could write:
</p>
<pre>famNode := Families <i>// start at head of families list</i>
<b>while</b> famNode ≠ <b>null</b> <i>// loop through list of families</i>
    aFamily := (family) famNode.data <i>// extract family from node</i>
    print information about family
    memNode := aFamily.members <i>// get list of family members</i>
    <b>while</b> memNode ≠ <b>null</b> <i>// loop through list of members</i>
        aMember := (member)memNode.data <i>// extract member from node</i>
        print information about member
        memNode := memNode.next
    famNode := famNode.next
</pre>
<p>Notice that when using external storage, an extra step is needed to extract the record from the node and cast it into the proper data type.  This is because both the list of families and the list of members within the family are stored in two linked lists using the same data structure (<i>node</i>), and this language does not have parametric types.
</p><p>As long as the number of families that a member can belong to is known at compile time, internal storage works fine. If, however, a member needed to be included in an arbitrary number of families, with the specific number known only at run time, external storage would be necessary.
</p>
<h3><span class="mw-headline" id="Speeding_up_search">Speeding up search</span><span class="mw-editsection"></span></h3>
<p>Finding a specific element in a linked list, even if it is sorted, normally requires O(<i>n</i>) time (linear search).  This is one of the primary disadvantages of linked lists over other data structures.  In addition to the variants discussed above, below are two simple ways to improve search time.
</p><p>In an unordered list, one simple heuristic for decreasing average search time is the <i>move-to-front heuristic</i>, which simply moves an element to the beginning of the list once it is found. This scheme, handy for creating simple caches, ensures that the most recently used items are also the quickest to find again.
</p><p>Another common approach is to "index" a linked list using a more efficient external data structure. For example, one can build a red–black tree or hash table whose elements are references to the linked list nodes. Multiple such indexes can be built on a single list. The disadvantage is that these indexes may need to be updated each time a node is added or removed (or at least, before that index is used again).
</p>
<h3><span class="mw-headline" id="Random-access_lists">Random-access lists</span><span class="mw-editsection"></span></h3>
<p>A random-access list is a list with support for fast random access to read or modify any element in the list.<sup class="reference" id="cite_ref-okasaki_10-0">[9]</sup> One possible implementation is a skew binary random-access list using the skew binary number system, which involves a list of trees with special properties; this allows worst-case constant time head/cons operations, and worst-case logarithmic time random access to an element by index.<sup class="reference" id="cite_ref-okasaki_10-1">[9]</sup> Random-access lists can be implemented as persistent data structures.<sup class="reference" id="cite_ref-okasaki_10-2">[9]</sup>
</p><p>Random-access lists can be viewed as immutable linked lists in that they likewise support the same O(1) head and tail operations.<sup class="reference" id="cite_ref-okasaki_10-3">[9]</sup>
</p><p>A simple extension to random-access lists is the min-list, which provides an additional operation that yields the minimum element in the entire list in constant time (without<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><span title="The text near this tag may need clarification or removal of jargon. (October 2011)">clarification needed</span></i>]</sup> mutation complexities).<sup class="reference" id="cite_ref-okasaki_10-4">[9]</sup>
</p>
<h2><span class="mw-headline" id="Related_data_structures">Related data structures</span><span class="mw-editsection"></span></h2>
<p>Both stacks and queues are often implemented using linked lists, and simply restrict the type of operations which are supported.
</p><p>The skip list is a linked list augmented with layers of pointers for quickly jumping over large numbers of elements, and then descending to the next layer.  This process continues down to the bottom layer, which is the actual list.
</p><p>A binary tree can be seen as a type of linked list where the elements are themselves linked lists of the same nature. The result is that each node may include a reference to the first node of one or two other linked lists, which, together with their contents, form the subtrees below that node.
</p><p>An unrolled linked list is a linked list in which each node contains an array of data values. This leads to improved cache performance, since more list elements are contiguous in memory, and reduced memory overhead, because less metadata needs to be stored for each element of the list.
</p><p>A hash table may use linked lists to store the chains of items that hash to the same position in the hash table.
</p><p>A heap shares some of the ordering properties of a linked list, but is almost always implemented using an array. Instead of references from node to node, the next and previous data indexes are calculated using the current data's index.
</p><p>A self-organizing list rearranges its nodes based on some heuristic which reduces search times for data retrieval by keeping commonly accessed nodes at the head of the list.
</p>
<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<link href="mw-data:TemplateStyles:r1011085734" rel="mw-deduplicated-inline-style"/>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"></span></h2>
<ul><li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation web cs1">Juan, Angel (2006). "Ch20 –Data Structures; ID06 - PROGRAMMING with JAVA (slide part of the book 'Big Java', by CayS. Horstmann)" <span class="cs1-format">(PDF)</span>. p. 3. Archived from the original <span class="cs1-format">(PDF)</span> on 2012-01-06<span class="reference-accessdate">. Retrieved <span class="nowrap">2011-07-10</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Ch20+%E2%80%93Data+Structures%3B+ID06+-+PROGRAMMING+with+JAVA+%28slide+part+of+the+book+%27Big+Java%27%2C+by+CayS.+Horstmann%29&amp;rft.pages=3&amp;rft.date=2006&amp;rft.aulast=Juan&amp;rft.aufirst=Angel&amp;rft_id=http%3A%2F%2Fwww.uoc.edu%2Fin3%2Femath%2Fdocs%2Fjava%2Fch20.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation web cs1">Black, Paul E. (2004-08-16).  Pieterse, Vreda; Black, Paul E. (eds.). "linked list". <i>Dictionary of Algorithms and Data Structures</i>. National Institute of Standards and Technology<span class="reference-accessdate">. Retrieved <span class="nowrap">2004-12-14</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Dictionary+of+Algorithms+and+Data+Structures&amp;rft.atitle=linked+list&amp;rft.date=2004-08-16&amp;rft.aulast=Black&amp;rft.aufirst=Paul+E.&amp;rft_id=http%3A%2F%2Fnist.gov%2Fdads%2FHTML%2FlinkedList.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation book cs1">Antonakos, James L.; Mansfield, Kenneth C. Jr. (1999). <i>Practical Data Structures Using C/C++</i>. Prentice-Hall. pp. 165–190. ISBN <bdi>0-13-280843-9</bdi>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Practical+Data+Structures+Using+C%2FC%2B%2B&amp;rft.pages=165-190&amp;rft.pub=Prentice-Hall&amp;rft.date=1999&amp;rft.isbn=0-13-280843-9&amp;rft.aulast=Antonakos&amp;rft.aufirst=James+L.&amp;rft.au=Mansfield%2C+Kenneth+C.+Jr.&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Fpracticaldatastr0000anto%2Fpage%2F165&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation book cs1">Collins, William J. (2005) [2002]. <i>Data Structures and the Java Collections Framework</i>. New York: McGraw Hill. pp. 239–303. ISBN <bdi>0-07-282379-8</bdi>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Data+Structures+and+the+Java+Collections+Framework&amp;rft.place=New+York&amp;rft.pages=239-303&amp;rft.pub=McGraw+Hill&amp;rft.date=2005&amp;rft.isbn=0-07-282379-8&amp;rft.aulast=Collins&amp;rft.aufirst=William+J.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation book cs1">Cormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2003). <i>Introduction to Algorithms</i>. MIT Press. pp. 205–213, 501–505. ISBN <bdi>0-262-03293-7</bdi>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Introduction+to+Algorithms&amp;rft.pages=205-213%2C+501-505&amp;rft.pub=MIT+Press&amp;rft.date=2003&amp;rft.isbn=0-262-03293-7&amp;rft.aulast=Cormen&amp;rft.aufirst=Thomas+H.&amp;rft.au=Leiserson%2C+Charles+E.&amp;rft.au=Rivest%2C+Ronald+L.&amp;rft.au=Stein%2C+Clifford&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation book cs1">Cormen, Thomas H.; Leiserson, Charles E.; Rivest, Ronald L.; Stein, Clifford (2001). "10.2: Linked lists". <i>Introduction to Algorithms</i> (2nd ed.). MIT Press. pp. 204–209. ISBN <bdi>0-262-03293-7</bdi>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=10.2%3A+Linked+lists&amp;rft.btitle=Introduction+to+Algorithms&amp;rft.pages=204-209&amp;rft.edition=2nd&amp;rft.pub=MIT+Press&amp;rft.date=2001&amp;rft.isbn=0-262-03293-7&amp;rft.aulast=Cormen&amp;rft.aufirst=Thomas+H.&amp;rft.au=Leiserson%2C+Charles+E.&amp;rft.au=Rivest%2C+Ronald+L.&amp;rft.au=Stein%2C+Clifford&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1">Green, Bert F. Jr. (1961). "Computer Languages for Symbol Manipulation". <i>IRE Transactions on Human Factors in Electronics</i> (2): 3–8. doi:10.1109/THFE2.1961.4503292.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=IRE+Transactions+on+Human+Factors+in+Electronics&amp;rft.atitle=Computer+Languages+for+Symbol+Manipulation&amp;rft.issue=2&amp;rft.pages=3-8&amp;rft.date=1961&amp;rft_id=info%3Adoi%2F10.1109%2FTHFE2.1961.4503292&amp;rft.aulast=Green&amp;rft.aufirst=Bert+F.+Jr.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1">McCarthy, John (1960). "Recursive Functions of Symbolic Expressions and Their Computation by Machine, Part I". <i>Communications of the ACM</i>. <b>3</b> (4): 184. doi:10.1145/367177.367199. S2CID 1489409.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=Recursive+Functions+of+Symbolic+Expressions+and+Their+Computation+by+Machine%2C+Part+I&amp;rft.volume=3&amp;rft.issue=4&amp;rft.pages=184&amp;rft.date=1960&amp;rft_id=info%3Adoi%2F10.1145%2F367177.367199&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A1489409%23id-name%3DS2CID&amp;rft.aulast=McCarthy&amp;rft.aufirst=John&amp;rft_id=http%3A%2F%2Fwww-formal.stanford.edu%2Fjmc%2Frecursive.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation book cs1">Knuth, Donald (1997). "2.2.3-2.2.5". <i>Fundamental Algorithms</i> (3rd ed.). Addison-Wesley. pp. 254–298. ISBN <bdi>0-201-89683-4</bdi>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=2.2.3-2.2.5&amp;rft.btitle=Fundamental+Algorithms&amp;rft.pages=254-298&amp;rft.edition=3rd&amp;rft.pub=Addison-Wesley&amp;rft.date=1997&amp;rft.isbn=0-201-89683-4&amp;rft.aulast=Knuth&amp;rft.aufirst=Donald&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1">Newell, Allen; Shaw, F. C. (1957). "Programming the Logic Theory Machine". <i>Proceedings of the Western Joint Computer Conference</i>: 230–240.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+Western+Joint+Computer+Conference&amp;rft.atitle=Programming+the+Logic+Theory+Machine&amp;rft.pages=230-240&amp;rft.date=1957&amp;rft.aulast=Newell&amp;rft.aufirst=Allen&amp;rft.au=Shaw%2C+F.+C.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation web cs1">Parlante, Nick (2001). "Linked list basics" <span class="cs1-format">(PDF)</span>. Stanford University<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-21</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Linked+list+basics&amp;rft.pub=Stanford+University&amp;rft.date=2001&amp;rft.aulast=Parlante&amp;rft.aufirst=Nick&amp;rft_id=http%3A%2F%2Fcslibrary.stanford.edu%2F103%2FLinkedListBasics.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation book cs1">Sedgewick, Robert (1998). <span class="cs1-lock-registration" title="Free registration required"><i>Algorithms in C</i></span>. Addison Wesley. pp. 90–109. ISBN <bdi>0-201-31452-5</bdi>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Algorithms+in+C&amp;rft.pages=90-109&amp;rft.pub=Addison+Wesley&amp;rft.date=1998&amp;rft.isbn=0-201-31452-5&amp;rft.aulast=Sedgewick&amp;rft.aufirst=Robert&amp;rft_id=https%3A%2F%2Farchive.org%2Fdetails%2Falgorithmsinc00sedg%2Fpage%2F90&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation book cs1">Shaffer, Clifford A. (1998). <i>A Practical Introduction to Data Structures and Algorithm Analysis</i>. New Jersey: Prentice Hall. pp. 77–102. ISBN <bdi>0-13-660911-2</bdi>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=A+Practical+Introduction+to+Data+Structures+and+Algorithm+Analysis&amp;rft.place=New+Jersey&amp;rft.pages=77-102&amp;rft.pub=Prentice+Hall&amp;rft.date=1998&amp;rft.isbn=0-13-660911-2&amp;rft.aulast=Shaffer&amp;rft.aufirst=Clifford+A.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1">Wilkes, Maurice Vincent (1964). "An Experiment with a Self-compiling Compiler for a Simple List-Processing Language". <i>Annual Review in Automatic Programming</i>. Pergamon Press. <b>4</b> (1): 1. doi:10.1016/0066-4138(64)90013-8.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Annual+Review+in+Automatic+Programming&amp;rft.atitle=An+Experiment+with+a+Self-compiling+Compiler+for+a+Simple+List-Processing+Language&amp;rft.volume=4&amp;rft.issue=1&amp;rft.pages=1&amp;rft.date=1964&amp;rft_id=info%3Adoi%2F10.1016%2F0066-4138%2864%2990013-8&amp;rft.aulast=Wilkes&amp;rft.aufirst=Maurice+Vincent&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1">Wilkes, Maurice Vincent (1964). "Lists and Why They are Useful". <i>Proceeds of the ACM National Conference, Philadelphia 1964</i>. ACM (P–64): F1–1.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceeds+of+the+ACM+National+Conference%2C+Philadelphia+1964&amp;rft.atitle=Lists+and+Why+They+are+Useful&amp;rft.issue=P%E2%80%9364&amp;rft.pages=F1-1&amp;rft.date=1964&amp;rft.aulast=Wilkes&amp;rft.aufirst=Maurice+Vincent&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation web cs1">Shanmugasundaram, Kulesh (2005-04-04). "Linux Kernel Linked List Explained"<span class="reference-accessdate">. Retrieved <span class="nowrap">2009-09-21</span></span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Linux+Kernel+Linked+List+Explained&amp;rft.date=2005-04-04&amp;rft.aulast=Shanmugasundaram&amp;rft.aufirst=Kulesh&amp;rft_id=http%3A%2F%2Fisis.poly.edu%2Fkulesh%2Fstuff%2Fsrc%2Fklist%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ALinked+list"></span></li></ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1097025294">.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:#f9f9f9}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1}}@media(min-width:720px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}</style>
<ul><li>Description from the Dictionary of Algorithms and Data Structures</li>
<li>Introduction to Linked Lists, Stanford University Computer Science Library</li>
<li>Linked List Problems, Stanford University Computer Science Library</li>
<li>Open Data Structures - Chapter 3 - Linked Lists, Pat Morin</li>
<li>Patent for the idea of having nodes which are in several linked lists simultaneously (note that this technique was widely used for many decades before the patent was granted)</li></ul>


<!-- 
NewPP limit report
Parsed by mw2406
Cached time: 20221223235442
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.457 seconds
Real time usage: 0.627 seconds
Preprocessor visited node count: 2435/1000000
Post‐expand include size: 71596/2097152 bytes
Template argument size: 2627/2097152 bytes
Highest expansion depth: 13/100
Expensive parser function count: 8/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 67196/5000000 bytes
Lua time usage: 0.269/10.000 seconds
Lua memory usage: 7151049/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  487.196      1 -total
 24.12%  117.496      2 Template:Reflist
 22.47%  109.492     10 Template:Cite_book
 11.68%   56.917      1 Template:More_footnotes_needed
 10.78%   52.502      1 Template:Short_description
 10.48%   51.079      1 Template:Ambox
  8.30%   40.460      1 Template:Data_structures
  8.16%   39.769      1 Template:Commons_category
  7.94%   38.683      1 Template:Navbox
  7.74%   37.723      1 Template:Sister_project
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:18167-0!canonical and timestamp 20221223235442 and revision id 1121408648.
 -->
</div></body>
</html>