<!DOCTYPE html>
<html>
<head>
<title>pointer_jumping</title>
</head>
<body>
<div class="mw-parser-output"><style data-mw-deduplicate="TemplateStyles:r1097763485">.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}</style><table class="box-More_citations_needed plainlinks metadata ambox ambox-content ambox-Refimprove" role="presentation"><tbody><tr><td class="mbox-image"></td><td class="mbox-text"></td></tr></tbody></table>
<p><b>Pointer jumping</b> or <b>path doubling</b> is a design technique for parallel algorithms that operate on pointer structures, such as linked lists and directed graphs. Pointer jumping allows an algorithm to follow paths with a time complexity that is logarithmic with respect to the length of the longest path. It does this by "jumping" to the end of the path computed by neighbors.
</p><p>The basic operation of pointer jumping is to replace each neighbor in a pointer structure with its neighbor's neighbor. In each step of the algorithm, this replacement is done for all nodes in the data structure, which can be done independently in parallel. In the next step when a neighbor's neighbor is followed, the neighbor's path already followed in the previous step is added to the node's followed path in a single step. Thus, each step effectively doubles the distance traversed by the explored paths.
</p><p>Pointer jumping is best understood by looking at simple examples such as list ranking and root finding.
</p>

<h2><span class="mw-headline" id="List_ranking">List ranking</span><span class="mw-editsection"></span></h2>
<p>One of the simpler tasks that can be solved by a pointer jumping algorithm is the <i>list ranking</i> problem. This problem is defined as follows: given a linked list of <span class="texhtml mvar" style="font-style:italic;">N</span> nodes, find the distance (measured in the number of nodes) of each node to the end of the list. The distance <style data-mw-deduplicate="TemplateStyles:r886049734">.mw-parser-output .monospaced{font-family:monospace,monospace}</style><span class="monospaced">d(n)</span> is defined as follows, for nodes <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">n</span> that point to their successor by a pointer called <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">next</span>:
</p>
<ul><li>If <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">n.next</span> is <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">nil</span>, then <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">d(n) = 0</span>.</li>
<li>For any other node, <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">d(n) = d(n.next) + 1</span>.</li></ul>
<p>This problem can easily be solved in linear time on a sequential machine, but a parallel algorithm can do better: given <span class="texhtml mvar" style="font-style:italic;">n</span> processors, the problem can be solved in logarithmic time, <span class="texhtml"><i>O</i>(log <i>N</i>)</span>, by the following pointer jumping algorithm:<sup class="reference" id="cite_ref-clrs_1-0">[1]</sup><sup class="reference nowrap"><span title="Page / location: 693">: 693 </span></sup>
</p>

<p>The pointer jumping occurs in the last line of the algorithm, where each node's <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">next</span> pointer is reset to skip the node's direct successor. It is assumed, as in common in the PRAM model of computation, that memory access are performed in lock-step, so that each <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">n.next.next</span> memory fetch is performed before each <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">n.next</span> memory store; otherwise, processors may clobber each other's data, producing inconsistencies.<sup class="reference" id="cite_ref-clrs_1-1">[1]</sup><sup class="reference nowrap"><span title="Page / location: 694">: 694 </span></sup>
</p><p>The following diagram follows how the parallel list ranking algorithm uses pointer jumping for a linked list with 11 elements. As the algorithm describes, the first iteration starts initialized with all ranks set to 1 except those with a null pointer for <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">next</span>. The first iteration looks at immediate neighbors. Each subsequent iteration jumps twice as far as the previous.
</p><p><img alt="An example of performing the parallel pointer jumping technique to compute list ranking." data-file-height="324" data-file-width="512" decoding="async" height="324" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/50/PointerJumpingListRanking.svg/512px-PointerJumpingListRanking.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/50/PointerJumpingListRanking.svg/768px-PointerJumpingListRanking.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/50/PointerJumpingListRanking.svg/1024px-PointerJumpingListRanking.svg.png 2x" width="512"/>
</p><p>Analyzing the algorithm yields a logarithmic running time. The initialization loop takes constant time, because each of the <span class="texhtml mvar" style="font-style:italic;">N</span> processors performs a constant amount of work, all in parallel. The inner loop of the main loop also takes constant time, as does (by assumption) the termination check for the loop, so the running time is determined by how often this inner loop is executed. Since the pointer jumping in each iteration splits the list into two parts, one consisting of the "odd" elements and one of the "even" elements, the length of the list pointed to by each processor's <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">n</span> is halved in each iteration, which can be done at most  <span class="texhtml"><i>O</i>(log <i>N</i>)</span> time before each list has a length of at most one.<sup class="reference" id="cite_ref-clrs_1-2">[1]</sup><sup class="reference nowrap"><span title="Page / location: 694–695">: 694–695 </span></sup>
</p>
<h2><span class="mw-headline" id="Root_finding">Root finding</span><span class="mw-editsection"></span></h2>
<link href="mw-data:TemplateStyles:r1097763485" rel="mw-deduplicated-inline-style"/><table class="box-Unreferenced_section plainlinks metadata ambox ambox-content ambox-Unreferenced" role="presentation"><tbody><tr><td class="mbox-image"></td><td class="mbox-text"></td></tr></tbody></table>
<p>Following a path in a graph is an inherently serial operation, but pointer jumping reduces the total amount of work by following all paths simultaneously and sharing results among dependent operations. Pointer jumping iterates and finds a <i>successor</i> — a vertex closer to the tree root — each time. By following successors computed for other vertices, the traversal down each path can be doubled every iteration, which means that the tree roots can be found in logarithmic time.
</p><p>Pointer doubling operates on an array <code>successor</code> with an entry for every vertex in the graph. Each <code>successor[<i>i</i>]</code> is initialized with the parent index of vertex <code><i>i</i></code> if that vertex is not a root or to <code><i>i</i></code> itself if that vertex is a root. At each iteration, each successor is updated to its successor's successor. The root is found when the successor's successor points to itself.
</p><p>The following pseudocode demonstrates the algorithm.
</p>
<pre><b>algorithm</b>
    <b>Input:</b> An array parent representing a forest of trees. parent[i] is the parent of vertex i or itself for a root
    <b>Output:</b> An array containing the root ancestor for every vertex

    <b>for</b> <i>i</i> ← 1 <b>to</b> length(parent) <b>do in parallel</b>
        successor[<i>i</i>] ← parent[<i>i</i>]
    <b>while</b> true
        <b>for</b> <i>i</i> ← 1 <b>to</b> length(successor) <b>do in parallel</b>
            successor_next[<i>i</i>] ← successor[successor[<i>i</i>]]
        <b>if</b> successor_next = successor <b>then</b>
            break
        <b>for</b> <i>i</i> ← 1 <b>to</b> length(successor) <b>do in parallel</b>
            successor[<i>i</i>] ← successor_next[<i>i</i>]
    <b>return</b> successor
</pre>
<p>The following image provides an example of using pointer jumping on a small forest. On each iteration the successor points to the vertex following one more successor. After two iterations, every vertex points to its root node.
</p><p><img alt="Pointer jumping: example execution" data-file-height="281" data-file-width="701" decoding="async" height="281" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Pointer_Jumping_Example.svg/701px-Pointer_Jumping_Example.svg.png" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Pointer_Jumping_Example.svg/1052px-Pointer_Jumping_Example.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/57/Pointer_Jumping_Example.svg/1402px-Pointer_Jumping_Example.svg.png 2x" width="701"/>
</p>
<h2><span class="mw-headline" id="History_and_examples">History and examples</span><span class="mw-editsection"></span></h2>
<p>Although the name pointer jumping would come later, JáJá<sup class="reference" id="cite_ref-JaJa_2-0">[2]</sup><sup class="reference nowrap"><span title="Page / location: 88">: 88 </span></sup> attributes the first uses of the technique in early parallel graph algorithms<sup class="reference" id="cite_ref-3">[3]</sup><sup class="reference" id="cite_ref-4">[4]</sup><sup class="reference nowrap"><span title="Page / location: 43">: 43 </span></sup> and list ranking.<sup class="reference" id="cite_ref-Wylie_5-0">[5]</sup> The technique has been described with other names such as shortcutting,<sup class="reference" id="cite_ref-Shiloach_6-0">[6]</sup><sup class="reference" id="cite_ref-Tarjan_7-0">[7]</sup> but by the 1990s textbooks on parallel algorithms consistently used the term pointer jumping.<sup class="reference" id="cite_ref-JaJa_2-1">[2]</sup><sup class="reference nowrap"><span title="Page / location: 52–56">: 52–56 </span></sup><sup class="reference" id="cite_ref-clrs_1-3">[1]</sup><sup class="reference nowrap"><span title="Page / location: 692–701">: 692–701 </span></sup><sup class="reference" id="cite_ref-8">[8]</sup><sup class="reference nowrap"><span title="Page / location: 34–35">: 34–35 </span></sup> Today, pointer jumping is considered a software design pattern for operating on recursive data types in parallel.<sup class="reference" id="cite_ref-9">[9]</sup><sup class="reference nowrap"><span title="Page / location: 99">: 99 </span></sup>
</p><p>As a technique for following linked paths, graph algorithms are a natural fit for pointer jumping. Consequently, several parallel graph algorithms utilizing pointer jumping have been designed. These include algorithms for finding the roots of a forest of rooted trees,<sup class="reference" id="cite_ref-JaJa_2-2">[2]</sup><sup class="reference nowrap"><span title="Page / location: 52–53">: 52–53 </span></sup><sup class="reference" id="cite_ref-Shiloach_6-1">[6]</sup> connected components,<sup class="reference" id="cite_ref-JaJa_2-3">[2]</sup><sup class="reference nowrap"><span title="Page / location: 213–221">: 213–221 </span></sup> minimum spanning trees<sup class="reference" id="cite_ref-JaJa_2-4">[2]</sup>,<sup class="reference nowrap"><span title="Page / location: 222–227">: 222–227 </span></sup><sup class="reference" id="cite_ref-10">[10]</sup> and biconnected components<sup class="reference" id="cite_ref-JaJa_2-5">[2]</sup><sup class="reference nowrap"><span title="Page / location: 227–239">: 227–239 </span></sup><sup class="reference" id="cite_ref-Tarjan_7-1">[7]</sup>. However, pointer jumping has also shown to be useful in a variety of other problems including computer vision,<sup class="reference" id="cite_ref-11">[11]</sup> image compression,<sup class="reference" id="cite_ref-12">[12]</sup> and Bayesian inference.<sup class="reference" id="cite_ref-13">[13]</sup>
</p>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>

<!-- 
NewPP limit report
Parsed by mw2275
Cached time: 20221221023552
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.446 seconds
Real time usage: 0.561 seconds
Preprocessor visited node count: 7183/1000000
Post‐expand include size: 78622/2097152 bytes
Template argument size: 2706/2097152 bytes
Highest expansion depth: 16/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 51835/5000000 bytes
Lua time usage: 0.228/10.000 seconds
Lua memory usage: 6918678/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  486.506      1 -total
 33.64%  163.670      1 Template:Reflist
 19.70%   95.846     23 Template:R/superscript
 18.74%   91.162     13 Template:Rp
 18.62%   90.598      4 Template:Cite_book
 17.94%   87.295      1 Template:Moresources
 16.56%   80.553      1 Template:Introduction_to_Algorithms
 15.14%   73.645      2 Template:Ambox
 11.97%   58.213      1 Template:Parallel_computing
 11.46%   55.777      1 Template:Navbox
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:41026219-0!canonical and timestamp 20221221023552 and revision id 1092466795.
 -->
</div></body>
</html>