<!DOCTYPE html>
<html>
<head>
<title>directed_acyclic_graph</title>
</head>
<body>
<div class="mw-parser-output"><img alt="This is a good article. Click here for more information." data-file-height="185" data-file-width="180" decoding="async" height="20" src="//upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/19px-Symbol_support_vote.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/29px-Symbol_support_vote.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/39px-Symbol_support_vote.svg.png 2x" width="19"/></div><div class="mw-parser-output">
<p class="mw-empty-elt">
</p>

<p>In mathematics, particularly graph theory, and computer science, a <b>directed acyclic graph</b> (<b>DAG</b>) is a directed graph with no directed cycles. That is, it consists of vertices and edges (also called <i>arcs</i>), with each edge directed from one vertex to another, such that following those directions will never form a closed loop. A directed graph is a DAG if and only if it can be topologically ordered, by arranging the vertices as a linear ordering that is consistent with all edge directions. DAGs have numerous scientific and computational applications, ranging from biology (evolution, family trees, epidemiology) to information science (citation networks) to computation (scheduling).
</p><p>Directed acyclic graphs are sometimes instead called <b>acyclic directed graphs</b><sup class="reference" id="cite_ref-thul_1-0">[1]</sup> or <b>acyclic digraphs</b>.<sup class="reference" id="cite_ref-bang_2-0">[2]</sup>
</p>

<h2><span class="mw-headline" id="Definitions">Definitions</span><span class="mw-editsection"></span></h2>
<p>A graph is formed by vertices and by edges connecting pairs of vertices, where the vertices can be any kind of object that is connected in pairs by edges. In the case of a directed graph, each edge has an orientation, from one vertex to another vertex. A path in a directed graph is a sequence of edges having the property that the ending vertex of each edge in the sequence is the same as the starting vertex of the next edge in the sequence; a path forms a cycle if the starting vertex of its first edge equals the ending vertex of its last edge. A directed acyclic graph is a directed graph that has no cycles.<sup class="reference" id="cite_ref-thul_1-1">[1]</sup><sup class="reference" id="cite_ref-bang_2-1">[2]</sup><sup class="reference" id="cite_ref-3">[3]</sup>
</p><p>A vertex <span class="texhtml mvar" style="font-style:italic;">v</span> of a directed graph is said to be reachable from another vertex <span class="texhtml mvar" style="font-style:italic;">u</span> when there exists a path that starts at <span class="texhtml mvar" style="font-style:italic;">u</span> and ends at <span class="texhtml mvar" style="font-style:italic;">v</span>. As a special case, every vertex is considered to be reachable from itself (by a path with zero edges). If a vertex can reach itself via a nontrivial path (a path with one or more edges), then that path is a cycle, so another way to define directed acyclic graphs is that they are the graphs in which no vertex can reach itself via a nontrivial path.<sup class="reference" id="cite_ref-4">[4]</sup>
</p>
<h2><span class="mw-headline" id="Mathematical_properties">Mathematical properties</span><span class="mw-editsection"></span></h2>
<h3><span id="Reachability_relation.2C_transitive_closure.2C_and_transitive_reduction"></span><span class="mw-headline" id="Reachability_relation,_transitive_closure,_and_transitive_reduction">Reachability relation, transitive closure, and transitive reduction</span><span class="mw-editsection"></span></h3>
<style data-mw-deduplicate="TemplateStyles:r1096954695/mw-parser-output/.tmulti">.mw-parser-output .tmulti .multiimageinner{display:flex;flex-direction:column}.mw-parser-output .tmulti .trow{display:flex;flex-direction:row;clear:left;flex-wrap:wrap;width:100%;box-sizing:border-box}.mw-parser-output .tmulti .tsingle{margin:1px;float:left}.mw-parser-output .tmulti .theader{clear:both;font-weight:bold;text-align:center;align-self:center;background-color:transparent;width:100%}.mw-parser-output .tmulti .thumbcaption{background-color:transparent}.mw-parser-output .tmulti .text-align-left{text-align:left}.mw-parser-output .tmulti .text-align-right{text-align:right}.mw-parser-output .tmulti .text-align-center{text-align:center}@media all and (max-width:720px){.mw-parser-output .tmulti .thumbinner{width:100%!important;box-sizing:border-box;max-width:none!important;align-items:center}.mw-parser-output .tmulti .trow{justify-content:center}.mw-parser-output .tmulti .tsingle{float:none!important;max-width:100%!important;box-sizing:border-box;text-align:center}.mw-parser-output .tmulti .tsingle .thumbcaption{text-align:left}.mw-parser-output .tmulti .trow>.thumbcaption{text-align:center}}</style>
<p>The reachability relation of a DAG can be formalized as a partial order <span class="texhtml">≤</span> on the vertices of the DAG. In this partial order, two vertices <span class="texhtml mvar" style="font-style:italic;">u</span> and <span class="texhtml mvar" style="font-style:italic;">v</span> are ordered as <span class="texhtml"><i>u</i> ≤ <i>v</i></span> exactly when there exists a directed path from <span class="texhtml mvar" style="font-style:italic;">u</span> to <span class="texhtml mvar" style="font-style:italic;">v</span> in the DAG; that is, when <span class="texhtml mvar" style="font-style:italic;">u</span> can reach <span class="texhtml mvar" style="font-style:italic;">v</span> (or <span class="texhtml mvar" style="font-style:italic;">v</span> is reachable from <span class="texhtml mvar" style="font-style:italic;">u</span>).<sup class="reference" id="cite_ref-5">[5]</sup> However, different DAGs may give rise to the same reachability relation and the same partial order.<sup class="reference" id="cite_ref-6">[6]</sup> For example, a DAG with two edges <span class="texhtml"><i>u</i> → <i>v</i></span> and <span class="texhtml"><i>v</i> → <i>w</i></span> has the same reachability relation as the DAG with three edges <span class="texhtml"><i>u</i> → <i>v</i></span>, <span class="texhtml"><i>v</i> → <i>w</i></span>, and <span class="texhtml"><i>u</i> → <i>w</i></span>. Both of these DAGs produce the same partial order, in which the vertices are ordered as <span class="texhtml"><i>u</i> ≤ <i>v</i> ≤ <i>w</i></span>.
</p><p>The transitive closure of a DAG is the graph with the most edges that has the same reachability relation as the DAG. It has an edge <span class="texhtml"><i>u</i> → <i>v</i></span> for every pair of vertices (<span class="texhtml mvar" style="font-style:italic;">u</span>, <span class="texhtml mvar" style="font-style:italic;">v</span>) in the reachability relation <span class="texhtml">≤</span> of the DAG, and may therefore be thought of as a direct translation of the reachability relation <span class="texhtml">≤</span> into graph-theoretic terms. The same method of translating partial orders into DAGs works more generally: for every finite partially ordered set <span class="texhtml">(<i>S</i>, ≤)</span>, the graph that has a vertex for every element of <span class="texhtml mvar" style="font-style:italic;">S</span> and an edge for every pair of elements in <span class="texhtml">≤</span> is automatically a transitively closed DAG, and has <span class="texhtml">(<i>S</i>, ≤)</span> as its reachability relation. In this way, every finite partially ordered set can be represented as a DAG.
</p>

<p>The transitive reduction of a DAG is the graph with the fewest edges that has the same reachability relation as the DAG. It has an edge <span class="texhtml"><i>u</i> → <i>v</i></span> for every pair of vertices (<span class="texhtml mvar" style="font-style:italic;">u</span>, <span class="texhtml mvar" style="font-style:italic;">v</span>) in the covering relation of the reachability relation <span class="texhtml">≤</span> of the DAG. It is a subgraph of the DAG, formed by discarding the edges <span class="texhtml"><i>u</i> → <i>v</i></span> for which the DAG also contains a longer directed path from <span class="texhtml mvar" style="font-style:italic;">u</span> to <span class="texhtml mvar" style="font-style:italic;">v</span>.
Like the transitive closure, the transitive reduction is uniquely defined for DAGs. In contrast, for a directed graph that is not acyclic, there can be more than one minimal subgraph with the same reachability relation.<sup class="reference" id="cite_ref-7">[7]</sup> Transitive reductions are useful in visualizing the partial orders they represent, because they have fewer edges than other graphs representing the same orders and therefore lead to simpler graph drawings. A Hasse diagram of a partial order is a drawing of the transitive reduction in which the orientation of every edge is shown by placing the starting vertex of the edge in a lower position than its ending vertex.<sup class="reference" id="cite_ref-8">[8]</sup>
</p>
<h3><span class="mw-headline" id="Topological_ordering">Topological ordering</span><span class="mw-editsection"></span></h3>
<link href="mw-data:TemplateStyles:r1096954695/mw-parser-output/.tmulti" rel="mw-deduplicated-inline-style"/>
<p>A topological ordering of a directed graph is an ordering of its vertices into a sequence, such that for every edge the start vertex of the edge occurs earlier in the sequence than the ending vertex of the edge. A graph that has a topological ordering cannot have any cycles, because the edge into the earliest vertex of a cycle would have to be oriented the wrong way. Therefore, every graph with a topological ordering is acyclic. Conversely, every directed acyclic graph has at least one topological ordering. The existence of a topological ordering can therefore be used as an equivalent definition of a directed acyclic graphs: they are exactly the graphs that have topological orderings.<sup class="reference" id="cite_ref-bang_2-2">[2]</sup>
In general, this ordering is not unique; a DAG has a unique topological ordering if and only if it has a directed path containing all the vertices, in which case the ordering is the same as the order in which the vertices appear in the path.<sup class="reference" id="cite_ref-9">[9]</sup>
</p><p>The family of topological orderings of a DAG is the same as the family of linear extensions of the reachability relation for the DAG,<sup class="reference" id="cite_ref-10">[10]</sup> so any two graphs representing the same partial order have the same set of topological orders.
</p>
<h3><span class="mw-headline" id="Combinatorial_enumeration">Combinatorial enumeration</span><span class="mw-editsection"></span></h3>
<p>The graph enumeration problem of counting directed acyclic graphs was studied by Robinson (1973).<sup class="reference" id="cite_ref-enum_11-0">[11]</sup>
The number of DAGs on <span class="texhtml mvar" style="font-style:italic;">n</span> labeled vertices, for <span class="texhtml"><i>n</i> = 0, 1, 2, 3, …</span> (without restrictions on the order in which these numbers appear in a topological ordering of the DAG) is
</p>
<dl><dd>1, 1, 3, 25, 543, 29281, 3781503, … (sequence <span class="nowrap external">A003024</span> in the OEIS).</dd></dl>
<p>These numbers may be computed by the recurrence relation
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle a_{n}=\sum _{k=1}^{n}(-1)^{k-1}{n \choose k}2^{k(n-k)}a_{n-k}.}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>a</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</msub>
<mo>=</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<mo stretchy="false">(</mo>
<mo>−<!-- − --></mo>
<mn>1</mn>
<msup>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</msup>
<mrow class="MJX-TeXAtom-ORD">
<mrow>
<mrow class="MJX-TeXAtom-OPEN">
<mo maxsize="2.047em" minsize="2.047em">(</mo>
</mrow>
<mfrac linethickness="0">
<mi>n</mi>
<mi>k</mi>
</mfrac>
<mrow class="MJX-TeXAtom-CLOSE">
<mo maxsize="2.047em" minsize="2.047em">)</mo>
</mrow>
</mrow>
</mrow>
<msup>
<mn>2</mn>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mi>k</mi>
<mo stretchy="false">)</mo>
</mrow>
</msup>
<msub>
<mi>a</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
<mo>−<!-- − --></mo>
<mi>k</mi>
</mrow>
</msub>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle a_{n}=\sum _{k=1}^{n}(-1)^{k-1}{n \choose k}2^{k(n-k)}a_{n-k}.}</annotation>
</semantics>
</math></span><img alt="a_n = \sum_{k=1}^n (-1)^{k-1} {n\choose k}2^{k(n-k)} a_{n-k}." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7d6b288e5e3203dfb301a6063177c59a82f5908a" style="vertical-align: -3.005ex; width:33.569ex; height:6.843ex;"/></span><sup class="reference" id="cite_ref-enum_11-1">[11]</sup></dd></dl>
<p>Eric W. Weisstein conjectured,<sup class="reference" id="cite_ref-12">[12]</sup> and McKay et al. (2004) proved, that the same numbers count the (0,1) matrices for which all eigenvalues are positive real numbers. The proof is bijective: a matrix <span class="texhtml mvar" style="font-style:italic;">A</span> is an adjacency matrix of a DAG if and only if <span class="texhtml"><i>A</i> + <i>I</i></span> is a (0,1) matrix with all eigenvalues positive, where <span class="texhtml mvar" style="font-style:italic;">I</span> denotes the identity matrix. Because a DAG cannot have self-loops, its adjacency matrix must have a zero diagonal, so adding <span class="texhtml mvar" style="font-style:italic;">I</span> preserves the property that all matrix coefficients are 0 or 1.<sup class="reference" id="cite_ref-13">[13]</sup>
</p>
<h3><span class="mw-headline" id="Related_families_of_graphs">Related families of graphs</span><span class="mw-editsection"></span></h3>
<link href="mw-data:TemplateStyles:r1096954695/mw-parser-output/.tmulti" rel="mw-deduplicated-inline-style"/>
<p>A <i>multitree</i> (also called a <i>strongly unambiguous graph</i> or a <i>mangrove</i>) is a DAG in which there is at most one directed path between any two vertices. Equivalently, it is a DAG in which the subgraph reachable from any vertex induces an undirected tree.<sup class="reference" id="cite_ref-14">[14]</sup>
</p><p>A <i>polytree</i> (also called a <i>directed tree</i>) is a multitree formed by orienting the edges of an undirected tree.<sup class="reference" id="cite_ref-15">[15]</sup>
</p><p>An <i>arborescence</i> is a polytree formed by orienting the edges of an undirected tree away from a particular vertex, called the <i>root</i> of the arborescence.
</p>
<h2><span class="mw-headline" id="Computational_problems">Computational problems</span><span class="mw-editsection"></span></h2>
<h3><span class="mw-headline" id="Topological_sorting_and_recognition">Topological sorting and recognition</span><span class="mw-editsection"></span></h3>
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style>
<p>Topological sorting is the algorithmic problem of finding a topological ordering of a given DAG. It can be solved in linear time.<sup class="reference" id="cite_ref-clrs_16-0">[16]</sup> Kahn's algorithm for topological sorting builds the vertex ordering directly. It maintains a list of vertices that have no incoming edges from other vertices that have not already been included in the partially constructed topological ordering; initially this list consists of the vertices with no incoming edges at all. Then, it repeatedly adds one vertex from this list to the end of the partially constructed topological ordering, and checks whether its neighbors should be added to the list. The algorithm terminates when all vertices have been processed in this way.<sup class="reference" id="cite_ref-j50_17-0">[17]</sup> Alternatively, a topological ordering may be constructed by reversing a postorder numbering of a depth-first search graph traversal.<sup class="reference" id="cite_ref-clrs_16-1">[16]</sup>
</p><p>It is also possible to check whether a given directed graph is a DAG in linear time, either by attempting to find a topological ordering and then testing for each edge whether the resulting ordering is valid<sup class="reference" id="cite_ref-18">[18]</sup> or alternatively, for some topological sorting algorithms, by verifying that the algorithm successfully orders all the vertices without meeting an error condition.<sup class="reference" id="cite_ref-j50_17-1">[17]</sup>
</p>
<h3><span class="mw-headline" id="Construction_from_cyclic_graphs">Construction from cyclic graphs</span><span class="mw-editsection"></span></h3>
<p>Any undirected graph may be made into a DAG by choosing a total order for its vertices and directing every edge from the earlier endpoint in the order to the later endpoint. The resulting orientation of the edges is called an acyclic orientation. Different total orders may lead to the same acyclic orientation, so an <span class="texhtml mvar" style="font-style:italic;">n</span>-vertex graph can have fewer than <span class="texhtml"><i>n</i>!</span> acyclic orientations. The number of acyclic orientations is equal to <span class="texhtml">|<i>χ</i>(−1)|</span>, where <span class="texhtml mvar" style="font-style:italic;">χ</span> is the chromatic polynomial of the given graph.<sup class="reference" id="cite_ref-19">[19]</sup>
</p>

<p>Any directed graph may be made into a DAG by removing a feedback vertex set or a feedback arc set, a set of vertices or edges (respectively) that touches all cycles. However, the smallest such set is NP-hard to find.<sup class="reference" id="cite_ref-20">[20]</sup> An arbitrary directed graph may also be transformed into a DAG, called its condensation, by contracting each of its strongly connected components into a single supervertex.<sup class="reference" id="cite_ref-21">[21]</sup> When the graph is already acyclic, its smallest feedback vertex sets and feedback arc sets are empty, and its condensation is the graph itself.
</p>
<h3><span class="mw-headline" id="Transitive_closure_and_transitive_reduction">Transitive closure and transitive reduction</span><span class="mw-editsection"></span></h3>
<p>The transitive closure of a given DAG, with <span class="texhtml mvar" style="font-style:italic;">n</span> vertices and <span class="texhtml mvar" style="font-style:italic;">m</span> edges, may be constructed in time <span class="texhtml"><i>O</i>(<i>mn</i>)</span> by using either breadth-first search or depth-first search to test reachability from each vertex.<sup class="reference" id="cite_ref-22">[22]</sup> Alternatively, it can be solved in time <span class="texhtml"><i>O</i>(<i>n</i><sup><i>ω</i></sup>)</span> where <span class="texhtml"><i>ω</i> &lt; 2.373</span> is the exponent for matrix multiplication algorithms; this is a theoretical improvement over the <span class="texhtml"><i>O</i>(<i>mn</i>)</span> bound for dense graphs.<sup class="reference" id="cite_ref-23">[23]</sup>
</p><p>In all of these transitive closure algorithms, it is possible to distinguish pairs of vertices that are reachable by at least one path of length two or more from pairs that can only be connected by a length-one path. The transitive reduction consists of the edges that form length-one paths that are the only paths connecting their endpoints. Therefore, the transitive reduction can be constructed in the same asymptotic time bounds as the transitive closure.<sup class="reference" id="cite_ref-24">[24]</sup>
</p>
<h3><span class="mw-headline" id="Closure_problem">Closure problem</span><span class="mw-editsection"></span></h3>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<p>The closure problem takes as input a vertex-weighted directed acyclic graph and seeks the minimum (or maximum) weight of a closure – a set of vertices <i>C</i>, such that no edges leave <i>C</i>. The problem may be formulated for directed graphs without the assumption of acyclicity, but with no greater generality, because in this case it is equivalent to the same problem on the condensation of the graph. It may be solved in polynomial time using a reduction to the maximum flow problem.<sup class="reference" id="cite_ref-25">[25]</sup>
</p>
<h3><span class="mw-headline" id="Path_algorithms">Path algorithms</span><span class="mw-editsection"></span></h3>
<p>Some algorithms become simpler when used on DAGs instead of general graphs, based on the principle of topological ordering. For example, it is possible to find shortest paths and longest paths from a given starting vertex in DAGs in linear time by processing the vertices in a topological order, and calculating the path length for each vertex to be the minimum or maximum length obtained via any of its incoming edges.<sup class="reference" id="cite_ref-26">[26]</sup> In contrast, for arbitrary graphs the shortest path may require slower algorithms such as Dijkstra's algorithm or the Bellman–Ford algorithm,<sup class="reference" id="cite_ref-27">[27]</sup> and longest paths in arbitrary graphs are NP-hard to find.<sup class="reference" id="cite_ref-28">[28]</sup>
</p>
<h2><span class="mw-headline" id="Applications">Applications</span><span class="mw-editsection"></span></h2>
<h3><span class="mw-headline" id="Scheduling">Scheduling</span><span class="mw-editsection"></span></h3>
<p>Directed acyclic graph representations of partial orderings have many applications in scheduling for systems of tasks with ordering constraints.<sup class="reference" id="cite_ref-29">[29]</sup>
An important class of problems of this type concern collections of objects that need to be updated, such as the cells of a spreadsheet after one of the cells has been changed, or the object files of a piece of computer software after its source code has been changed.
In this context, a dependency graph is a graph that has a vertex for each object to be updated, and an edge connecting two objects whenever one of them needs to be updated earlier than the other. A cycle in this graph is called a circular dependency, and is generally not allowed, because there would be no way to consistently schedule the tasks involved in the cycle.
Dependency graphs without circular dependencies form DAGs.<sup class="reference" id="cite_ref-30">[30]</sup>
</p><p>For instance, when one cell of a spreadsheet changes, it is necessary to recalculate the values of other cells that depend directly or indirectly on the changed cell. For this problem, the tasks to be scheduled are the recalculations of the values of individual cells of the spreadsheet. Dependencies arise when an expression in one cell uses a value from another cell. In such a case, the value that is used must be recalculated earlier than the expression that uses it. Topologically ordering the dependency graph, and using this topological order to schedule the cell updates, allows the whole spreadsheet to be updated with only a single evaluation per cell.<sup class="reference" id="cite_ref-hgt1181_31-0">[31]</sup> Similar problems of task ordering arise in makefiles for program compilation<sup class="reference" id="cite_ref-hgt1181_31-1">[31]</sup> and instruction scheduling for low-level computer program optimization.<sup class="reference" id="cite_ref-32">[32]</sup>
</p>

<p>A somewhat different DAG-based formulation of scheduling constraints is used by the program evaluation and review technique (PERT), a method for management of large human projects that was one of the first applications of DAGs. In this method, the vertices of a DAG represent milestones of a project rather than specific tasks to be performed. Instead, a task or activity is represented by an edge of a DAG, connecting two milestones that mark the beginning and completion of the task. Each such edge is labeled with an estimate for the amount of time that it will take a team of workers to perform the task. The longest path in this DAG represents the critical path of the project, the one that controls the total time for the project. Individual milestones can be scheduled according to the lengths of the longest paths ending at their vertices.<sup class="reference" id="cite_ref-33">[33]</sup>
</p>
<h3><span class="mw-headline" id="Data_processing_networks">Data processing networks</span><span class="mw-editsection"></span></h3>
<p>A directed acyclic graph may be used to represent a network of processing elements. In this representation, data enters a processing element through its incoming edges and leaves the element through its outgoing edges.
</p><p>For instance, in electronic circuit design, static combinational logic blocks can be represented as an acyclic system of logic gates that computes a function of an input, where the input and output of the function are represented as individual bits. In general, the output of these blocks cannot be used as the input unless it is captured by a register or state element which maintains its acyclic properties.<sup class="reference" id="cite_ref-34">[34]</sup> Electronic circuit schematics either on paper or in a database are a form of directed acyclic graphs using instances or components to form a directed reference to a lower level component. Electronic circuits themselves are not necessarily acyclic or directed.
</p><p>Dataflow programming languages describe systems of operations on data streams, and the connections between the outputs of some operations and the inputs of others. These languages can be convenient for describing repetitive data processing tasks, in which the same acyclically-connected collection of operations is applied to many data items. They can be executed as a parallel algorithm in which each operation is performed by a parallel process as soon as another set of inputs becomes available to it.<sup class="reference" id="cite_ref-35">[35]</sup>
</p><p>In compilers, straight line code (that is, sequences of statements without loops or conditional branches) may be represented by a DAG describing the inputs and outputs of each of the arithmetic operations performed within the code. This representation allows the compiler to perform common subexpression elimination efficiently.<sup class="reference" id="cite_ref-36">[36]</sup> At a higher level of code organization, the acyclic dependencies principle states that the dependencies between modules or components of a large software system should form a directed acyclic graph.<sup class="reference" id="cite_ref-37">[37]</sup>
</p><p>Feedforward neural networks are another example.
</p>
<h3><span class="mw-headline" id="Causal_structures">Causal structures</span><span class="mw-editsection"></span></h3>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<p>Graphs in which vertices represent events occurring at a definite time, and where the edges always point from the early time vertex to a late time vertex of the edge, are necessarily directed and acyclic. The lack of a cycle follows because the time associated with a vertex always increases as you follow any path in the graph so you can never return to a vertex on a path.  This reflects our natural intuition that causality means events can only affect the future, they never affect the past, and thus we have no causal loops. An example of this type of directed acyclic graph are those encountered in the causal set approach to quantum gravity though in this case the graphs considered are transitively complete. In the version history example below, each version of the software is associated with a unique time, typically the time the version was saved, committed or released. In the citation graph examples below, the documents are published at one time and can only refer to older documents.
</p><p>Sometimes events are not associated with a specific physical time. Provided that pairs of events have a purely causal relationship, that is edges represent causal relations between the events, we will have a directed acyclic graph.<sup class="reference" id="cite_ref-38">[38]</sup> For instance, a Bayesian network represents a system of probabilistic events as vertices in a directed acyclic graph, in which the likelihood of an event may be calculated from the likelihoods of its predecessors in the DAG.<sup class="reference" id="cite_ref-39">[39]</sup> In this context, the moral graph of a DAG is the undirected graph created by adding an (undirected) edge between all parents of the same vertex (sometimes called <i>marrying</i>), and then replacing all directed edges by undirected edges.<sup class="reference" id="cite_ref-40">[40]</sup> Another type of graph with a similar causal structure is an influence diagram, the vertices of which represent either decisions to be made or unknown information, and the edges of which represent causal influences from one vertex to another.<sup class="reference" id="cite_ref-41">[41]</sup> In epidemiology, for instance, these diagrams are often used to estimate the expected value of different choices for intervention.<sup class="reference" id="cite_ref-42">[42]</sup><sup class="reference" id="cite_ref-pearl:95_43-0">[43]</sup>
</p><p>The converse is also true. That is in any application represented by a directed acyclic graph there is a causal structure, either an explicit order or time in the example or an order which can be derived from graph structure. This follows because all directed acyclic graphs have a topological ordering, i.e. there is at least one way to put the vertices in an order such that all edges point in the same direction along that order.
</p>
<h3><span class="mw-headline" id="Genealogy_and_version_history">Genealogy and version history</span><span class="mw-editsection"></span></h3>

<p>Family trees may be seen as directed acyclic graphs, with a vertex for each family member and an edge for each parent-child relationship.<sup class="reference" id="cite_ref-44">[44]</sup> Despite the name, these graphs are not necessarily trees because of the possibility of marriages between relatives (so a child has a common ancestor on both the mother's and father's side) causing pedigree collapse.<sup class="reference" id="cite_ref-45">[45]</sup> The graphs of matrilineal descent (mother-daughter relationships) and patrilineal descent (father-son relationships) are trees within this graph. Because no one can become their own ancestor, family trees are acyclic.<sup class="reference" id="cite_ref-46">[46]</sup>
</p><p>The version history of a distributed revision control system, such as Git, generally has the structure of a directed acyclic graph, in which there is a vertex for each revision and an edge connecting pairs of revisions that were directly derived from each other. These are not trees in general due to merges.<sup class="reference" id="cite_ref-47">[47]</sup>
</p><p>In many randomized algorithms in computational geometry, the algorithm maintains a <i>history DAG</i> representing the version history of a geometric structure over the course of a sequence of changes to the structure. For instance in a randomized incremental algorithm for Delaunay triangulation, the triangulation changes by replacing one triangle by three smaller triangles when each point is added, and by "flip" operations that replace pairs of triangles by a different pair of triangles. The history DAG for this algorithm has a vertex for each triangle constructed as part of the algorithm, and edges from each triangle to the two or three other triangles that replace it. This structure allows point location queries to be answered efficiently: to find the location of a query point <span class="texhtml mvar" style="font-style:italic;">q</span> in the Delaunay triangulation, follow a path in the history DAG, at each step moving to the replacement triangle that contains <span class="texhtml mvar" style="font-style:italic;">q</span>. The final triangle reached in this path must be the Delaunay triangle that contains <span class="texhtml mvar" style="font-style:italic;">q</span>.<sup class="reference" id="cite_ref-48">[48]</sup>
</p>
<h3><span class="mw-headline" id="Citation_graphs">Citation graphs</span><span class="mw-editsection"></span></h3>
<p>In a citation graph the vertices are documents with a single publication date. The edges represent the citations from the bibliography of one document to other necessarily earlier documents. The classic example comes from the citations between academic papers as pointed out in the 1965 article "Networks of Scientific Papers"<sup class="reference" id="cite_ref-49">[49]</sup> by Derek J. de Solla Price who went on to produce the first model of a citation network, the Price model.<sup class="reference" id="cite_ref-50">[50]</sup> In this case the citation count of a paper is just the in-degree of the corresponding vertex of the citation network. This is an important measure in citation analysis. Court judgements provide another example as judges support their conclusions in one case by recalling other earlier decisions made in previous cases. A final example is provided by patents which must refer to earlier prior art, earlier patents which are relevant to the current patent claim. By taking the special properties of directed acyclic graphs into account, one can analyse citation networks with techniques not available when analysing the general graphs considered in many studies using network analysis. For instance transitive reduction gives new insights into the citation distributions found in different applications highlighting clear differences in the mechanisms creating citations networks in different contexts.<sup class="reference" id="cite_ref-51">[51]</sup> Another technique is main path analysis, which traces the citation links and suggests the most significant citation chains in a given citation graph.
</p><p>The Price model is too simple to be a realistic model of a citation network but it is simple enough to allow for analytic solutions for some of its properties. Many of these can be found by using results derived from the undirected version of the Price model, the Barabási–Albert model. However, since Price's model gives a directed acyclic graph, it is a useful model when looking for analytic calculations of properties unique to directed acyclic graphs. For instance,
the length of the longest path, from the n-th node added to the network to the first node in the network, scales as<sup class="reference" id="cite_ref-ECV_52-0">[52]</sup> <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \ln(n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>ln</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \ln(n)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \ln(n)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b40d8af55c5679aa769abbd67a7b98612c2aeaf5" style="vertical-align: -0.838ex; width:5.143ex; height:2.843ex;"/></span>.
</p>
<h3><span class="mw-headline" id="Data_compression">Data compression</span><span class="mw-editsection"></span></h3>
<p>Directed acyclic graphs may also be used as a compact representation of a collection of sequences. In this type of application, one finds a DAG in which the paths form the given sequences. When many of the sequences share the same subsequences, these shared subsequences can be represented by a shared part of the DAG, allowing the representation to use less space than it would take to list out all of the sequences separately. For example, the directed acyclic word graph is a data structure in computer science formed by a directed acyclic graph with a single source and with edges labeled by letters or symbols; the paths from the source to the sinks in this graph represent a set of strings, such as English words.<sup class="reference" id="cite_ref-53">[53]</sup> Any set of sequences can be represented as paths in a tree, by forming a tree vertex for every prefix of a sequence and making the parent of one of these vertices represent the sequence with one fewer element; the tree formed in this way for a set of strings is called a trie. A directed acyclic word graph saves space over a trie by allowing paths to diverge and rejoin, so that a set of words with the same possible suffixes can be represented by a single tree vertex.<sup class="reference" id="cite_ref-54">[54]</sup>
</p><p>The same idea of using a DAG to represent a family of paths occurs in the binary decision diagram,<sup class="reference" id="cite_ref-55">[55]</sup><sup class="reference" id="cite_ref-56">[56]</sup> a DAG-based data structure for representing binary functions. In a binary decision diagram, each non-sink vertex is labeled by the name of a binary variable, and each sink and each edge is labeled by a 0 or 1. The function value for any truth assignment to the variables is the value at the sink found by following a path, starting from the single source vertex, that at each non-sink vertex follows the outgoing edge labeled with the value of that vertex's variable. Just as directed acyclic word graphs can be viewed as a compressed form of tries, binary decision diagrams can be viewed as compressed forms of decision trees that save space by allowing paths to rejoin when they agree on the results of all remaining decisions.<sup class="reference" id="cite_ref-57">[57]</sup>
</p>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1097025294">.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:#f9f9f9}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1}}@media(min-width:720px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}</style>
<ul><li><span class="citation mathworld" id="Reference-Mathworld-Acyclic_Digraph"><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation web cs2" id="CITEREFWeisstein">Weisstein, Eric W., "Acyclic Digraph", <i>MathWorld</i></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MathWorld&amp;rft.atitle=Acyclic+Digraph&amp;rft.au=Weisstein%2C+Eric+W.&amp;rft_id=https%3A%2F%2Fmathworld.wolfram.com%2FAcyclicDigraph.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ADirected+acyclic+graph"></span></span></li>
<li>DAGitty – an online tool for creating DAGs</li></ul>
<!-- 
NewPP limit report
Parsed by mw2335
Cached time: 20221223231819
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.577 seconds
Real time usage: 0.739 seconds
Preprocessor visited node count: 5015/1000000
Post‐expand include size: 117492/2097152 bytes
Template argument size: 3418/2097152 bytes
Highest expansion depth: 13/100
Expensive parser function count: 3/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 167692/5000000 bytes
Lua time usage: 0.352/10.000 seconds
Lua memory usage: 8703468/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  597.417      1 -total
 54.55%  325.893      1 Template:Reflist
 42.72%  255.216     48 Template:Citation
  9.54%   57.012      1 Template:Short_description
  9.18%   54.849      7 Template:Harvtxt
  7.69%   45.927      1 Template:Commons_category
  7.33%   43.764      1 Template:Sister_project
  7.07%   42.247      1 Template:Side_box
  7.03%   41.986     30 Template:Main_other
  4.46%   26.674      2 Template:Pagetype
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:204002-0!canonical and timestamp 20221223231818 and revision id 1114643590.
 -->
</div></body>
</html>