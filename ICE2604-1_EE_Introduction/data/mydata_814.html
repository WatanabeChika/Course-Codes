<!DOCTYPE html>
<html>
<head>
<title>quicksort</title>
</head>
<body>
<div class="mw-parser-output">
<p class="mw-empty-elt">
</p>
<style data-mw-deduplicate="TemplateStyles:r1066479718">.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}body.skin-minerva .mw-parser-output .infobox-header,body.skin-minerva .mw-parser-output .infobox-subheader,body.skin-minerva .mw-parser-output .infobox-above,body.skin-minerva .mw-parser-output .infobox-title,body.skin-minerva .mw-parser-output .infobox-image,body.skin-minerva .mw-parser-output .infobox-full-data,body.skin-minerva .mw-parser-output .infobox-below{text-align:center}</style><table class="infobox"><caption class="infobox-title">Quicksort</caption><tbody><tr><td class="infobox-image" colspan="2"><img alt="Sorting quicksort anim.gif" data-file-height="214" data-file-width="280" decoding="async" height="168" src="//upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Sorting_quicksort_anim.gif/220px-Sorting_quicksort_anim.gif" srcset="//upload.wikimedia.org/wikipedia/commons/6/6a/Sorting_quicksort_anim.gif 1.5x" width="220"/></td></tr><tr><th class="infobox-label" scope="row">Class</th><td class="infobox-data">Sorting algorithm</td></tr><tr><th class="infobox-label" scope="row">Worst-case performance</th><td class="infobox-data"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n^{2})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>n</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n^{2})}</annotation>
</semantics>
</math></span><img alt="O(n^{2})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6cd9594a16cb898b8f2a2dff9227a385ec183392" style="vertical-align: -0.838ex; width:6.032ex; height:3.176ex;"/></span></td></tr><tr><th class="infobox-label" scope="row">Best-case performance</th><td class="infobox-data"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n\log n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n\log n)}</annotation>
</semantics>
</math></span><img alt="O(n\log n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9d2320768fb54880ca4356e61f60eb02a3f9d9f1" style="vertical-align: -0.838ex; width:10.118ex; height:2.843ex;"/></span> (simple partition)<br/>or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n)}</annotation>
</semantics>
</math></span><img alt="O(n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34109fe397fdcff370079185bfdb65826cb5565a" style="vertical-align: -0.838ex; width:4.977ex; height:2.843ex;"/></span> (three-way partition and equal keys)</td></tr><tr><th class="infobox-label" scope="row">Average performance</th><td class="infobox-data"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n\log n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n\log n)}</annotation>
</semantics>
</math></span><img alt="O(n\log n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9d2320768fb54880ca4356e61f60eb02a3f9d9f1" style="vertical-align: -0.838ex; width:10.118ex; height:2.843ex;"/></span></td></tr><tr><th class="infobox-label" scope="row">Worst-case space complexity</th><td class="infobox-data"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n)}</annotation>
</semantics>
</math></span><img alt="O(n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34109fe397fdcff370079185bfdb65826cb5565a" style="vertical-align: -0.838ex; width:4.977ex; height:2.843ex;"/></span> auxiliary (naive)<br/><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(\log n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(\log n)}</annotation>
</semantics>
</math></span><img alt="O(\log n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/aae0f22048ba6b7c05dbae17b056bfa16e21807d" style="vertical-align: -0.838ex; width:8.336ex; height:2.843ex;"/></span> auxiliary (Hoare 1962)</td></tr></tbody></table>
<p><b>Quicksort</b> is an efficient, general-purpose sorting algorithm. Quicksort was developed by British computer scientist Tony Hoare in 1959<sup class="reference" id="cite_ref-1">[1]</sup> and published in 1961,<sup class="reference" id="cite_ref-alg64_2-0">[2]</sup> it is still a commonly used algorithm for sorting. Overall, it is slightly faster than merge sort and heapsort for randomized data, particularly on larger distributions.<sup class="reference" id="cite_ref-skiena_3-0">[3]</sup>
</p><p>Quicksort is a divide-and-conquer algorithm. It works by selecting a 'pivot' element from the array and partitioning the other elements into two sub-arrays, according to whether they are less than or greater than the pivot. For this reason, it is sometimes called <b>partition-exchange sort</b>.<sup class="reference" id="cite_ref-4">[4]</sup> The sub-arrays are then sorted recursively. This can be done in-place, requiring small additional amounts of memory to perform the sorting.
</p><p>Quicksort is a comparison sort, meaning that it can sort items of any type for which a "less-than" relation (formally, a total order) is defined. Most implementations of quicksort are not stable, meaning that the relative order of equal sort items is not preserved.
</p><p>Mathematical analysis of quicksort shows that, on average, the algorithm takes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n\log {n})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n\log {n})}</annotation>
</semantics>
</math></span><img alt="O(n\log {n})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8b5ea2d55d8c31feb17ce14f35da4c93f94982b3" style="vertical-align: -0.838ex; width:10.118ex; height:2.843ex;"/></span> comparisons to sort <i>n</i> items. In the worst case, it makes <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n^{2})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>n</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n^{2})}</annotation>
</semantics>
</math></span><img alt="O(n^{2})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6cd9594a16cb898b8f2a2dff9227a385ec183392" style="vertical-align: -0.838ex; width:6.032ex; height:3.176ex;"/></span> comparisons.
</p>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"></span></h2>
<p>The quicksort algorithm was developed in 1959 by Tony Hoare while he was a visiting student at Moscow State University. At that time, Hoare was working on a machine translation project for the National Physical Laboratory. As a part of the translation process, he needed to sort the words in Russian sentences before looking them up in a Russian-English dictionary, which was in alphabetical order on magnetic tape.<sup class="reference" id="cite_ref-5">[5]</sup> After recognizing that his first idea, insertion sort, would be slow, he came up with a new idea. He wrote the partition part in Mercury Autocode but had trouble dealing with the list of unsorted segments. On return to England, he was asked to write code for Shellsort. Hoare mentioned to his boss that he knew of a faster algorithm and his boss bet sixpence that he did not. His boss ultimately accepted that he had lost the bet. Later, Hoare learned about ALGOL and its ability to do recursion that enabled him to publish the code in <i>Communications of the Association for Computing Machinery</i>, the premier computer science journal of the time.<sup class="reference" id="cite_ref-alg64_2-1">[2]</sup><sup class="reference" id="cite_ref-6">[6]</sup>
</p><p>Quicksort gained widespread adoption, appearing, for example, in Unix as the default library sort subroutine. Hence, it lent its name to the C standard library subroutine <style data-mw-deduplicate="TemplateStyles:r886049734">.mw-parser-output .monospaced{font-family:monospace,monospace}</style><span class="monospaced">qsort</span><sup class="reference" id="cite_ref-engineering_7-0">[7]</sup> and in the reference implementation of Java.
</p><p>Robert Sedgewick's PhD thesis in 1975 is considered a milestone in the study of Quicksort where he resolved many open problems related to the analysis of various pivot selection schemes including Samplesort, adaptive partitioning by Van Emden<sup class="reference" id="cite_ref-8">[8]</sup> as well as derivation of expected number of comparisons and swaps.<sup class="reference" id="cite_ref-engineering_7-1">[7]</sup> Jon Bentley and Doug McIlroy in 1993 incorporated various improvements for use in programming libraries, including a technique to deal with equal elements and a pivot scheme known as <i>pseudomedian of nine,</i> where a sample of nine elements is divided into groups of three and then the median of the three medians from three groups is chosen.<sup class="reference" id="cite_ref-engineering_7-2">[7]</sup> Bentley described another simpler and compact partitioning scheme in his book <i>Programming Pearls</i> that he attributed to Nico Lomuto. Later Bentley wrote that he used Hoare's version for years but never really understood it but Lomuto's version was simple enough to prove correct.<sup class="reference" id="cite_ref-9">[9]</sup> Bentley described Quicksort as the "most beautiful code I had ever written" in the same essay. Lomuto's partition scheme was also popularized by the textbook <i>Introduction to Algorithms</i> although it is inferior to Hoare's scheme because it does three times more swaps on average and degrades to <span class="texhtml"><i>O</i>(<i>n</i><sup>2</sup>)</span> runtime when all elements are equal.<sup class="reference" id="cite_ref-:1_10-0">[10]</sup><sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><span title="The material near this tag may rely on a self-published source. (August 2015)">self-published source?</span></i>]</sup> McIlroy would further produce an<i>AntiQuicksort</i> (<link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">aqsort</span>) function in 1998, which consistently drives even his 1993 variant of Quicksort into quadratic behavior by producing adversarial data on-the-fly.<sup class="reference" id="cite_ref-11">[11]</sup>
</p>
<h2><span class="mw-headline" id="Algorithm">Algorithm</span><span class="mw-editsection"></span></h2>

<p>Quicksort is a type of divide and conquer algorithm for sorting an array, based on a partitioning routine; the details of this partitioning can vary somewhat, so that quicksort is really a family of closely related algorithms. Applied to a range of at least two elements, partitioning produces a division into two consecutive non empty sub-ranges, in such a way that no element of the first sub-range is greater than any element of the second sub-range. After applying this partition, quicksort then recursively sorts the sub-ranges, possibly after excluding from them an element at the point of division that is at this point known to be already in its final location. Due to its recursive nature, quicksort (like  the partition routine) has to be formulated so as to be callable for a range within a larger array, even if the ultimate goal is to sort a complete array. The steps for in-place quicksort are:
</p>
<ol><li>If the range has fewer than two elements, return immediately as there is nothing to do. Possibly for other very short lengths a special-purpose sorting method is applied and the remainder of these steps skipped.</li>
<li>Otherwise pick a value, called a <i>pivot</i>, that occurs in the range (the precise manner of choosing depends on the partition routine, and can involve randomness).</li>
<li><i>Partition</i> the range: reorder its elements, while determining a point of division, so that all elements with values less than the pivot come before the division, while all elements with values greater than the pivot come after it; elements that are equal to the pivot can go either way. Since at least one instance of the pivot is present,  most partition routines ensure that the value that ends up at the point of division is equal to the pivot, and is now in its final position (but termination of quicksort does not depend on this, as long as sub-ranges strictly smaller than the original are produced).</li>
<li>Recursively apply the quicksort to the sub-range up to the point of division and to the sub-range after it, possibly excluding from both ranges the element equal to the pivot at the point of division. (If the partition produces a possibly larger sub-range near the boundary where all elements are known to be equal to the pivot, these can be excluded as well.)</li></ol>
<p>The choice of partition routine (including the pivot selection) and other details not entirely specified above can affect the algorithm's performance, possibly to a great extent for specific input arrays. In discussing the efficiency of quicksort, it is therefore necessary to specify these choices first. Here we mention two specific partition methods.
</p>
<h3><span class="mw-headline" id="Lomuto_partition_scheme">Lomuto partition scheme</span><span class="mw-editsection"></span></h3>
<p>This scheme is attributed to Nico Lomuto and popularized by Bentley in his book <i>Programming Pearls</i><sup class="reference" id="cite_ref-:3_12-0">[12]</sup> and Cormen <i>et al.</i> in their book <i>Introduction to Algorithms</i>.<sup class="reference" id="cite_ref-:2_13-0">[13]</sup> In most formulations this scheme chooses as the pivot the last element in the array. The algorithm maintains index <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">i</span> as it scans the array using another index <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">j</span> such that the elements at <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">lo</span> through <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">i-1</span> (inclusive) are less than the pivot, and the elements at <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">i</span> through <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">j</span> (inclusive) are equal to or greater than the pivot. As this scheme is more compact and easy to understand, it is frequently used in introductory material, although it is less efficient than Hoare's original scheme e.g., when all elements are equal.<sup class="reference" id="cite_ref-14">[14]</sup> The complexity of Quicksort with this scheme degrades to <span class="texhtml"><i>O</i>(<i>n</i><sup>2</sup>)</span> when the array is already in order, due to the partition being the worst possible one.<sup class="reference" id="cite_ref-:1_10-1">[10]</sup> There have been various variants proposed to boost performance including various ways to select the pivot, deal with equal elements, use other sorting algorithms such as insertion sort for small arrays, and so on. In pseudocode, a quicksort that sorts elements at <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">lo</span> through <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">hi</span> (inclusive) of an array <span class="texhtml mvar" style="font-style:italic;">A</span> can be expressed as:<sup class="reference" id="cite_ref-:2_13-1">[13]</sup>
</p>
<pre><i>// Sorts a (portion of an) array, divides it into partitions, then sorts those</i>
<b>algorithm</b> quicksort(A, lo, hi) <b>is</b> 
  <i>// Ensure indices are in correct order</i>
  <b>if</b> lo &gt;= hi || lo &lt; 0 <b>then</b> 
    return
    
  <i>// Partition array and get the pivot index</i>
  p := partition(A, lo, hi) 
      
  <i>// Sort the two partitions</i>
  quicksort(A, lo, p - 1) <i>// Left side of pivot</i>
  quicksort(A, p + 1, hi) <i>// Right side of pivot</i>

<i>// Divides array into two partitions</i>
<b>algorithm</b> partition(A, lo, hi) <b>is</b> 
  pivot := A[hi] <i>// Choose the last element as the pivot</i>

  <i>// Temporary pivot index</i>
  i := lo - 1

  <b>for</b> j := lo <b>to</b> hi - 1 <b>do</b> 
    <i>// If the current element is less than or equal to the pivot</i>
    <b>if</b> A[j] &lt;= pivot <b>then</b> 
      <i>// Move the temporary pivot index forward</i>
      i := i + 1
      <i>// Swap the current element with the element at the temporary pivot index</i>
      swap A[i] <b>with</b> A[j]

  <i>// Move the pivot element to the correct pivot position (between the smaller and larger elements)</i>
  i := i + 1
  swap A[i] <b>with</b> A[hi]
  <b>return</b> i <i>// the pivot index</i>
</pre>
<p>Sorting the entire array is accomplished by <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">quicksort(A, 0, length(A) - 1)</span>.
</p>
<h3><span class="mw-headline" id="Hoare_partition_scheme">Hoare partition scheme</span><span class="mw-editsection"></span></h3>
<p>The original partition scheme described by Tony Hoare uses two pointers (indices into the range) that start at both ends of the array being partitioned, then move toward each other, until they detect an inversion: a pair of elements, one greater than the bound (Hoare's terms for the pivot value) at the first pointer, and one less than the bound at the second pointer; if at this point the first pointer is still before the second, these elements are in the wrong order relative to each other, and they are then exchanged.<sup class="reference" id="cite_ref-15">[15]</sup> After this the pointers are moved inwards, and the search for an inversion is repeated; when eventually the pointers cross (the first points after the second), no exchange is performed; a valid partition is found, with the point of division between the crossed pointers (any entries that might be strictly between the crossed pointers are equal to the pivot and can be excluded from both sub-ranges formed). With this formulation it is possible that one sub-range turns out to be the whole original range, which would prevent the algorithm from advancing. Hoare therefore stipulates that at the end, the sub-range containing the pivot element (which still is at its original position) can be decreased in size by excluding that pivot, after (if necessary) exchanging it with the sub-range element closest to the separation; thus, termination of quicksort is ensured.
</p><p>With respect to this original description, implementations often make minor but important variations. Notably, the scheme as presented below includes elements equal to the pivot among the candidates for an inversion (so "greater than or equal" and "less than or equal" tests are used instead of "greater than" and "less than" respectively; since the formulation uses <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced"><b>do</b>...<b>while</b> rather than <b>repeat</b>...<b>until</b></span> which is actually reflected by the use of strict comparison operators). While there is no reason to exchange elements equal to the bound, this change allows tests on the pointers themselves to be omitted, which are otherwise needed to ensure they do not run out of range. Indeed, since at least one instance of the pivot value is present in the range, the first advancement of either pointer cannot pass across this instance if an inclusive test is used; once an exchange is performed, these exchanged elements are now both strictly ahead of the pointer that found them, preventing that pointer from running off. (The latter is true independently of the test used, so it would be possible to use the inclusive test only when looking for the first inversion. However, using an inclusive test throughout also ensures that a division near the middle is found when all elements in the range are equal, which gives an important efficiency gain for sorting arrays with many equal elements.) The risk of producing a non-advancing separation is avoided in a different manner than described by Hoare. Such a separation can only result when no inversions are found, with both pointers advancing to the pivot element at the first iteration (they are then considered to have crossed, and no exchange takes place). The division returned is after the final position of the second pointer, so the case to avoid is where the pivot is the final element of the range and all others are smaller than it. Therefore, the pivot choice must avoid the final element (in Hoare's description it could be any element in the range); this is done here by rounding <i>down</i> the middle position, using the <kbd>floor</kbd> function.<sup class="reference" id="cite_ref-16">[16]</sup> This illustrates that the argument for correctness of an implementation of the Hoare partition scheme can be subtle, and it is easy to get it wrong.
</p><p>In pseudocode,<sup class="reference" id="cite_ref-:2_13-2">[13]</sup>
</p>
<pre><i>// Sorts a (portion of an) array, divides it into partitions, then sorts those</i>
<b>algorithm</b> quicksort(A, lo, hi) <b>is</b> 
  <b>if</b> lo &gt;= 0 &amp;&amp; hi &gt;= 0 &amp;&amp; lo &lt; hi <b>then</b>
    p := partition(A, lo, hi) 
    quicksort(A, lo, p) // Note: the pivot is now included
    quicksort(A, p + 1, hi) 

<i>// Divides array into two partitions</i>
<b>algorithm</b> partition(A, lo, hi) <b>is</b> 
  <i>// Pivot value</i>
  pivot := A[ floor((hi + lo) / 2) ] <i>// The value in the middle of the array</i>

  <i>// Left index</i>
  i := lo - 1 

  <i>// Right index</i>
  j := hi + 1

  <b>loop forever</b> 
    <i>// Move the left index to the right at least once and while the element at</i>
    <i>// the left index is less than the pivot</i>
    <b>do</b> i := i + 1 <b>while</b> A[i] &lt; pivot
    
    <i>// Move the right index to the left at least once and while the element at</i>
    <i>// the right index is greater than the pivot</i>
    <b>do</b> j := j - 1 <b>while</b> A[j] &gt; pivot

    <i>// If the indices crossed, return</i>
    <b>if</b> i &gt;= j <b>then</b> <b>return</b> j
    
    <i>// Swap the elements at the left and right indices</i>
    <b>swap</b> A[i] <b>with</b> A[j]
</pre>
<p>The entire array is sorted by <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">quicksort(A, 0, length(A) - 1)</span>.
</p><p>Hoare's scheme is more efficient than Lomuto's partition scheme because it does three times fewer swaps on average. Also, as mentioned, the implementation given creates a balanced partition even when all values are equal.<sup class="reference" id="cite_ref-:1_10-2">[10]</sup><sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><span title="The material near this tag may rely on a self-published source. (August 2015)">self-published source?</span></i>]</sup>, which Lomuto's scheme does not. Like Lomuto's partition scheme, Hoare's partitioning also would cause Quicksort to degrade to <span class="texhtml"><i>O</i>(<i>n</i><sup>2</sup>)</span> for already sorted input, if the pivot was chosen as the first or the last element. With the middle element as the pivot, however, sorted data results with (almost) no swaps in equally sized partitions leading to best case behavior of Quicksort, i.e. <span class="texhtml"><i>O</i>(<i>n</i> log(<i>n</i>))</span>. Like others, Hoare's partitioning doesn't produce a stable sort. In this scheme, the pivot's final location is not necessarily at the index that is returned, as the pivot and elements equal to the pivot can end up anywhere within the partition after a partition step, and may not be sorted until the base case of a partition with a single element is reached via recursion. The next two segments that the main algorithm recurs on are <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(lo..p)</span> (elements ≤ pivot) and <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(p+1..hi)</span> (elements ≥ pivot) as opposed to <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(lo..p-1)</span> and <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(p+1..hi)</span> as in Lomuto's scheme.<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><span title="The reason for this is unclear. (September 2021)">why?</span></i>]</sup>
</p><p><b>Subsequent recursions (expansion on previous paragraph)</b>
</p><p>Let's expand a little bit on the next two segments that the main algorithm recurs on. Because we are using strict comparators (&gt;, &lt;) in the <b><link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">"do...while"</span></b> loops to prevent ourselves from running out of range, there's a chance that the pivot itself gets swapped with other elements in the partition function. Therefore, <b>the index returned in the partition function isn't necessarily where the actual pivot is.</b> Consider the example of <b><link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">[5, 2, 3, 1, 0]</span></b>, following the scheme, after the first partition the array becomes <b><link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">[0, 2, 1, 3, 5]</span></b>, the "index" returned is 2, which is the number 1, when the real pivot, the one we chose to start the partition with was the number 3. With this example, we see how it is necessary to include the returned index of the partition function in our subsequent recursions. As a result, we are presented with the choices of either recursing on <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(lo..p)</span> and <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(p+1..hi)</span>, or <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(lo..p - 1)</span> and <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(p..hi)</span>. Which of the two options we choose depends on which index (<b>i</b> or <b>j</b>) we return in the partition function when the indices cross, and how we choose our pivot in the partition function (<b>floor</b> v.s. <b>ceiling</b>).
</p><p>Let's first examine the choice of recursing on <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(lo..p)</span> and <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(p+1..hi)</span>, with the example of sorting an array where multiple identical elements exist <b><link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">[0, 0]</span></b>. If index i (the "latter" index) is returned after indices cross in the partition function, the index 1 would be returned after the first partition. The subsequent recursion on <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(lo..p)</span>would be on (0, 1), which corresponds to the exact same array <b><link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">[0, 0]</span></b>. A non-advancing separation that causes infinite recursion is produced. It is therefore obvious that <b>when recursing on <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(lo..p)</span> and <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(p+1..hi)</span>, because the left half of the recursion includes the returned index, it is the partition function's job to exclude the "tail" in non-advancing scenarios.</b> Which is to say, index j (the "former" index when indices cross) should be returned instead of i. Going with a similar logic, when considering the example of an already sorted array <b><link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">[0, 1]</span></b>, the choice of pivot needs to be "floor" to ensure that the pointers stop on the "former" instead of the "latter" (with "ceiling" as the pivot, the index 1 would be returned and included in <b><link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(lo..p)</span></b> causing infinite recursion). It is for the exact same reason why choice of the last element as pivot must be avoided.
</p><p>The choice of recursing on <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(lo..p - 1)</span> and <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">(p..hi)</span> follows the exact same logic as above. <b>Because the right half of the recursion includes the returned index, it is the partition function's job to exclude the "head" in non-advancing scenarios.</b> The index i (the "latter" index after the indices cross) in the partition function needs to be returned, and "ceiling" needs to be chosen as the pivot. The two nuances are clear, again, when considering the examples of sorting an array where multiple identical elements exist (<b><link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">[0, 0]</span></b>), and an already sorted array <b><link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">[0, 1]</span></b> respectively. It is noteworthy that with version of recursion, for the same reason, choice of the first element as pivot must be avoided.
</p>
<h3><span class="mw-headline" id="Implementation_issues">Implementation issues</span><span class="mw-editsection"></span></h3>
<h4><span class="mw-headline" id="Choice_of_pivot">Choice of pivot</span><span class="mw-editsection"></span></h4>
<p>In the very early versions of quicksort, the leftmost element of the partition would often be chosen as the pivot element. Unfortunately, this causes worst-case behavior on already sorted arrays, which is a rather common use-case.<sup class="reference" id="cite_ref-17">[17]</sup> The problem was easily solved by choosing either a random index for the pivot, choosing the middle index of the partition or (especially for longer partitions) choosing the median of the first, middle and last element of the partition for the pivot (as recommended by Sedgewick).<sup class="reference" id="cite_ref-sedgewickBook_18-0">[18]</sup> This "median-of-three" rule counters the case of sorted (or reverse-sorted) input, and gives a better estimate of the optimal pivot (the true median) than selecting any single element, when no information about the ordering of the input is known.
</p><p>Median-of-three code snippet for Lomuto partition:
</p>
<pre>mid := ⌊(lo + hi) / 2⌋
<b>if</b> A[mid] &lt; A[lo]
    swap A[lo] with A[mid]
<b>if</b> A[hi] &lt; A[lo]
    swap A[lo] with A[hi]
<b>if</b> A[mid] &lt; A[hi]
    swap A[mid] with A[hi]
pivot := A[hi]
</pre>
<p>It puts a median into <code>A[hi]</code> first, then that new value of <code>A[hi]</code> is used for a pivot, as in a basic algorithm presented above.
</p><p>Specifically, the expected number of comparisons needed to sort <span class="texhtml mvar" style="font-style:italic;">n</span> elements (see § Analysis of randomized quicksort) with random pivot selection is <span class="texhtml">1.386 <i>n</i> log <i>n</i></span>. Median-of-three pivoting brings this down to <span class="texhtml"><i>C</i><sub><i>n</i>, 2</sub> ≈ 1.188 <i>n</i> log <i>n</i></span>, at the expense of a three-percent increase in the expected number of swaps.<sup class="reference" id="cite_ref-engineering_7-3">[7]</sup> An even stronger pivoting rule, for larger arrays, is to pick the ninther, a recursive median-of-three (Mo3), defined as<sup class="reference" id="cite_ref-engineering_7-4">[7]</sup>
</p>
<dl><dd><span class="texhtml">ninther(<i>a</i>) = median(Mo3(first <style data-mw-deduplicate="TemplateStyles:r1050945101">.mw-parser-output .sfrac{white-space:nowrap}.mw-parser-output .sfrac.tion,.mw-parser-output .sfrac .tion{display:inline-block;vertical-align:-0.5em;font-size:85%;text-align:center}.mw-parser-output .sfrac .num,.mw-parser-output .sfrac .den{display:block;line-height:1em;margin:0 0.1em}.mw-parser-output .sfrac .den{border-top:1px solid}.mw-parser-output .sr-only{border:0;clip:rect(0,0,0,0);height:1px;margin:-1px;overflow:hidden;padding:0;position:absolute;width:1px}</style><span class="sfrac tion" role="math"><span class="num">1</span><span class="sr-only">/</span><span class="den">3</span></span> of <i>a</i>), Mo3(middle <link href="mw-data:TemplateStyles:r1050945101" rel="mw-deduplicated-inline-style"/><span class="sfrac tion" role="math"><span class="num">1</span><span class="sr-only">/</span><span class="den">3</span></span> of <i>a</i>), Mo3(final <link href="mw-data:TemplateStyles:r1050945101" rel="mw-deduplicated-inline-style"/><span class="sfrac tion" role="math"><span class="num">1</span><span class="sr-only">/</span><span class="den">3</span></span> of <i>a</i>))</span></dd></dl>
<p>Selecting a pivot element is also complicated by the existence of integer overflow. If the boundary indices of the subarray being sorted are sufficiently large, the naïve expression for the middle index, <span class="texhtml">(<i>lo</i> + <i>hi</i>)/2</span>, will cause overflow and provide an invalid pivot index. This can be overcome by using, for example, <span class="texhtml"><i>lo</i> + (<i>hi</i>−<i>lo</i>)/2</span> to index the middle element, at the cost of more complex arithmetic. Similar issues arise in some other methods of selecting the pivot element.
</p>
<h4><span class="mw-headline" id="Repeated_elements">Repeated elements</span><span class="mw-editsection"></span></h4>
<p>With a partitioning algorithm such as the Lomuto partition scheme described above (even one that chooses good pivot values), quicksort exhibits poor performance for inputs that contain many repeated elements. The problem is clearly apparent when all the input elements are equal: at each recursion, the left partition is empty (no input values are less than the pivot), and the right partition has only decreased by one element (the pivot is removed). Consequently, the Lomuto partition scheme takes quadratic time to sort an array of equal values. However, with a partitioning algorithm such as the Hoare partition scheme, repeated elements generally results in better partitioning, and although needless swaps of elements equal to the pivot may occur, the running time generally decreases as the number of repeated elements increases (with memory cache reducing the swap overhead). In the case where all elements are equal, Hoare partition scheme needlessly swaps elements, but the partitioning itself is best case, as noted in the Hoare partition section above.
</p><p>To solve the Lomuto partition scheme problem (sometimes called the Dutch national flag problem<sup class="reference" id="cite_ref-engineering_7-5">[7]</sup>), an alternative linear-time partition routine can be used that separates the values into three groups: values less than the pivot, values equal to the pivot, and values greater than the pivot. (Bentley and McIlroy call this a "fat partition" and it was already implemented in the <link href="mw-data:TemplateStyles:r886049734" rel="mw-deduplicated-inline-style"/><span class="monospaced">qsort</span> of Version 7 Unix.<sup class="reference" id="cite_ref-engineering_7-6">[7]</sup>) The values equal to the pivot are already sorted, so only the less-than and greater-than partitions need to be recursively sorted. In pseudocode, the quicksort algorithm becomes
</p>
<pre><b>algorithm</b> quicksort(A, lo, hi) <b>is</b>
    <b>if</b> lo &lt; hi <b>then</b>
        p := pivot(A, lo, hi)
        left, right := partition(A, p, lo, hi)  <i>// note: multiple return values</i>
        quicksort(A, lo, left - 1)
        quicksort(A, right + 1, hi)
</pre>
<p>The <code>partition</code> algorithm returns indices to the first ('leftmost') and to the last ('rightmost') item of the middle partition. Every item of the partition is equal to <code>p</code> and is therefore sorted. Consequently, the items of the partition need not be included in the recursive calls to <code>quicksort</code>.
</p><p>The best case for the algorithm now occurs when all elements are equal (or are chosen from a small set of <span class="texhtml"><i>k</i> ≪ <i>n</i></span> elements). In the case of all equal elements, the modified quicksort will perform only two recursive calls on empty subarrays and thus finish in linear time (assuming the <code>partition</code> subroutine takes no longer than linear time).
</p>
<h4><span class="mw-headline" id="Optimizations">Optimizations</span><span class="mw-editsection"></span></h4>
<p>Two other important optimizations, also suggested by Sedgewick and widely used in practice, are:<sup class="reference" id="cite_ref-glibc_qsort_19-0">[19]</sup><sup class="reference" id="cite_ref-20">[20]</sup>
</p>
<ul><li>To make sure at most <span class="texhtml"><i>O</i>(log <i>n</i>)</span> space is used, recur first into the smaller side of the partition, then use a tail call to recur into the other, or update the parameters to no longer include the now sorted smaller side, and iterate to sort the larger side.</li>
<li>When the number of elements is below some threshold (perhaps ten elements), switch to a non-recursive sorting algorithm such as insertion sort that performs fewer swaps, comparisons or other operations on such small arrays. The ideal 'threshold' will vary based on the details of the specific implementation.</li>
<li>An older variant of the previous optimization: when the number of elements is less than the threshold <span class="texhtml mvar" style="font-style:italic;">k</span>, simply stop; then after the whole array has been processed, perform insertion sort on it. Stopping the recursion early leaves the array <span class="texhtml mvar" style="font-style:italic;">k</span>-sorted, meaning that each element is at most <span class="texhtml mvar" style="font-style:italic;">k</span> positions away from its final sorted position. In this case, insertion sort takes <span class="texhtml"><i>O</i>(<i>kn</i>)</span> time to finish the sort, which is linear if <span class="texhtml mvar" style="font-style:italic;">k</span> is a constant.<sup class="reference" id="cite_ref-sedgewickQsortPaper_21-0">[21]</sup><sup class="reference" id="cite_ref-:3_12-1">[12]</sup><sup class="reference nowrap"><span title="Page / location: 117">: 117 </span></sup> Compared to the "many small sorts" optimization, this version may execute fewer instructions, but it makes suboptimal use of the cache memories in modern computers.<sup class="reference" id="cite_ref-LaMarca1999_22-0">[22]</sup></li></ul>
<h4><span class="mw-headline" id="Parallelization">Parallelization</span><span class="mw-editsection"></span></h4>
<p>Quicksort's divide-and-conquer formulation makes it amenable to parallelization using task parallelism. The partitioning step is accomplished through the use of a parallel prefix sum algorithm to compute an index for each array element in its section of the partitioned array.<sup class="reference" id="cite_ref-23">[23]</sup><sup class="reference" id="cite_ref-24">[24]</sup> Given an array of size <span class="texhtml mvar" style="font-style:italic;">n</span>, the partitioning step performs <span class="texhtml">O(<i>n</i>)</span> work in <span class="texhtml"><i>O</i>(log <i>n</i>)</span> time and requires <span class="texhtml">O(<i>n</i>)</span> additional scratch space. After the array has been partitioned, the two partitions can be sorted recursively in parallel. Assuming an ideal choice of pivots, parallel quicksort sorts an array of size <span class="texhtml mvar" style="font-style:italic;">n</span> in <span class="texhtml">O(<i>n</i> log <i>n</i>)</span> work in <span class="texhtml">O(log<sup>2</sup> <i>n</i>)</span> time using <span class="texhtml">O(<i>n</i>)</span> additional space.
</p><p>Quicksort has some disadvantages when compared to alternative sorting algorithms, like merge sort, which complicate its efficient parallelization. The depth of quicksort's divide-and-conquer tree directly impacts the algorithm's scalability, and this depth is highly dependent on the algorithm's choice of pivot. Additionally, it is difficult to parallelize the partitioning step efficiently in-place. The use of scratch space simplifies the partitioning step, but increases the algorithm's memory footprint and constant overheads.
</p><p>Other more sophisticated parallel sorting algorithms can achieve even better time bounds.<sup class="reference" id="cite_ref-25">[25]</sup> For example, in 1991 David Powers described a parallelized quicksort (and a related radix sort) that can operate in <span class="texhtml"><i>O</i>(log <i>n</i>)</span> time on a CRCW (concurrent read and concurrent write) PRAM (parallel random-access machine) with <span class="texhtml mvar" style="font-style:italic;">n</span> processors by performing partitioning implicitly.<sup class="reference" id="cite_ref-26">[26]</sup>
</p>
<h2><span class="mw-headline" id="Formal_analysis">Formal analysis</span><span class="mw-editsection"></span></h2>
<h3><span class="mw-headline" id="Worst-case_analysis">Worst-case analysis</span><span class="mw-editsection"></span></h3>
<p>The most unbalanced partition occurs when one of the sublists returned by the partitioning routine is of size <span class="texhtml"><i>n</i> − 1</span>.<sup class="reference" id="cite_ref-unbalanced_27-0">[27]</sup> This may occur if the pivot happens to be the smallest or largest element in the list, or in some implementations (e.g., the Lomuto partition scheme as described above) when all the elements are equal.
</p><p>If this happens repeatedly in every partition, then each recursive call processes a list of size one less than the previous list. Consequently, we can make <span class="texhtml"><i>n</i> − 1</span> nested calls before we reach a list of size 1. This means that the call tree is a linear chain of <span class="texhtml"><i>n</i> − 1</span> nested calls. The <span class="texhtml mvar" style="font-style:italic;">i</span>th call does <span class="texhtml"><i>O</i>(<i>n</i> − <i>i</i>)</span> work to do the partition, and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \textstyle \sum _{i=0}^{n}(n-i)=O(n^{2})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mstyle displaystyle="false" scriptlevel="0">
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>0</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mi>i</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>O</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>n</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mo stretchy="false">)</mo>
</mstyle>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \textstyle \sum _{i=0}^{n}(n-i)=O(n^{2})}</annotation>
</semantics>
</math></span><img alt="\textstyle \sum _{i=0}^{n}(n-i)=O(n^{2})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8829d4203c5b6319b5752064f10812e9aa8e3b20" style="vertical-align: -1.005ex; width:21.331ex; height:3.176ex;"/></span>, so in that case quicksort takes <span class="texhtml"><i>O</i>(<i>n</i><sup>2</sup>)</span> time.
</p>
<h3><span class="mw-headline" id="Best-case_analysis">Best-case analysis</span><span class="mw-editsection"></span></h3>
<p>In the most balanced case, each time we perform a partition we divide the list into two nearly equal pieces. This means each recursive call processes a list of half the size. Consequently, we can make only <span class="texhtml">log<sub>2</sub> <i>n</i></span> nested calls before we reach a list of size 1. This means that the depth of the call tree is <span class="texhtml">log<sub>2</sub> <i>n</i></span>. But no two calls at the same level of the call tree process the same part of the original list; thus, each level of calls needs only <span class="texhtml"><i>O</i>(<i>n</i>)</span> time all together (each call has some constant overhead, but since there are only <span class="texhtml"><i>O</i>(<i>n</i>)</span> calls at each level, this is subsumed in the <span class="texhtml"><i>O</i>(<i>n</i>)</span> factor). The result is that the algorithm uses only <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span> time.
</p>
<h3><span class="mw-headline" id="Average-case_analysis">Average-case analysis</span><span class="mw-editsection"></span></h3>
<p>To sort an array of <span class="texhtml mvar" style="font-style:italic;">n</span> distinct elements, quicksort takes <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span> time in expectation, averaged over all <span class="texhtml"><i>n</i>!</span> permutations of <span class="texhtml mvar" style="font-style:italic;">n</span> elements with equal probability. Alternatively, if the algorithm selects the pivot uniformly at random from the input array, the same analysis can be used to bound the expected running time for any input sequence; the expectation is then take over the random choices made by the algorithm (Cormen <i>et al.</i>, <i>Introduction to Algorithms</i>,<sup class="reference" id="cite_ref-:2_13-3">[13]</sup> Section 7.3).
</p><p>We list here three common proofs to this claim providing different insights into quicksort's workings.
</p>
<h4><span class="mw-headline" id="Using_percentiles">Using percentiles</span><span class="mw-editsection"></span></h4>
<p>If each pivot has rank somewhere in the middle 50 percent, that is, between the 25th percentile and the 75th percentile, then it splits the elements with at least 25% and at most 75% on each side. If we could consistently choose such pivots, we would only have to split the list at most <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \log _{4/3}n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>log</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>4</mn>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mn>3</mn>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \log _{4/3}n}</annotation>
</semantics>
</math></span><img alt="\log _{4/3}n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/472aaeba13d1c610fa5606a60d0f46510934ffe6" style="vertical-align: -1.171ex; width:7.452ex; height:3.009ex;"/></span> times before reaching lists of size 1, yielding an <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span> algorithm.
</p><p>When the input is a random permutation, the pivot has a random rank, and so it is not guaranteed to be in the middle 50 percent. However, when we start from a random permutation, in each recursive call the pivot has a random rank in its list, and so it is in the middle 50 percent about half the time. That is good enough. Imagine that a coin is flipped: heads means that the rank of the pivot is in the middle 50 percent, tail means that it isn't. Now imagine that the coin is flipped over and over until it gets <span class="texhtml mvar" style="font-style:italic;">k</span> heads. Although this could take a long time, on average only <span class="texhtml">2<i>k</i></span> flips are required, and the chance that the coin won't get <span class="texhtml mvar" style="font-style:italic;">k</span> heads after <span class="texhtml">100<i>k</i></span> flips is highly improbable (this can be made rigorous using Chernoff bounds). By the same argument, Quicksort's recursion will terminate on average at a call depth of only <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle 2\log _{4/3}n}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mn>2</mn>
<msub>
<mi>log</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>4</mn>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mn>3</mn>
</mrow>
</msub>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle 2\log _{4/3}n}</annotation>
</semantics>
</math></span><img alt="2\log _{4/3}n" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e78465031be8070063f91b1089c08e34f2ad7e7f" style="vertical-align: -1.171ex; width:9.001ex; height:3.009ex;"/></span>. But if its average call depth is <span class="texhtml"><i>O</i>(log <i>n</i>)</span>, and each level of the call tree processes at most <span class="texhtml mvar" style="font-style:italic;">n</span> elements, the total amount of work done on average is the product, <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span>. The algorithm does not have to verify that the pivot is in the middle half—if we hit it any constant fraction of the times, that is enough for the desired complexity.
</p>
<h4><span class="mw-headline" id="Using_recurrences">Using recurrences</span><span class="mw-editsection"></span></h4>
<p>An alternative approach is to set up a recurrence relation for the <span class="texhtml"><i>T</i>(<i>n</i>)</span> factor, the time needed to sort a list of size <span class="texhtml mvar" style="font-style:italic;">n</span>. In the most unbalanced case, a single quicksort call involves <span class="texhtml"><i>O</i>(<i>n</i>)</span> work plus two recursive calls on lists of size <span class="texhtml">0</span> and <span class="texhtml"><i>n</i>−1</span>, so the recurrence relation is
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle T(n)=O(n)+T(0)+T(n-1)=O(n)+T(n-1).}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>T</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>T</mi>
<mo stretchy="false">(</mo>
<mn>0</mn>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>T</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>T</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle T(n)=O(n)+T(0)+T(n-1)=O(n)+T(n-1).}</annotation>
</semantics>
</math></span><img alt="T(n)=O(n)+T(0)+T(n-1)=O(n)+T(n-1)." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b81a41c256cda3a04bf949533833270d7451d8d0" style="vertical-align: -0.838ex; width:52.454ex; height:2.843ex;"/></span></dd></dl>
<p>This is the same relation as for insertion sort and selection sort, and it solves to worst case <span class="texhtml"><i>T</i>(<i>n</i>) = <i>O</i>(<i>n</i><sup>2</sup>)</span>.
</p><p>In the most balanced case, a single quicksort call involves <span class="texhtml"><i>O</i>(<i>n</i>)</span> work plus two recursive calls on lists of size <span class="texhtml"><i>n</i>/2</span>, so the recurrence relation is
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle T(n)=O(n)+2T\left({\frac {n}{2}}\right).}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>T</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mn>2</mn>
<mi>T</mi>
<mrow>
<mo>(</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mi>n</mi>
<mn>2</mn>
</mfrac>
</mrow>
<mo>)</mo>
</mrow>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle T(n)=O(n)+2T\left({\frac {n}{2}}\right).}</annotation>
</semantics>
</math></span><img alt="T(n)=O(n)+2T\left({\frac {n}{2}}\right)." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bc4b7a2077256a99347a4b53ff4d22252e1a87a6" style="vertical-align: -1.838ex; width:24.983ex; height:4.843ex;"/></span></dd></dl>
<p>The master theorem for divide-and-conquer recurrences tells us that <span class="texhtml"><i>T</i>(<i>n</i>) = <i>O</i>(<i>n</i> log <i>n</i>)</span>.
</p><p>The outline of a formal proof of the <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span> expected time complexity follows. Assume that there are no duplicates as duplicates could be handled with linear time pre- and post-processing, or considered cases easier than the analyzed. When the input is a random permutation, the rank of the pivot is uniform random from 0 to <span class="texhtml"><i>n</i> − 1</span>. Then the resulting parts of the partition have sizes <span class="texhtml mvar" style="font-style:italic;">i</span> and <span class="texhtml"><i>n</i> − <i>i</i> − 1</span>, and i is uniform random from 0 to <span class="texhtml"><i>n</i> − 1</span>. So, averaging over all possible splits and noting that the number of comparisons for the partition is <span class="texhtml"><i>n</i> − 1</span>, the average number of comparisons over all permutations of the input sequence can be estimated accurately by solving the recurrence relation:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle C(n)=n-1+{\frac {1}{n}}\sum _{i=0}^{n-1}(C(i)+C(n-i-1))=n-1+{\frac {2}{n}}\sum _{i=0}^{n-1}C(i)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>1</mn>
<mi>n</mi>
</mfrac>
</mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>0</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</munderover>
<mo stretchy="false">(</mo>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>i</mi>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mi>i</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mi>n</mi>
</mfrac>
</mrow>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>0</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</munderover>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>i</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle C(n)=n-1+{\frac {1}{n}}\sum _{i=0}^{n-1}(C(i)+C(n-i-1))=n-1+{\frac {2}{n}}\sum _{i=0}^{n-1}C(i)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle C(n)=n-1+{\frac {1}{n}}\sum _{i=0}^{n-1}(C(i)+C(n-i-1))=n-1+{\frac {2}{n}}\sum _{i=0}^{n-1}C(i)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ed5e0c47601060f808fb99bc8520c60cde33b573" style="vertical-align: -3.005ex; width:65.998ex; height:7.343ex;"/></span></dd>
<dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle nC(n)=n(n-1)+2\sum _{i=0}^{n-1}C(i)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>n</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mn>2</mn>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>0</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</munderover>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>i</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle nC(n)=n(n-1)+2\sum _{i=0}^{n-1}C(i)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle nC(n)=n(n-1)+2\sum _{i=0}^{n-1}C(i)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/42473ab5d3cd4c35c7bc4ee929c3a3d718e06dcd" style="vertical-align: -3.005ex; width:30.575ex; height:7.343ex;"/></span></dd></dl>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle nC(n)-(n-1)C(n-1)=n(n-1)-(n-1)(n-2)+2C(n-1)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mi>n</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>−<!-- − --></mo>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mn>2</mn>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle nC(n)-(n-1)C(n-1)=n(n-1)-(n-1)(n-2)+2C(n-1)}</annotation>
</semantics>
</math></span><img alt="{\displaystyle nC(n)-(n-1)C(n-1)=n(n-1)-(n-1)(n-2)+2C(n-1)}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3ea64cf14d23269bfe275c1997949cfdb53c3600" style="vertical-align: -0.838ex; width:67.316ex; height:2.843ex;"/></span></dd></dl>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle nC(n)=(n+1)C(n-1)+2n-2}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mn>2</mn>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>2</mn>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle nC(n)=(n+1)C(n-1)+2n-2}</annotation>
</semantics>
</math></span><img alt="{\displaystyle nC(n)=(n+1)C(n-1)+2n-2}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0ca24632475205ce39882bc1fff54051942907bf" style="vertical-align: -0.838ex; width:35.044ex; height:2.843ex;"/></span></dd></dl>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\begin{aligned}{\frac {C(n)}{n+1}}&amp;={\frac {C(n-1)}{n}}+{\frac {2}{n+1}}-{\frac {2}{n(n+1)}}\leq {\frac {C(n-1)}{n}}+{\frac {2}{n+1}}\\&amp;={\frac {C(n-2)}{n-1}}+{\frac {2}{n}}-{\frac {2}{(n-1)n}}+{\frac {2}{n+1}}\leq {\frac {C(n-2)}{n-1}}+{\frac {2}{n}}+{\frac {2}{n+1}}\\&amp;\ \ \vdots \\&amp;={\frac {C(1)}{2}}+\sum _{i=2}^{n}{\frac {2}{i+1}}\leq 2\sum _{i=1}^{n-1}{\frac {1}{i}}\approx 2\int _{1}^{n}{\frac {1}{x}}\mathrm {d} x=2\ln n\end{aligned}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mtable columnalign="right left right left right left right left right left right left" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true" rowspacing="3pt">
<mtr>
<mtd>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mrow>
<mrow>
<mi>n</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
</mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
<mi>n</mi>
</mfrac>
</mrow>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mrow>
<mi>n</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mrow>
<mi>n</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
</mfrac>
</mrow>
<mo>≤<!-- ≤ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
<mi>n</mi>
</mfrac>
</mrow>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mrow>
<mi>n</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
<mrow>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mi>n</mi>
</mfrac>
</mrow>
<mo>−<!-- − --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mrow>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mi>n</mi>
</mrow>
</mfrac>
</mrow>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mrow>
<mi>n</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
<mo>≤<!-- ≤ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
</mrow>
<mrow>
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mi>n</mi>
</mfrac>
</mrow>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mrow>
<mi>n</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mtext> </mtext>
<mtext> </mtext>
<mo>⋮<!-- ⋮ --></mo>
</mtd>
</mtr>
<mtr>
<mtd></mtd>
<mtd>
<mi></mi>
<mo>=</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<mi>C</mi>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mrow>
<mn>2</mn>
</mfrac>
</mrow>
<mo>+</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>2</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mrow>
<mi>i</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
<mo>≤<!-- ≤ --></mo>
<mn>2</mn>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
<mo>−<!-- − --></mo>
<mn>1</mn>
</mrow>
</munderover>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>1</mn>
<mi>i</mi>
</mfrac>
</mrow>
<mo>≈<!-- ≈ --></mo>
<mn>2</mn>
<msubsup>
<mo>∫<!-- ∫ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</msubsup>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>1</mn>
<mi>x</mi>
</mfrac>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">d</mi>
</mrow>
<mi>x</mi>
<mo>=</mo>
<mn>2</mn>
<mi>ln</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
</mtd>
</mtr>
</mtable>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\begin{aligned}{\frac {C(n)}{n+1}}&amp;={\frac {C(n-1)}{n}}+{\frac {2}{n+1}}-{\frac {2}{n(n+1)}}\leq {\frac {C(n-1)}{n}}+{\frac {2}{n+1}}\\&amp;={\frac {C(n-2)}{n-1}}+{\frac {2}{n}}-{\frac {2}{(n-1)n}}+{\frac {2}{n+1}}\leq {\frac {C(n-2)}{n-1}}+{\frac {2}{n}}+{\frac {2}{n+1}}\\&amp;\ \ \vdots \\&amp;={\frac {C(1)}{2}}+\sum _{i=2}^{n}{\frac {2}{i+1}}\leq 2\sum _{i=1}^{n-1}{\frac {1}{i}}\approx 2\int _{1}^{n}{\frac {1}{x}}\mathrm {d} x=2\ln n\end{aligned}}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\begin{aligned}{\frac {C(n)}{n+1}}&amp;={\frac {C(n-1)}{n}}+{\frac {2}{n+1}}-{\frac {2}{n(n+1)}}\leq {\frac {C(n-1)}{n}}+{\frac {2}{n+1}}\\&amp;={\frac {C(n-2)}{n-1}}+{\frac {2}{n}}-{\frac {2}{(n-1)n}}+{\frac {2}{n+1}}\leq {\frac {C(n-2)}{n-1}}+{\frac {2}{n}}+{\frac {2}{n+1}}\\&amp;\ \ \vdots \\&amp;={\frac {C(1)}{2}}+\sum _{i=2}^{n}{\frac {2}{i+1}}\leq 2\sum _{i=1}^{n-1}{\frac {1}{i}}\approx 2\int _{1}^{n}{\frac {1}{x}}\mathrm {d} x=2\ln n\end{aligned}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3174160e1ef234d8900a269bfc0aef28c7b1633e" style="vertical-align: -11.838ex; width:73.37ex; height:24.676ex;"/></span></dd></dl>
<p>Solving the recurrence gives <span class="texhtml"><i>C</i>(<i>n</i>) = 2<i>n</i> ln <i>n</i> ≈ 1.39<i>n</i> log<sub>2</sub> <i>n</i></span>.
</p><p>This means that, on average, quicksort performs only about 39% worse than in its best case. In this sense, it is closer to the best case than the worst case. A comparison sort cannot use less than <span class="texhtml">log<sub>2</sub>(<i>n</i>!)</span> comparisons on average to sort <span class="texhtml mvar" style="font-style:italic;">n</span> items (as explained in the article Comparison sort) and in case of large <span class="texhtml mvar" style="font-style:italic;">n</span>, Stirling's approximation yields <span class="texhtml">log<sub>2</sub>(<i>n</i>!) ≈ <i>n</i>(log<sub>2</sub> <i>n</i> − log<sub>2</sub> <i>e</i>)</span>, so quicksort is not much worse than an ideal comparison sort. This fast average runtime is another reason for quicksort's practical dominance over other sorting algorithms.
</p>
<h4><span class="mw-headline" id="Using_a_binary_search_tree">Using a binary search tree</span><span class="mw-editsection"></span></h4>
<p>The following binary search tree (BST) corresponds to each execution of quicksort: the initial pivot is the root node; the pivot of the left half is the root of the left subtree, the pivot of the right half is the root of the right subtree, and so on. The number of comparisons of the execution of quicksort equals the number of comparisons during the construction of the BST by a sequence of insertions. So, the average number of comparisons for randomized quicksort equals the average cost of constructing a BST when the values inserted <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle (x_{1},x_{2},\ldots ,x_{n})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle (x_{1},x_{2},\ldots ,x_{n})}</annotation>
</semantics>
</math></span><img alt="(x_{1},x_{2},\ldots ,x_{n})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/47d8b3ec62633086002489cad8df4214e9585880" style="vertical-align: -0.838ex; width:15.337ex; height:2.843ex;"/></span> form a random permutation.
</p><p>Consider a BST created by insertion of a sequence <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle (x_{1},x_{2},\ldots ,x_{n})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle (x_{1},x_{2},\ldots ,x_{n})}</annotation>
</semantics>
</math></span><img alt="(x_{1},x_{2},\ldots ,x_{n})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/47d8b3ec62633086002489cad8df4214e9585880" style="vertical-align: -0.838ex; width:15.337ex; height:2.843ex;"/></span> of values forming a random permutation. Let <span class="texhtml mvar" style="font-style:italic;">C</span> denote the cost of creation of the BST. We have <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle C=\sum _{i}\sum _{j&lt;i}c_{i,j}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>C</mi>
<mo>=</mo>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</munder>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>&lt;</mo>
<mi>i</mi>
</mrow>
</munder>
<msub>
<mi>c</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>,</mo>
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle C=\sum _{i}\sum _{j&lt;i}c_{i,j}}</annotation>
</semantics>
</math></span><img alt="C=\sum _{i}\sum _{j&lt;i}c_{i,j}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/921aa43a360e47b12cf9babd977d24387dd8ad6c" style="vertical-align: -3.338ex; width:15.29ex; height:5.843ex;"/></span>, where <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle c_{i,j}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>c</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>,</mo>
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle c_{i,j}}</annotation>
</semantics>
</math></span><img alt="c_{i,j}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8504228ae66c6c24cc403c35a3df8d78771c9492" style="vertical-align: -1.005ex; width:2.941ex; height:2.343ex;"/></span> is a binary random variable expressing whether during the insertion of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
</semantics>
</math></span><img alt="x_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;"/></span> there was a comparison to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{j}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{j}}</annotation>
</semantics>
</math></span><img alt="x_{j}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5db47cb3d2f9496205a17a6856c91c1d3d363ccd" style="vertical-align: -1.005ex; width:2.239ex; height:2.343ex;"/></span>.
</p><p>By linearity of expectation, the expected value <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \operatorname {E} [C]}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi mathvariant="normal">E</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<mi>C</mi>
<mo stretchy="false">]</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \operatorname {E} [C]}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \operatorname {E} [C]}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2d00e09c61139656019942c3cd118d16b1cd3878" style="vertical-align: -0.838ex; width:4.643ex; height:2.843ex;"/></span> of <span class="texhtml mvar" style="font-style:italic;">C</span> is <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \operatorname {E} [C]=\sum _{i}\sum _{j&lt;i}\Pr(c_{i,j})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi mathvariant="normal">E</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<mi>C</mi>
<mo stretchy="false">]</mo>
<mo>=</mo>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</munder>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>&lt;</mo>
<mi>i</mi>
</mrow>
</munder>
<mo form="prefix" movablelimits="true">Pr</mo>
<mo stretchy="false">(</mo>
<msub>
<mi>c</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>,</mo>
<mi>j</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \operatorname {E} [C]=\sum _{i}\sum _{j&lt;i}\Pr(c_{i,j})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \operatorname {E} [C]=\sum _{i}\sum _{j&lt;i}\Pr(c_{i,j})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9949df370597c61d1573cace1261c7595d0f1ee7" style="vertical-align: -3.338ex; width:22.471ex; height:5.843ex;"/></span>.
</p><p>Fix <span class="texhtml mvar" style="font-style:italic;">i</span> and <span class="texhtml"><i>j</i>&lt;<i>i</i></span>. The values <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {x_{1},x_{2},\ldots ,x_{j}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {x_{1},x_{2},\ldots ,x_{j}}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {x_{1},x_{2},\ldots ,x_{j}}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9b988b3f1f93aae36696921a84b7280a6f982c17" style="vertical-align: -1.005ex; width:13.219ex; height:2.343ex;"/></span>, once sorted, define <span class="texhtml"><i>j</i>+1</span> intervals. The core structural observation is that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
</semantics>
</math></span><img alt="x_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;"/></span> is compared to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{j}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{j}}</annotation>
</semantics>
</math></span><img alt="x_{j}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5db47cb3d2f9496205a17a6856c91c1d3d363ccd" style="vertical-align: -1.005ex; width:2.239ex; height:2.343ex;"/></span> in the algorithm if and only if <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
</semantics>
</math></span><img alt="x_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;"/></span> falls inside one of the two intervals adjacent to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{j}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{j}}</annotation>
</semantics>
</math></span><img alt="x_{j}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5db47cb3d2f9496205a17a6856c91c1d3d363ccd" style="vertical-align: -1.005ex; width:2.239ex; height:2.343ex;"/></span>.
</p><p>Observe that since <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle (x_{1},x_{2},\ldots ,x_{n})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle (x_{1},x_{2},\ldots ,x_{n})}</annotation>
</semantics>
</math></span><img alt="(x_{1},x_{2},\ldots ,x_{n})" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/47d8b3ec62633086002489cad8df4214e9585880" style="vertical-align: -0.838ex; width:15.337ex; height:2.843ex;"/></span> is a random permutation, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle (x_{1},x_{2},\ldots ,x_{j},x_{i})}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mo stretchy="false">(</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msub>
<mo>,</mo>
<mo>…<!-- … --></mo>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
<mo>,</mo>
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle (x_{1},x_{2},\ldots ,x_{j},x_{i})}</annotation>
</semantics>
</math></span><img alt="{\displaystyle (x_{1},x_{2},\ldots ,x_{j},x_{i})}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/af35de0127ca752b50cb7efbd008a73fb3485d36" style="vertical-align: -1.005ex; width:18.192ex; height:3.009ex;"/></span> is also a random permutation, so the probability that <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{i}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{i}}</annotation>
</semantics>
</math></span><img alt="x_{i}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e87000dd6142b81d041896a30fe58f0c3acb2158" style="vertical-align: -0.671ex; width:2.129ex; height:2.009ex;"/></span> is adjacent to <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle x_{j}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>x</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle x_{j}}</annotation>
</semantics>
</math></span><img alt="x_{j}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5db47cb3d2f9496205a17a6856c91c1d3d363ccd" style="vertical-align: -1.005ex; width:2.239ex; height:2.343ex;"/></span> is exactly <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\frac {2}{j+1}}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mrow>
<mi>j</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\frac {2}{j+1}}}</annotation>
</semantics>
</math></span><img alt="{\frac {2}{j+1}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bea7e2b4b166968eeac0e0dc37ecb3f38f6dca11" style="vertical-align: -2.338ex; width:5.797ex; height:5.676ex;"/></span>.
</p><p>We end with a short calculation:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \operatorname {E} [C]=\sum _{i}\sum _{j&lt;i}{\frac {2}{j+1}}=O\left(\sum _{i}\log i\right)=O(n\log n).}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi mathvariant="normal">E</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<mi>C</mi>
<mo stretchy="false">]</mo>
<mo>=</mo>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</munder>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>j</mi>
<mo>&lt;</mo>
<mi>i</mi>
</mrow>
</munder>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mn>2</mn>
<mrow>
<mi>j</mi>
<mo>+</mo>
<mn>1</mn>
</mrow>
</mfrac>
</mrow>
<mo>=</mo>
<mi>O</mi>
<mrow>
<mo>(</mo>
<mrow>
<munder>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
</mrow>
</munder>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>i</mi>
</mrow>
<mo>)</mo>
</mrow>
<mo>=</mo>
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \operatorname {E} [C]=\sum _{i}\sum _{j&lt;i}{\frac {2}{j+1}}=O\left(\sum _{i}\log i\right)=O(n\log n).}</annotation>
</semantics>
</math></span><img alt="{\displaystyle \operatorname {E} [C]=\sum _{i}\sum _{j&lt;i}{\frac {2}{j+1}}=O\left(\sum _{i}\log i\right)=O(n\log n).}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d2dadca7408799f6c84e2f2e80c4099e56cbe970" style="vertical-align: -3.338ex; width:51.729ex; height:7.676ex;"/></span></dd></dl>
<h3><span class="mw-headline" id="Space_complexity">Space complexity</span><span class="mw-editsection"></span></h3>
<p>The space used by quicksort depends on the version used.
</p><p>The in-place version of quicksort has a space complexity of <span class="texhtml"><i>O</i>(log <i>n</i>)</span>, even in the worst case, when it is carefully implemented using the following strategies.
</p>
<ul><li>In-place partitioning is used. This unstable partition requires <span class="texhtml"><i>O</i>(1)</span> space.</li>
<li>After partitioning, the partition with the fewest elements is (recursively) sorted first, requiring at most <span class="texhtml"><i>O</i>(log <i>n</i>)</span> space. Then the other partition is sorted using tail recursion or iteration, which doesn't add to the call stack. This idea, as discussed above, was described by R. Sedgewick, and keeps the stack depth bounded by <span class="texhtml"><i>O</i>(log <i>n</i>)</span>.<sup class="reference" id="cite_ref-sedgewickBook_18-1">[18]</sup><sup class="reference" id="cite_ref-sedgewickQsortPaper_21-1">[21]</sup></li></ul>
<p>Quicksort with in-place and unstable partitioning uses only constant additional space before making any recursive call. Quicksort must store a constant amount of information for each nested recursive call. Since the best case makes at most <span class="texhtml"><i>O</i>(log <i>n</i>)</span> nested recursive calls, it uses <span class="texhtml"><i>O</i>(log <i>n</i>)</span> space. However, without Sedgewick's trick to limit the recursive calls, in the worst case quicksort could make <span class="texhtml"><i>O</i>(<i>n</i>)</span> nested recursive calls and need <span class="texhtml"><i>O</i>(<i>n</i>)</span> auxiliary space.
</p><p>From a bit complexity viewpoint, variables such as <i>lo</i> and <i>hi</i> do not use constant space; it takes <span class="texhtml"><i>O</i>(log <i>n</i>)</span> bits to index into a list of <span class="texhtml mvar" style="font-style:italic;">n</span> items. Because there are such variables in every stack frame, quicksort using Sedgewick's trick requires <span class="texhtml"><i>O</i>((log <i>n</i>)<sup>2</sup>)</span> bits of space. This space requirement isn't too terrible, though, since if the list contained distinct elements, it would need at least <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span> bits of space.
</p><p>Another, less common, not-in-place, version of quicksort uses <span class="texhtml"><i>O</i>(<i>n</i>)</span> space for working storage and can implement a stable sort. The working storage allows the input array to be easily partitioned in a stable manner and then copied back to the input array for successive recursive calls. Sedgewick's optimization is still appropriate.
</p>
<h2><span class="mw-headline" id="Relation_to_other_algorithms">Relation to other algorithms</span><span class="mw-editsection"></span></h2>
<p>Quicksort is a space-optimized version of the binary tree sort. Instead of inserting items sequentially into an explicit tree, quicksort organizes them concurrently into a tree that is implied by the recursive calls. The algorithms make exactly the same comparisons, but in a different order. An often desirable property of a sorting algorithm is stability – that is the order of elements that compare equal is not changed, allowing controlling order of multikey tables (e.g. directory or folder listings) in a natural way. This property is hard to maintain for in-place quicksort (that uses only constant additional space for pointers and buffers, and <span class="texhtml"><i>O</i>(log <i>n</i>)</span> additional space for the management of explicit or implicit recursion). For variant quicksorts involving extra memory due to representations using pointers (e.g. lists or trees) or files (effectively lists), it is trivial to maintain stability. The more complex, or disk-bound, data structures tend to increase time cost, in general making increasing use of virtual memory or disk.
</p><p>The most direct competitor of quicksort is heapsort. Heapsort's running time is <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span>, but heapsort's average running time is usually considered slower than in-place quicksort.<sup class="reference" id="cite_ref-28">[28]</sup> This result is debatable; some publications indicate the opposite.<sup class="reference" id="cite_ref-29">[29]</sup><sup class="reference" id="cite_ref-30">[30]</sup> Introsort is a variant of quicksort that switches to heapsort when a bad case is detected to avoid quicksort's worst-case running time. Major programming languages, such as C++ (in the GNU and LLVM implementations), use introsort.<sup class="reference" id="cite_ref-Kutenin-LLVM_31-0">[31]</sup>
</p><p>Quicksort also competes with merge sort, another <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span> sorting algorithm. Standard merge sort is an out-of-place stable sort, unlike standard in-place quicksort and heapsort, and has excellent worst-case performance.  The main disadvantage of mergesort is that, when operating on arrays, efficient implementations require <span class="texhtml"><i>O</i>(<i>n</i>)</span> auxiliary space, whereas the variant of quicksort with in-place partitioning and tail recursion uses only <span class="texhtml"><i>O</i>(log <i>n</i>)</span> space.
</p><p>Mergesort works very well on linked lists, requiring only a small, constant amount of auxiliary storage.  Although quicksort can be implemented as a stable sort using linked lists, it will often suffer from poor pivot choices without random access.  Mergesort is also the algorithm of choice for external sorting of very large data sets stored on slow-to-access media such as disk storage or network-attached storage.
</p><p>Bucket sort with two buckets is very similar to quicksort; the pivot in this case is effectively the value in the middle of the value range, which does well on average for uniformly distributed inputs.
</p>
<h3><span class="mw-headline" id="Selection-based_pivoting">Selection-based pivoting</span><span class="mw-editsection"></span></h3>
<p>A selection algorithm chooses the <span class="texhtml mvar" style="font-style:italic;">k</span>th smallest of a list of numbers; this is an easier problem in general than sorting. One simple but effective selection algorithm works nearly in the same manner as quicksort, and is accordingly known as quickselect. The difference is that instead of making recursive calls on both sublists, it only makes a single tail-recursive call on the sublist that contains the desired element. This change lowers the average complexity to linear or <span class="texhtml"><i>O</i>(<i>n</i>)</span> time, which is optimal for selection, but the selection algorithm is still <span class="texhtml"><i>O</i>(<i>n</i><sup>2</sup>)</span> in the worst case.
</p><p>A variant of quickselect, the median of medians algorithm, chooses pivots more carefully, ensuring that the pivots are near the middle of the data (between the 30th and 70th percentiles), and thus has guaranteed linear time – <span class="texhtml"><i>O</i>(<i>n</i>)</span>. This same pivot strategy can be used to construct a variant of quicksort (median of medians quicksort) with <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span> time. However, the overhead of choosing the pivot is significant, so this is generally not used in practice.
</p><p>More abstractly, given an <span class="texhtml"><i>O</i>(<i>n</i>)</span> selection algorithm, one can use it to find the ideal pivot (the median) at every step of quicksort and thus produce a sorting algorithm with <span class="texhtml"><i>O</i>(<i>n</i> log <i>n</i>)</span> running time. Practical implementations of this variant are considerably slower on average, but they are of theoretical interest because they show an optimal selection algorithm can yield an optimal sorting algorithm.
</p>
<h3><span class="mw-headline" id="Variants">Variants</span><span class="mw-editsection"></span></h3>
<h4><span class="mw-headline" id="Multi-pivot_quicksort">Multi-pivot quicksort</span><span class="mw-editsection"></span></h4>
<p>Instead of partitioning into two subarrays using a single pivot, multi-pivot quicksort (also multiquicksort<sup class="reference" id="cite_ref-LaMarca1999_22-1">[22]</sup>) partitions its input into some <span class="texhtml mvar" style="font-style:italic;">s</span> number of subarrays using <span class="texhtml"><i>s</i> − 1</span> pivots. While the dual-pivot case (<span class="texhtml"><i>s</i> = 3</span>) was considered by Sedgewick and others already in the mid-1970s, the resulting algorithms were not faster in practice than the "classical" quicksort.<sup class="reference" id="cite_ref-32">[32]</sup> A 1999 assessment of a multiquicksort with a variable number of pivots, tuned to make efficient use of processor caches, found it to increase the instruction count by some 20%, but simulation results suggested that it would be more efficient on very large inputs.<sup class="reference" id="cite_ref-LaMarca1999_22-2">[22]</sup> A version of dual-pivot quicksort developed by Yaroslavskiy in 2009<sup class="reference" id="cite_ref-:0_33-0">[33]</sup> turned out to be fast enough<sup class="reference" id="cite_ref-34">[34]</sup> to warrant implementation in Java 7, as the standard algorithm to sort arrays of primitives (sorting arrays of objects is done using Timsort).<sup class="reference" id="cite_ref-35">[35]</sup> The performance benefit of this algorithm was subsequently found to be mostly related to cache performance,<sup class="reference" id="cite_ref-36">[36]</sup> and experimental results indicate that the three-pivot variant may perform even better on modern machines.<sup class="reference" id="cite_ref-37">[37]</sup><sup class="reference" id="cite_ref-38">[38]</sup>
</p>
<h4><span class="mw-headline" id="External_quicksort">External quicksort</span><span class="mw-editsection"></span></h4>
<p>For disk files, an external sort based on partitioning similar to quicksort is possible. It is slower than external merge sort, but doesn't require extra disk space. 4 buffers are used, 2 for input, 2 for output. Let N = number of records in the file, B = the number of records per buffer, and M = N/B = the number of buffer segments in the file. Data is read (and written) from both ends of the file inwards. Let X represent the segments that start at the beginning of the file and Y represent segments that start at the end of the file. Data is read into the X and Y read buffers. A pivot record is chosen and the records in the X and Y buffers other than the pivot record are copied to the X write buffer in ascending order and Y write buffer in descending order based comparison with the pivot record. Once either X or Y buffer is filled, it is written to the file and the next X or Y buffer is read from the file. The process continues until all segments are read and one write buffer remains. If that buffer is an X write buffer, the pivot record is appended to it and the X buffer written. If that buffer is a Y write buffer, the pivot record is prepended to the Y buffer and the Y buffer written. This constitutes one partition step of the file, and the file is now composed of two subfiles. The start and end positions of each subfile are pushed/popped to a stand-alone stack or the main stack via recursion. To limit stack space to O(log2(n)), the smaller subfile is processed first. For a stand-alone stack, push the larger subfile parameters onto the stack, iterate on the smaller subfile. For recursion, recurse on the smaller subfile first, then iterate to handle the larger subfile. Once a sub-file is less than or equal to 4 B records, the subfile is sorted in-place via quicksort and written. That subfile is now sorted and in place in the file. The process is continued until all sub-files are sorted and in place. The average number of passes on the file is approximately 1 + ln(N+1)/(4 B), but worst case pattern is N passes (equivalent to O(n^2) for worst case internal sort).<sup class="reference" id="cite_ref-39">[39]</sup>
</p>
<h4><span class="mw-headline" id="Three-way_radix_quicksort">Three-way radix quicksort</span><span class="mw-editsection"></span></h4>
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style>
<p>This algorithm is a combination of radix sort and quicksort. Pick an element from the array (the pivot) and consider the first character (key) of the string (multikey). Partition the remaining elements into three sets: those whose corresponding character is less than, equal to, and greater than the pivot's character. Recursively sort the "less than" and "greater than" partitions on the same character. Recursively sort the "equal to" partition by the next character (key). Given we sort using bytes or words of length <span class="texhtml mvar" style="font-style:italic;">W</span> bits, the best case is <span class="texhtml"><i>O</i>(<i>KN</i>)</span> and the worst case <span class="texhtml"><i>O</i>(2<sup><i>K</i></sup><i>N</i>)</span> or at least <span class="texhtml"><i>O</i>(<i>N</i><sup>2</sup>)</span> as for standard quicksort, given for unique keys <span class="texhtml"><i>N</i>&lt;2<sup><i>K</i></sup></span>, and <span class="texhtml mvar" style="font-style:italic;">K</span> is a hidden constant in all standard comparison sort algorithms including quicksort. This is a kind of three-way quicksort in which the middle partition represents a (trivially) sorted subarray of elements that are <i>exactly</i> equal to the pivot.
</p>
<h4><span class="mw-headline" id="Quick_radix_sort">Quick radix sort</span><span class="mw-editsection"></span></h4>
<p>Also developed by Powers as an <span class="texhtml"><i>O</i>(<i>K</i>)</span> parallel PRAM algorithm. This is again a combination of radix sort and quicksort but the quicksort left/right partition decision is made on successive bits of the key, and is thus <span class="texhtml"><i>O</i>(<i>KN</i>)</span> for <span class="texhtml mvar" style="font-style:italic;">N</span> <span class="texhtml mvar" style="font-style:italic;">K</span>-bit keys. All comparison sort algorithms impliclty assume the transdichotomous model with <span class="texhtml mvar" style="font-style:italic;">K</span> in <span class="texhtml"><i>Θ</i>(log <i>N</i>)</span>, as if <span class="texhtml mvar" style="font-style:italic;">K</span> is smaller we can sort in <span class="texhtml"><i>O</i>(<i>N</i>)</span> time using a hash table or integer sorting.  If <span class="texhtml"><i>K</i> ≫ log <i>N</i></span> but elements are unique within <span class="texhtml"><i>O</i>(log <i>N</i>)</span> bits, the remaining bits will not be looked at by either quicksort or quick radix sort.  Failing that, all comparison sorting algorithms will also have the same overhead of looking through <span class="texhtml"><i>O</i>(<i>K</i>)</span> relatively useless bits but quick radix sort will avoid the worst case <span class="texhtml"><i>O</i>(<i>N</i><sup>2</sup>)</span> behaviours of standard quicksort and radix quicksort, and will be faster even in the best case of those comparison algorithms under these conditions of <span class="texhtml">uniqueprefix(<i>K</i>) ≫ log <i>N</i></span>. See Powers<sup class="reference" id="cite_ref-40">[40]</sup> for further discussion of the hidden overheads in comparison, radix and parallel sorting.
</p>
<h4><span class="mw-headline" id="BlockQuicksort">BlockQuicksort</span><span class="mw-editsection"></span></h4>
<p>In any comparison-based sorting algorithm, minimizing the number of comparisons requires maximizing the amount of information gained from each comparison, meaning that the comparison results are unpredictable.  This causes frequent branch mispredictions, limiting performance.<sup class="reference" id="cite_ref-41">[41]</sup> BlockQuicksort<sup class="reference" id="cite_ref-42">[42]</sup> rearranges the computations of quicksort to convert unpredictable branches to data dependencies.  When partitioning, the input is divided into moderate-sized blocks (which fit easily into the data cache), and two arrays are filled with the positions of elements to swap.  (To avoid conditional branches, the position is unconditionally stored at the end of the array, and the index of the end is incremented if a swap is needed.) A second pass exchanges the elements at the positions indicated in the arrays.  Both loops have only one conditional branch, a test for termination, which is usually taken.
</p><p>The BlockQuicksort technique is incorporated into LLVM's C++ STL implementation, libcxx, providing a 50% improvement on random integer sequences. Pattern-defeating quicksort (pdqsort), a version of introsort, also incorporates this technique.<sup class="reference" id="cite_ref-Kutenin-LLVM_31-1">[31]</sup>
</p>
<h4><span class="mw-headline" id="Partial_and_incremental_quicksort">Partial and incremental quicksort</span><span class="mw-editsection"></span></h4>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<p>Several variants of quicksort exist that separate the <span class="texhtml mvar" style="font-style:italic;">k</span> smallest or largest elements from the rest of the input.
</p>
<h3><span class="mw-headline" id="Generalization">Generalization</span><span class="mw-editsection"></span></h3>
<p>Richard Cole and David C. Kandathil, in 2004, discovered a one-parameter family of sorting algorithms, called partition sorts, which on average (with all input orderings equally likely) perform at most <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle n\log n+{O}(n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>n</mi>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>O</mi>
</mrow>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle n\log n+{O}(n)}</annotation>
</semantics>
</math></span><img alt="n\log n+{O}(n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1da176c1c292899e6fce0fb57ef6411c6e52d702" style="vertical-align: -0.838ex; width:14.353ex; height:2.843ex;"/></span> comparisons (close to the information theoretic lower bound) and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\Theta }(n\log n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">Θ<!-- Θ --></mi>
</mrow>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\Theta }(n\log n)}</annotation>
</semantics>
</math></span><img alt="{\Theta }(n\log n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0e6c2cf5a4e7fec90bb62d17ca48011035da5085" style="vertical-align: -0.838ex; width:10.153ex; height:2.843ex;"/></span> operations; at worst they perform <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\Theta }(n\log ^{2}n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">Θ<!-- Θ --></mi>
</mrow>
<mo stretchy="false">(</mo>
<mi>n</mi>
<msup>
<mi>log</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\Theta }(n\log ^{2}n)}</annotation>
</semantics>
</math></span><img alt="{\Theta }(n\log ^{2}n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9f1e0464ce5d4e27779b724dc57b399a5de5da2e" style="vertical-align: -0.838ex; width:11.207ex; height:3.176ex;"/></span> comparisons (and also operations); these are in-place, requiring only additional <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {O}(\log n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi>O</mi>
</mrow>
<mo stretchy="false">(</mo>
<mi>log</mi>
<mo>⁡<!-- ⁡ --></mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {O}(\log n)}</annotation>
</semantics>
</math></span><img alt="{O}(\log n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/43e18981f4be049b9e1602aa2db0bddd6472b3a2" style="vertical-align: -0.838ex; width:8.336ex; height:2.843ex;"/></span> space. Practical efficiency and smaller variance in performance were demonstrated against optimised quicksorts (of Sedgewick and Bentley-McIlroy).<sup class="reference" id="cite_ref-43">[43]</sup>
</p>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1128808480">.mw-parser-output .portalbox{padding:0;display:table;box-sizing:border-box;max-width:175px}.mw-parser-output .portalborder{border:solid #aaa 1px;padding:0.1em;background:#f9f9f9}.mw-parser-output .portalbox-entry{display:table-row;font-size:85%;line-height:110%;font-style:italic;font-weight:bold}.mw-parser-output .portalbox-image{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portalbox-link{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}@media(min-width:720px){.mw-parser-output .portalleft{clear:left;float:left;margin:0.5em 1em 0.5em 0}.mw-parser-output .portalright{clear:right;float:right;margin:0.5em 0 0.5em 1em}}</style>
<ul><li>Introsort – Hybrid sorting algorithm</li></ul>
<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<ul><li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1" id="CITEREFSedgewick1978">Sedgewick, R. (1978). "Implementing Quicksort programs". <i>Comm. ACM</i>. <b>21</b> (10): 847–857. doi:10.1145/359619.359631. S2CID 10020756.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Comm.+ACM&amp;rft.atitle=Implementing+Quicksort+programs&amp;rft.volume=21&amp;rft.issue=10&amp;rft.pages=847-857&amp;rft.date=1978&amp;rft_id=info%3Adoi%2F10.1145%2F359619.359631&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A10020756%23id-name%3DS2CID&amp;rft.aulast=Sedgewick&amp;rft.aufirst=R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1" id="CITEREFDean2006">Dean, B. C. (2006). "A simple expected running time analysis for randomized 'divide and conquer' algorithms". <i>Discrete Applied Mathematics</i>. <b>154</b>: 1–5. doi:10.1016/j.dam.2005.07.005.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Discrete+Applied+Mathematics&amp;rft.atitle=A+simple+expected+running+time+analysis+for+randomized+%27divide+and+conquer%27+algorithms&amp;rft.volume=154&amp;rft.pages=1-5&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1016%2Fj.dam.2005.07.005&amp;rft.aulast=Dean&amp;rft.aufirst=B.+C.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1" id="CITEREFHoare1961">Hoare, C. A. R. (1961). "Algorithm 63: Partition". <i>Comm. ACM</i>. <b>4</b> (7): 321. doi:10.1145/366622.366642. S2CID 52800011.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Comm.+ACM&amp;rft.atitle=Algorithm+63%3A+Partition&amp;rft.volume=4&amp;rft.issue=7&amp;rft.pages=321&amp;rft.date=1961&amp;rft_id=info%3Adoi%2F10.1145%2F366622.366642&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A52800011%23id-name%3DS2CID&amp;rft.aulast=Hoare&amp;rft.aufirst=C.+A.+R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1" id="CITEREFHoare1961">Hoare, C. A. R. (1961). "Algorithm 65: Find". <i>Comm. ACM</i>. <b>4</b> (7): 321–322. doi:10.1145/366622.366647.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Comm.+ACM&amp;rft.atitle=Algorithm+65%3A+Find&amp;rft.volume=4&amp;rft.issue=7&amp;rft.pages=321-322&amp;rft.date=1961&amp;rft_id=info%3Adoi%2F10.1145%2F366622.366647&amp;rft.aulast=Hoare&amp;rft.aufirst=C.+A.+R.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1" id="CITEREFHoare1962">Hoare, C. A. R. (1962). "Quicksort". <i>Comput. J.</i> <b>5</b> (1): 10–16. doi:<span class="cs1-lock-free" title="Freely accessible">10.1093/comjnl/5.1.10</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Comput.+J.&amp;rft.atitle=Quicksort&amp;rft.volume=5&amp;rft.issue=1&amp;rft.pages=10-16&amp;rft.date=1962&amp;rft_id=info%3Adoi%2F10.1093%2Fcomjnl%2F5.1.10&amp;rft.aulast=Hoare&amp;rft.aufirst=C.+A.+R.&amp;rft_id=%2F%2Fdoi.org%2F10.1093%252Fcomjnl%252F5.1.10&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span> (Reprinted in Hoare and Jones: <i>Essays in computing science</i>, 1989.)</li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1" id="CITEREFMusser1997">Musser, David R. (1997). "Introspective Sorting and Selection Algorithms". <i>Software: Practice and Experience</i>. <b>27</b> (8): 983–993. doi:10.1002/(SICI)1097-024X(199708)27:8&lt;983::AID-SPE117&gt;3.0.CO;2-#.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Software%3A+Practice+and+Experience&amp;rft.atitle=Introspective+Sorting+and+Selection+Algorithms&amp;rft.volume=27&amp;rft.issue=8&amp;rft.pages=983-993&amp;rft.date=1997&amp;rft_id=info%3Adoi%2F10.1002%2F%28SICI%291097-024X%28199708%2927%3A8%3C983%3A%3AAID-SPE117%3E3.0.CO%3B2-%23&amp;rft.aulast=Musser&amp;rft.aufirst=David+R.&amp;rft_id=http%3A%2F%2Fwww.cs.rpi.edu%2F~musser%2Fgp%2Fintrosort.ps&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span></li>
<li>Donald Knuth. <i>The Art of Computer Programming</i>, Volume 3: <i>Sorting and Searching</i>, Third Edition. Addison-Wesley, 1997. <link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/>ISBN 0-201-89685-0. Pages 113–122 of section 5.2.2: Sorting by Exchanging.</li>
<li>Thomas H. Cormen, Charles E. Leiserson, Ronald L. Rivest, and Clifford Stein. <i>Introduction to Algorithms</i>, Second Edition. MIT Press and McGraw-Hill, 2001. <link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/>ISBN 0-262-03293-7. Chapter 7: Quicksort, pp. 145–164.</li>
<li>Faron Moller. Analysis of Quicksort. CS 332: Designing Algorithms. Department of Computer Science, Swansea University.</li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1" id="CITEREFMartínezRoura2001">Martínez, C.; Roura, S. (2001). "Optimal Sampling Strategies in Quicksort and Quickselect". <i>SIAM J. Comput.</i> <b>31</b> (3): 683–705. CiteSeerX <span class="cs1-lock-free" title="Freely accessible">10.1.1.17.4954</span>. doi:10.1137/S0097539700382108.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=SIAM+J.+Comput.&amp;rft.atitle=Optimal+Sampling+Strategies+in+Quicksort+and+Quickselect&amp;rft.volume=31&amp;rft.issue=3&amp;rft.pages=683-705&amp;rft.date=2001&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.17.4954%23id-name%3DCiteSeerX&amp;rft_id=info%3Adoi%2F10.1137%2FS0097539700382108&amp;rft.aulast=Mart%C3%ADnez&amp;rft.aufirst=C.&amp;rft.au=Roura%2C+S.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1" id="CITEREFBentleyMcIlroy1993">Bentley, J. L.; McIlroy, M. D. (1993). "Engineering a sort function". <i>Software: Practice and Experience</i>. <b>23</b> (11): 1249–1265. CiteSeerX <span class="cs1-lock-free" title="Freely accessible">10.1.1.14.8162</span>. doi:10.1002/spe.4380231105. S2CID 8822797.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Software%3A+Practice+and+Experience&amp;rft.atitle=Engineering+a+sort+function&amp;rft.volume=23&amp;rft.issue=11&amp;rft.pages=1249-1265&amp;rft.date=1993&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.14.8162%23id-name%3DCiteSeerX&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A8822797%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1002%2Fspe.4380231105&amp;rft.aulast=Bentley&amp;rft.aufirst=J.+L.&amp;rft.au=McIlroy%2C+M.+D.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span></li></ul>
<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1097025294">.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:#f9f9f9}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1}}@media(min-width:720px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}</style>
<ul><li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation web cs1">"Animated Sorting Algorithms: Quick Sort". Archived from the original on 2 March 2015<span class="reference-accessdate">. Retrieved <span class="nowrap">25 November</span> 2008</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Animated+Sorting+Algorithms%3A+Quick+Sort&amp;rft_id=http%3A%2F%2Fwww.sorting-algorithms.com%2Fquick-sort&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span> – graphical demonstration</li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation web cs1">"Animated Sorting Algorithms: Quick Sort (3-way partition)". Archived from the original on 6 March 2015<span class="reference-accessdate">. Retrieved <span class="nowrap">25 November</span> 2008</span>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Animated+Sorting+Algorithms%3A+Quick+Sort+%283-way+partition%29&amp;rft_id=http%3A%2F%2Fwww.sorting-algorithms.com%2Fquick-sort-3-way&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AQuicksort"></span></li>
<li>Open Data Structures – Section 11.1.2 – Quicksort, Pat Morin</li>
<li>Interactive illustration of Quicksort, with code walkthrough</li></ul>

<!-- 
NewPP limit report
Parsed by mw2327
Cached time: 20221223231845
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.796 seconds
Real time usage: 1.025 seconds
Preprocessor visited node count: 11539/1000000
Post‐expand include size: 147093/2097152 bytes
Template argument size: 14895/2097152 bytes
Highest expansion depth: 17/100
Expensive parser function count: 7/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 153483/5000000 bytes
Lua time usage: 0.397/10.000 seconds
Lua memory usage: 8753058/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  788.687      1 -total
 38.93%  307.021      1 Template:Reflist
 13.62%  107.384     10 Template:Cite_web
 12.14%   95.781     96 Template:Math
 10.66%   84.054     18 Template:Cite_journal
  6.15%   48.535      1 Template:Short_description
  5.29%   41.703      1 Template:Sorting
  5.04%   39.747      1 Template:Navbox
  4.68%   36.885      4 Template:Fix
  4.60%   36.288      7 Template:Cite_book
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:3268249-0!canonical and timestamp 20221223231844 and revision id 1127527547.
 -->
</div></body>
</html>