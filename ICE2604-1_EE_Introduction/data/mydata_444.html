<!DOCTYPE html>
<html>
<head>
<title>Hamming_distance</title>
</head>
<body>
<div class="mw-parser-output">
<p class="mw-empty-elt">
</p>
<style data-mw-deduplicate="TemplateStyles:r1097763485">.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}</style><table class="box-More_footnotes plainlinks metadata ambox ambox-style ambox-More_footnotes" role="presentation"><tbody><tr><td class="mbox-image"></td><td class="mbox-text"></td></tr></tbody></table>
<style data-mw-deduplicate="TemplateStyles:r1066479718">.mw-parser-output .infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output .infobox-3cols-child{margin:auto}.mw-parser-output .infobox .navbar{font-size:100%}body.skin-minerva .mw-parser-output .infobox-header,body.skin-minerva .mw-parser-output .infobox-subheader,body.skin-minerva .mw-parser-output .infobox-above,body.skin-minerva .mw-parser-output .infobox-title,body.skin-minerva .mw-parser-output .infobox-image,body.skin-minerva .mw-parser-output .infobox-full-data,body.skin-minerva .mw-parser-output .infobox-below{text-align:center}</style><table class="infobox"><caption class="infobox-title">Hamming distance</caption><tbody><tr><td class="infobox-image" colspan="2"><table style="border-collapse:collapse;text-align:center;font-size:88%;line-height:1.25em;margin:auto;width:300px"><tbody><tr style="vertical-align:top"><td style="width:150px;text-align:center;:"></td><td style="width:150px;text-align:center;:"></td></tr></tbody></table></td></tr><tr><th class="infobox-label" scope="row">Class</th><td class="infobox-data">String similarity</td></tr><tr><th class="infobox-label" scope="row">Data structure</th><td class="infobox-data">string</td></tr><tr><th class="infobox-label" scope="row">Worst-case performance</th><td class="infobox-data"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n)}</annotation>
</semantics>
</math></span><img alt="O(n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34109fe397fdcff370079185bfdb65826cb5565a" style="vertical-align: -0.838ex; width:4.977ex; height:2.843ex;"/></span></td></tr><tr><th class="infobox-label" scope="row">Best-case performance</th><td class="infobox-data"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(1)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(1)}</annotation>
</semantics>
</math></span><img alt="O(1)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e66384bc40452c5452f33563fe0e27e803b0cc21" style="vertical-align: -0.838ex; width:4.745ex; height:2.843ex;"/></span></td></tr><tr><th class="infobox-label" scope="row">Average performance</th><td class="infobox-data"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n)}</annotation>
</semantics>
</math></span><img alt="O(n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34109fe397fdcff370079185bfdb65826cb5565a" style="vertical-align: -0.838ex; width:4.977ex; height:2.843ex;"/></span></td></tr><tr><th class="infobox-label" scope="row">Worst-case space complexity</th><td class="infobox-data"><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle O(n)}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>O</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle O(n)}</annotation>
</semantics>
</math></span><img alt="O(n)" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/34109fe397fdcff370079185bfdb65826cb5565a" style="vertical-align: -0.838ex; width:4.977ex; height:2.843ex;"/></span></td></tr></tbody></table>
<style data-mw-deduplicate="TemplateStyles:r1096954695/mw-parser-output/.tmulti">.mw-parser-output .tmulti .multiimageinner{display:flex;flex-direction:column}.mw-parser-output .tmulti .trow{display:flex;flex-direction:row;clear:left;flex-wrap:wrap;width:100%;box-sizing:border-box}.mw-parser-output .tmulti .tsingle{margin:1px;float:left}.mw-parser-output .tmulti .theader{clear:both;font-weight:bold;text-align:center;align-self:center;background-color:transparent;width:100%}.mw-parser-output .tmulti .thumbcaption{background-color:transparent}.mw-parser-output .tmulti .text-align-left{text-align:left}.mw-parser-output .tmulti .text-align-right{text-align:right}.mw-parser-output .tmulti .text-align-center{text-align:center}@media all and (max-width:720px){.mw-parser-output .tmulti .thumbinner{width:100%!important;box-sizing:border-box;max-width:none!important;align-items:center}.mw-parser-output .tmulti .trow{justify-content:center}.mw-parser-output .tmulti .tsingle{float:none!important;max-width:100%!important;box-sizing:border-box;text-align:center}.mw-parser-output .tmulti .tsingle .thumbcaption{text-align:left}.mw-parser-output .tmulti .trow>.thumbcaption{text-align:center}}</style>
<p>In information theory, the <b>Hamming distance</b> between two strings of equal length is the number of positions at which the corresponding symbols are different. In other words, it measures the minimum number of <i>substitutions</i> required to change one string into the other, or the minimum number of <i>errors</i> that could have transformed one string into the other. In a more general context, the Hamming distance is one of several string metrics for measuring the edit distance between two sequences. It is named after the American mathematician Richard Hamming.
</p><p>A major application is in coding theory, more specifically to block codes, in which the equal-length strings are vectors over a finite field.
</p>

<h2><span class="mw-headline" id="Definition">Definition</span><span class="mw-editsection"></span></h2>
<p>The Hamming distance between two equal-length strings of symbols is the number of positions at which the corresponding symbols are different.<sup class="reference" id="cite_ref-1">[1]</sup>
</p>
<h2><span class="mw-headline" id="Examples">Examples</span><span class="mw-editsection"></span></h2>
<p>The symbols may be letters, bits, or decimal digits, among other possibilities.  For example, the Hamming distance between:
</p>
<ul><li>"<b>ka<span style="color: red;">rol</span>in</b>"  and  "<b>ka<span style="color: red;">thr</span>in</b>"  is 3.</li>
<li>"<b>k<span style="color: red;">a</span>r<span style="color: red;">ol</span>in</b>"  and  "<b>k<span style="color: red;">e</span>r<span style="color: red;">st</span>in</b>"  is 3.</li>
<li>"<b>k<span style="color: red;">athr</span>in</b>"  and  "<b>k<span style="color: red;">erst</span>in</b>"  is 4.</li>
<li><b><span style="color: red;">0000</span></b>  and  <b><span style="color: red;">1111</span></b> is 4.</li>
<li><b>2<span style="color: red;">17</span>3<span style="color: red;">8</span>96</b>  and  <b>2<span style="color: red;">23</span>3<span style="color: red;">7</span>96</b>  is 3.</li></ul>
<h2><span class="mw-headline" id="Properties">Properties</span><span class="mw-editsection"></span></h2>
<p>For a fixed length <i>n</i>, the Hamming distance is a metric on the set of the words of length <i>n</i> (also known as a Hamming space), as it fulfills the conditions of non-negativity, symmetry, the Hamming distance of two words is 0 if and only if the two words are identical, and it satisfies the triangle inequality as well:<sup class="reference" id="cite_ref-Robinson2003_2-0">[2]</sup> Indeed, if we fix three words <i>a</i>, <i>b</i> and <i>c</i>, then whenever there is a difference between the <i>i</i>th letter of <i>a</i> and the <i>i</i>th letter of <i>c</i>, then there must be a difference between the <i>i</i>th letter of <i>a</i> and <i>i</i>th letter of <i>b</i>, or between the <i>i</i>th letter of <i>b</i> and the <i>i</i>th letter of <i>c</i>. Hence the Hamming distance between <i>a</i> and <i>c</i> is not larger than the sum of the Hamming distances between <i>a</i> and <i>b</i> and between <i>b</i> and <i>c</i>. The Hamming distance between two words <i>a</i> and <i>b</i> can also be seen as the Hamming weight of <i>a</i> − <i>b</i> for an appropriate choice of the − operator, much as the difference between two integers can be seen as a distance from zero on the number line.<sup class="noprint Inline-Template" style="margin-left:0.1em; white-space:nowrap;">[<i><span title="The text near this tag may need clarification or removal of jargon. (June 2020)">clarification needed</span></i>]</sup>
</p><p>For binary strings <i>a</i> and <i>b</i> the Hamming distance is equal to the number of ones (population count) in <i>a</i> XOR <i>b</i>.<sup class="reference" id="cite_ref-Warren_2013_3-0">[3]</sup> The metric space of length-<i>n</i> binary strings, with the Hamming distance, is known as the <i>Hamming cube</i>; it is equivalent as a metric space to the set of distances between vertices in a hypercube graph. One can also view a binary string of length <i>n</i> as a vector in <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle \mathbb {R} ^{n}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">R</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle \mathbb {R} ^{n}}</annotation>
</semantics>
</math></span><img alt="\mathbb {R} ^{n}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c510b63578322050121fe966f2e5770bea43308d" style="vertical-align: -0.338ex; width:2.897ex; height:2.343ex;"/></span> by treating each symbol in the string as a real coordinate; with this embedding, the strings form the vertices of an <i>n</i>-dimensional hypercube, and the Hamming distance of the strings is equivalent to the Manhattan distance between the vertices.
</p>
<h2><span class="mw-headline" id="Error_detection_and_error_correction">Error detection and error correction</span><span class="mw-editsection"></span></h2>
<p>The <b>minimum Hamming distance</b> is used to define some essential notions in coding theory, such as error detecting and error correcting codes. In particular, a code <i>C</i> is said to be <i>k</i> error detecting if, and only if, the minimum Hamming distance between any two of its codewords is at least <i>k</i>+1.<sup class="reference" id="cite_ref-Robinson2003_2-1">[2]</sup>
</p><p>For example, consider the code consisting of two codewords "000" and "111".  The hamming distance between these two words is 3, and therefore it is <i>k</i>=2 error detecting.  This means that if one bit is flipped or two bits are flipped, the error can be detected.  If three bits are flipped, then "000" becomes "111" and the error can not be detected.
</p><p>A code <i>C</i> is said to be <i>k-error correcting</i> if, for every word <i>w</i> in the underlying Hamming space <i>H</i>, there exists at most one codeword <i>c</i> (from <i>C</i>) such that the Hamming distance between <i>w</i> and <i>c</i> is at most <i>k</i>. In other words, a code is <i>k</i>-errors correcting if, and only if, the minimum Hamming distance between any two of its codewords is at least 2<i>k</i>+1. This is more easily understood geometrically as any closed balls of radius <i>k</i> centered on distinct codewords being disjoint.<sup class="reference" id="cite_ref-Robinson2003_2-2">[2]</sup> These balls are also called <i>Hamming spheres</i> in this context.<sup class="reference" id="cite_ref-cc17_4-0">[4]</sup>
</p><p>For example, consider the same 3 bit code consisting of two codewords "000" and "111".  The Hamming space consists of 8 words 000, 001, 010, 011, 100, 101, 110 and 111.  The codeword "000" and the single bit error words "001","010","100" are all less than or equal to the Hamming distance of 1 to "000".  Likewise, codeword "111" and its single bit error words "110","101" and "011" are all within 1 Hamming distance of the original "111".  In this code, a single bit error is always within 1 Hamming distance of the original codes, and the code can be <i>1-error correcting</i>, that is <i>k=1</i>. The minimum Hamming distance between "000" and "111" is 3, which satisfies <i>2k+1 = 3</i>.
</p><p>Thus a code with minimum Hamming distance <i>d</i> between its codewords can detect at most <i>d</i>-1 errors and can correct ⌊(<i>d</i>-1)/2⌋ errors.<sup class="reference" id="cite_ref-Robinson2003_2-3">[2]</sup> The latter number is also called the <i>packing radius</i> or the <i>error-correcting capability</i> of the code.<sup class="reference" id="cite_ref-cc17_4-1">[4]</sup>
</p>
<h2><span class="mw-headline" id="History_and_applications">History and applications</span><span class="mw-editsection"></span></h2>
<p>The Hamming distance is named after Richard Hamming, who introduced the concept in his fundamental paper on Hamming codes, <i>Error detecting and error correcting codes</i>, in 1950.<sup class="reference" id="cite_ref-5">[5]</sup> Hamming weight analysis of bits is used in several disciplines including information theory, coding theory, and cryptography.
</p><p>It is used in telecommunication to count the number of flipped bits in a fixed-length binary word as an estimate of error, and therefore is sometimes called the <b>signal distance</b>.<sup class="reference" id="cite_ref-Ayala2012_6-0">[6]</sup> For <i>q</i>-ary strings over an alphabet of size <i>q</i> ≥ 2 the Hamming distance is applied in case of the q-ary symmetric channel, while the Lee distance is used for phase-shift keying or more generally channels susceptible to synchronization errors because the Lee distance accounts for errors of ±1.<sup class="reference" id="cite_ref-Roth2006_7-0">[7]</sup> If <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle q=2}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>q</mi>
<mo>=</mo>
<mn>2</mn>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle q=2}</annotation>
</semantics>
</math></span><img alt="q=2" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/26622af6012fb982cab4e9584f57dd4f364233b7" style="vertical-align: -0.671ex; width:5.33ex; height:2.509ex;"/></span> or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle q=3}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>q</mi>
<mo>=</mo>
<mn>3</mn>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle q=3}</annotation>
</semantics>
</math></span><img alt="{\displaystyle q=3}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2d859ff2e5023ed1f714ccace69e88ab993a5f43" style="vertical-align: -0.671ex; width:5.33ex; height:2.509ex;"/></span> both distances coincide because any pair of elements from <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\textstyle \mathbb {Z} /2\mathbb {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">Z</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mn>2</mn>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\textstyle \mathbb {Z} /2\mathbb {Z} }</annotation>
</semantics>
</math></span><img alt="{\textstyle \mathbb {Z} /2\mathbb {Z} }" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4c9b3fa90898e3378d925bb1e2b191f2ff92a5eb" style="vertical-align: -0.838ex; width:5.426ex; height:2.843ex;"/></span> or <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\textstyle \mathbb {Z} /3\mathbb {Z} }" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="false" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">Z</mi>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mn>3</mn>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="double-struck">Z</mi>
</mrow>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\textstyle \mathbb {Z} /3\mathbb {Z} }</annotation>
</semantics>
</math></span><img alt="{\textstyle \mathbb {Z} /3\mathbb {Z} }" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/890848811f0aafa82a3a5637dcb726b10273a3b8" style="vertical-align: -0.838ex; width:5.426ex; height:2.843ex;"/></span> differ by 1, but the distances are different for larger <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle q}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>q</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle q}</annotation>
</semantics>
</math></span><img alt="q" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/06809d64fa7c817ffc7e323f85997f783dbdf71d" style="vertical-align: -0.671ex; width:1.07ex; height:2.009ex;"/></span>.
</p><p>The Hamming distance is also used in systematics as a measure of genetic distance.<sup class="reference" id="cite_ref-8">[8]</sup>
</p><p>However, for comparing strings of different lengths, or strings where not just substitutions but also insertions or deletions have to be expected, a more sophisticated metric like the Levenshtein distance is more appropriate.
</p>
<h2><span class="mw-headline" id="Algorithm_example">Algorithm example</span><span class="mw-editsection"></span></h2>
<p>The following function, written in Python 3, returns the Hamming distance between two strings:
</p>

<p>Or, in a shorter expression:
</p>

<p>The function <code>hamming_distance()</code>, implemented in Python 3, computes the Hamming distance between two strings (or other iterable objects) of equal length by creating a sequence of Boolean values indicating mismatches and matches between corresponding positions in the two inputs, then summing the sequence with True and False values, interpreted as one and zero, respectively.
</p>


<p>where the zip() function merges two equal-length collections in pairs.
</p><p>The following C function will compute the Hamming distance of two integers (considered as binary values, that is, as sequences of bits). The running time of this procedure is proportional to the Hamming distance rather than to the number of bits in the inputs. It computes the bitwise exclusive or of the two inputs, and then finds the Hamming weight of the result (the number of nonzero bits) using an algorithm of Wegner (1960) that repeatedly finds and clears the lowest-order nonzero bit.  Some compilers support the __builtin_popcount function which can calculate this using specialized processor hardware where available.
</p>

<p>A faster alternative is to use the population count (<i>popcount</i>) assembly instruction. Certain compilers such as GCC and Clang make it available via an intrinsic function:
</p>

<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1128808480">.mw-parser-output .portalbox{padding:0;display:table;box-sizing:border-box;max-width:175px}.mw-parser-output .portalborder{border:solid #aaa 1px;padding:0.1em;background:#f9f9f9}.mw-parser-output .portalbox-entry{display:table-row;font-size:85%;line-height:110%;font-style:italic;font-weight:bold}.mw-parser-output .portalbox-image{display:table-cell;padding:0.2em;vertical-align:middle;text-align:center}.mw-parser-output .portalbox-link{display:table-cell;padding:0.2em 0.2em 0.2em 0.3em;vertical-align:middle}@media(min-width:720px){.mw-parser-output .portalleft{clear:left;float:left;margin:0.5em 1em 0.5em 0}.mw-parser-output .portalright{clear:right;float:right;margin:0.5em 0 0.5em 1em}}</style>
<ul><li>Closest string</li>
<li>Damerau–Levenshtein distance</li>
<li>Euclidean distance</li>
<li>Gap-Hamming problem</li>
<li>Gray code</li>
<li>Jaccard index</li>
<li>Levenshtein distance</li>
<li>Mahalanobis distance</li>
<li>Mannheim distance</li>
<li>Sørensen similarity index</li>
<li>Sparse distributed memory</li>
<li>Word ladder</li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"></span></h2>
<ul><li><style data-mw-deduplicate="TemplateStyles:r1041539562">.mw-parser-output .citation{word-wrap:break-word}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}</style><span class="citation 1037C"><img alt="Public Domain" class="noviewer" data-file-height="196" data-file-width="196" decoding="async" height="12" src="//upload.wikimedia.org/wikipedia/en/thumb/6/62/PD-icon.svg/12px-PD-icon.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/6/62/PD-icon.svg/18px-PD-icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/6/62/PD-icon.svg/24px-PD-icon.svg.png 2x" width="12"/> This article incorporates public domain material from <link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation cs1"><i>Federal Standard 1037C</i>. General Services Administration. Archived from the original on 2022-01-22.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Federal+Standard+1037C&amp;rft.pub=General+Services+Administration&amp;rft_id=https%3A%2F%2Fwww.its.bldrdoc.gov%2Ffs-1037%2Ffs-1037c.htm&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHamming+distance"></span></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation journal cs1" id="CITEREFWegner1960">Wegner, Peter (1960). "A technique for counting ones in a binary computer". <i>Communications of the ACM</i>. <b>3</b> (5): 322. doi:10.1145/367236.367286. S2CID 31683715.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Communications+of+the+ACM&amp;rft.atitle=A+technique+for+counting+ones+in+a+binary+computer&amp;rft.volume=3&amp;rft.issue=5&amp;rft.pages=322&amp;rft.date=1960&amp;rft_id=info%3Adoi%2F10.1145%2F367236.367286&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A31683715%23id-name%3DS2CID&amp;rft.aulast=Wegner&amp;rft.aufirst=Peter&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHamming+distance"></span></li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation book cs1" id="CITEREFMacKay2003">MacKay, David J. C. (2003). <i>Information Theory, Inference, and Learning Algorithms</i>. Cambridge: Cambridge University Press. ISBN <bdi>0-521-64298-1</bdi>.</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Information+Theory%2C+Inference%2C+and+Learning+Algorithms&amp;rft.place=Cambridge&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2003&amp;rft.isbn=0-521-64298-1&amp;rft.aulast=MacKay&amp;rft.aufirst=David+J.+C.&amp;rft_id=http%3A%2F%2Fwww.inference.phy.cam.ac.uk%2Fmackay%2Fitila%2Fbook.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHamming+distance"></span></li></ul>


<!-- 
NewPP limit report
Parsed by mw2392
Cached time: 20221222032826
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.398 seconds
Real time usage: 0.590 seconds
Preprocessor visited node count: 1890/1000000
Post‐expand include size: 59850/2097152 bytes
Template argument size: 2932/2097152 bytes
Highest expansion depth: 17/100
Expensive parser function count: 11/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 50588/5000000 bytes
Lua time usage: 0.239/10.000 seconds
Lua memory usage: 8252129/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  459.821      1 -total
 23.69%  108.949      1 Template:Reflist
 17.88%   82.230      6 Template:Cite_book
 14.19%   65.266      1 Template:Short_description
  9.60%   44.121      1 Template:More_inline
  9.06%   41.645      1 Template:Strings
  8.74%   40.190      2 Template:Pagetype
  8.63%   39.702      1 Template:Ambox
  8.55%   39.313      1 Template:Navbox
  7.79%   35.841      1 Template:Harvtxt
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:41227-0!canonical and timestamp 20221222032825 and revision id 1127023838.
 -->
</div></body>
</html>