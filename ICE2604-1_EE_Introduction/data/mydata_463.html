<!DOCTYPE html>
<html>
<head>
<title>heuristic</title>
</head>
<body>
<div class="mw-parser-output">
<style data-mw-deduplicate="TemplateStyles:r1033289096">.mw-parser-output .hatnote{font-style:italic}.mw-parser-output div.hatnote{padding-left:1.6em;margin-bottom:0.5em}.mw-parser-output .hatnote i{font-style:normal}.mw-parser-output .hatnote+link+.hatnote{margin-top:-0.5em}</style>
<p>A <b>heuristic</b> (<span class="rt-commentedText nowrap"><span class="IPA nopopups noexcerpt" lang="en-fonipa">/<span style="border-bottom:1px dotted"><span title="'h' in 'hi'">h</span><span title="/j/: 'y' in 'yes'">j</span><span title="/ʊ/: 'u' in 'push'">ʊ</span><span title="/ˈ/: primary stress follows">ˈ</span><span title="'r' in 'rye'">r</span><span title="/ɪ/: 'i' in 'kit'">ɪ</span><span title="'s' in 'sigh'">s</span><span title="'t' in 'tie'">t</span><span title="/ɪ/: 'i' in 'kit'">ɪ</span><span title="'k' in 'kind'">k</span></span>/</span></span>; from Ancient Greek <i> </i>εὑρίσκω<i> (heurískō)</i> 'I find, discover'), or <b>heuristic technique</b>, is any approach to problem solving or self-discovery that employs a practical method that is not guaranteed to be optimal, perfect, or rational, but is nevertheless sufficient for reaching an immediate, short-term goal or approximation. Where finding an optimal solution is impossible or impractical, heuristic methods can be used to speed up the process of finding a satisfactory solution. Heuristics can be mental shortcuts that ease the cognitive load of making a decision.<sup class="reference" id="cite_ref-1">[1]</sup><sup class="reference" id="cite_ref-conceptually_2-0">[2]</sup>
</p><p>Examples that employ heuristics include using trial and error, a rule of thumb or an educated guess.
</p><p>Heuristics are the strategies derived from previous experiences with similar problems. These strategies depend on using readily accessible, though loosely applicable, information to control problem solving in human beings, machines and abstract issues.<sup class="reference" id="cite_ref-3">[3]</sup><sup class="reference" id="cite_ref-4">[4]</sup> When an individual applies a heuristic in practice, it generally performs as expected. However it can alternatively create systematic errors.<sup class="reference" id="cite_ref-5">[5]</sup>
</p><p>
The most fundamental heuristic is trial and error, which can be used in everything from matching nuts and bolts to finding the values of variables in algebra problems. In mathematics, some common heuristics involve the use of visual representations, additional assumptions, forward/backward reasoning and simplification. Here are a few commonly used heuristics from George Pólya's 1945 book, <i>How to Solve It</i>:<sup class="reference" id="cite_ref-6">[6]</sup><style data-mw-deduplicate="TemplateStyles:r996844942">.mw-parser-output .templatequote{overflow:hidden;margin:1em 0;padding:0 40px}.mw-parser-output .templatequote .templatequotecite{line-height:1.5em;text-align:left;padding-left:1.6em;margin-top:0}</style></p><blockquote class="templatequote">
<ul><li>When experiencing a difficulty in understanding a problem, draw the architecture from all directions e.g. top-view, side-view, front-view.</li>
<li>If you can't find a solution, try assuming that you have a solution and seeing what you can derive from that ("working backward"). AKA "what shape would it have" aka system-requirements.</li>
<li>If the problem is abstract, try examining a concrete example.</li>
<li>Try solving a more general problem first (the "inventor's paradox": the more ambitious plan may have more chances of success).</li></ul></blockquote><p> This is because only the general problem can provide to a specific problem—a context from which to draw meaning.
</p><p>In psychology, heuristics are simple, efficient rules, either learned or inculcated by evolutionary processes. These psychological heuristics have been proposed to explain how people make decisions, come to judgements, and solve problems. These rules typically come into play when people face complex problems or incomplete information. Researchers employ various methods to test whether people use these rules. The rules have been shown to work well under most circumstances, but in certain cases can lead to systematic errors or cognitive biases.<sup class="reference" id="cite_ref-7">[7]</sup>
</p>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"></span></h2>
<p>The study of heuristics in human decision-making was developed in the 1970s and the 1980s by the psychologists Amos Tversky and Daniel Kahneman,<sup class="reference" id="cite_ref-Kahneman_8-0">[8]</sup> although the concept had been originally introduced by the Nobel laureate Herbert A. Simon. Simon's original primary object of research was problem solving that showed that we operate within what he calls <i>bounded rationality</i>. He coined the term <i>satisficing</i>, which denotes a situation in which people seek solutions, or accept choices or judgements, that are "good enough" for their purposes although they could be optimised.<sup class="reference" id="cite_ref-9">[9]</sup>
</p><p>Rudolf Groner analysed the history of heuristics from its roots in ancient Greece up to contemporary work in cognitive psychology and artificial intelligence,<sup class="reference" id="cite_ref-10">[10]</sup> proposing a cognitive style "heuristic versus algorithmic thinking", which can be assessed by means of a validated questionnaire.<sup class="reference" id="cite_ref-11">[11]</sup>
</p>
<h3><span class="mw-headline" id="Adaptive_toolbox">Adaptive toolbox</span><span class="mw-editsection"></span></h3>
<p>Gerd Gigerenzer and his research group argued that models of heuristics need to be formal to allow for predictions of behavior that can be tested.<sup class="reference" id="cite_ref-12">[12]</sup> They study the fast and frugal heuristics in the "adaptive toolbox" of individuals or institutions, and the ecological rationality of these heuristics; that is, the conditions under which a given heuristic is likely to be successful.<sup class="reference" id="cite_ref-13">[13]</sup> The descriptive study of the "adaptive toolbox" is done by observation and experiment, the prescriptive study of the ecological rationality requires mathematical analysis and computer simulation. Heuristics – such as the recognition heuristic, the take-the-best heuristic and fast-and-frugal trees – have been shown to be effective in predictions, particularly in situations of uncertainty. It is often said that heuristics trade accuracy for effort but this is only the case in situations of risk. Risk refers to situations where all possible actions, their outcomes and probabilities are known. In the absence of this information, that is under uncertainty, heuristics can achieve higher accuracy with lower effort.<sup class="reference" id="cite_ref-14">[14]</sup> This finding, known as a less-is-more effect, would not have been found without formal models. The valuable insight of this program is that heuristics are effective not despite their simplicity — but because of it. Furthermore, Gigerenzer and Wolfgang Gaissmaier found that both individuals and organisations rely on heuristics in an adaptive way.<sup class="reference" id="cite_ref-15">[15]</sup>
</p>
<h3><span class="mw-headline" id="Cognitive-experiential_self-theory">Cognitive-experiential self-theory</span><span class="mw-editsection"></span></h3>
<p>Heuristics, through greater refinement and research, have begun to be applied to other theories, or be explained by them. For example, the cognitive-experiential self-theory (CEST) also is an adaptive view of heuristic processing. CEST breaks down two systems that process information. At some times, roughly speaking, individuals consider issues rationally, systematically, logically, deliberately, effortfully and verbally. On other occasions, individuals consider issues intuitively, effortlessly, globally, and emotionally.<sup class="reference" id="cite_ref-16">[16]</sup> From this perspective, heuristics are part of a larger experiential processing system that is often adaptive, but vulnerable to error in situations that require logical analysis.<sup class="reference" id="cite_ref-17">[17]</sup>
</p>
<h3><span class="mw-headline" id="Attribute_substitution">Attribute substitution</span><span class="mw-editsection"></span></h3>
<p>In 2002, Daniel Kahneman and Shane Frederick proposed that cognitive heuristics work by a process called <i>attribute substitution</i>, which happens without conscious awareness.<sup class="reference" id="cite_ref-revisited_18-0">[18]</sup> According to this theory, when somebody makes a judgement (of a "target attribute") that is computationally complex, a more easily calculated "heuristic attribute" is substituted. In effect, a cognitively difficult problem is dealt with by answering a rather simpler problem, without being aware of this happening.<sup class="reference" id="cite_ref-revisited_18-1">[18]</sup> This theory explains cases where judgements fail to show regression toward the mean.<sup class="reference" id="cite_ref-19">[19]</sup> Heuristics can be considered to reduce the complexity of clinical judgments in health care.<sup class="reference" id="cite_ref-20">[20]</sup>
</p>
<h2><span class="mw-headline" id="Psychology">Psychology</span><span class="mw-editsection"></span></h2>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<h3><span class="mw-headline" id="Informal_models_of_heuristics">Informal models of heuristics</span><span class="mw-editsection"></span></h3>
<ul><li>Affect heuristic: a mental shortcut which uses emotion to influence the decision. Emotion is the effect that plays the lead role that makes the decision or solves the problem quickly or efficiently. It is used while judging the risks and benefits of something, depending on the positive or negative feelings that people associate with a stimulus. It can also be considered the gut decision since if the gut feeling is right, then the benefits are high and the risks are low.<sup class="reference" id="cite_ref-21">[21]</sup></li>
<li>Anchoring and adjustment: describes the common human tendency to rely more heavily on the first piece of information offered (the "anchor") when making decisions. For example, in a study done with children, the children were told to estimate the number of jellybeans in a jar. Groups of children were given either a high or low "base" number (anchor). Children estimated the number of jellybeans to be closer to the anchor number that they were given.<sup class="reference" id="cite_ref-22">[22]</sup></li>
<li>Availability heuristic: a mental shortcut that occurs when people make judgements about the probability of events by the ease with which examples come to mind. For example, in a 1973 Tversky &amp; Kahneman experiment, the majority of participants reported that there were more words in the English language that start with the letter K than for which K was the third letter. There are actually twice as many words in the English Language that have K as the third letter as those that start with K, but words that start with K are much easier to recall and bring to mind.<sup class="reference" id="cite_ref-Harvey_23-0">[23]</sup></li>
<li>Balance heuristic: applies to when an individual balances the negative and positive effects from a decision which makes the choice obvious.<sup class="reference" id="cite_ref-Ross_24-0">[24]</sup></li>
<li>Base rate heuristic: when a decision involves probability this is a mental shortcut that uses relevant data to determine the probability of an outcome occurring. When using this Heuristic there is a common issue where individuals misjudge the likelihood of a situation. For example, if there is a test for a disease which has an accuracy of 90%, people may think it's a 90% they have the disease even though the disease only affects 1 in 500 people.<sup class="reference" id="cite_ref-Dale_25-0">[25]</sup></li>
<li>Common sense heuristic: used frequently by individuals when the potential outcomes of a decision appear obvious. For example, when your television remote stops working, you would probably change the batteries.<sup class="reference" id="cite_ref-Ross_24-1">[24]</sup></li>
<li>Contagion heuristic: follows the Law of Contagion or Similarity. This leads people to avoid others that are viewed as "contaminated" to the observer. This happens due to the fact of the observer viewing something that is seen as bad or to seek objects that have been associated with what seems good. Some things one can view as harmful can tend not to really be. This sometimes leads to irrational thinking on behalf of the observer.<sup class="reference" id="cite_ref-26">[26]</sup></li>
<li>Default heuristic: in real world models, it is common for consumers to apply this heuristic when selecting the default option regardless of whether the option was their preference.<sup class="reference" id="cite_ref-27">[27]</sup></li>
<li>Educated guess heuristic: when an individual responds to a decision using relevant information they have stored relating to the problem.<sup class="reference" id="cite_ref-28">[28]</sup></li>
<li>Effort heuristic: the worth of an object is determined by the amount of effort put into the production of the object. Objects that took longer to produce are more valuable while the objects that took less time are deemed not as valuable. Also applies to how much effort is put into achieving the product. This can be seen as the difference of working and earning the object versus finding the object on the side of the street. It can be the same object but the one found will not be deemed as valuable as the one that we earned.</li>
<li>Escalation of commitment: describes the phenomenon where people justify increased investment in a decision, based on the cumulative prior investment, despite new evidence suggesting that the cost, starting today, of continuing the decision outweighs the expected benefit. This is related to the sunk cost fallacy.</li>
<li>Fairness heuristic: applies to the reaction of an individual to a decision from an authoritative figure. If the decision is enacted in a fair manner the likelihood of the individual to comply voluntarily is higher than if it is unfair.<sup class="reference" id="cite_ref-29">[29]</sup></li>
<li>Familiarity heuristic: a mental shortcut applied to various situations in which individuals assume that the circumstances underlying the past behavior still hold true for the present situation and that the past behavior thus can be correctly applied to the new situation. Especially prevalent when the individual experiences a high cognitive load.<sup class="reference" id="cite_ref-30">[30]</sup></li>
<li>Naïve diversification: when asked to make several choices at once, people tend to diversify more than when making the same type of decision sequentially.</li>
<li>Peak–end rule: a person's subjective perceptions during the most intense and final moments of an event are averaged together into a single judgment.<sup class="reference" id="cite_ref-31">[31]</sup> For example, a person might judge the difficulty of a workout by taking into consideration only the most demanding part of the workout (e.g., Tabata sprints) and what happens at the very end (e.g., a cool-down). In this way, a difficult workout such as the one described here could be perceived as "easier" than a more relaxed workout that did not vary in intensity (e.g., 45 minutes of cycling in aerobic zone 3, without cool-down).</li>
<li>Representativeness heuristic: a mental shortcut used when making judgements about the probability of an event under uncertainty. Or, judging a situation based on how similar the prospects are to the prototypes the person holds in his or her mind. For example, in a 1982 Tversky and Kahneman experiment,<sup class="reference" id="cite_ref-Kahneman_8-1">[8]</sup> participants were given a description of a woman named Linda. Based on the description, it was likely that Linda was a feminist. Eighty to ninety percent of participants, choosing from two options, chose that it was more likely for Linda to be a feminist <i>and</i> a bank teller than only a bank teller. The likelihood of two events cannot be greater than that of either of the two events individually. For this reason, the representativeness heuristic is exemplary of the conjunction fallacy.<sup class="reference" id="cite_ref-Harvey_23-1">[23]</sup></li>
<li>Scarcity heuristic: as in economics, the scarcer an object or event is, the more value is attributed to the object or event. The lack of abundance is an indicator of value and provides a mental shortcut that influences the subjective valuation based on how easily the thing might be replaced or lost to competitors. The scarcity heuristic is a cognitive rule that the more difficult it is to acquire an item, the more value that item must have. In many situations we use an item's availability, its perceived abundance, to quickly estimate quality and/or utility. This can lead to systematic judgement errors or cognitive bias.<sup class="reference" id="cite_ref-32">[32]</sup></li>
<li>Simulation heuristic: a simplified mental strategy in which people determine the likelihood of an event happening based on how easy it is to mentally picture the event happening. People regret the events that are easier to imagine over the ones that would be harder to. It is also thought that people will use this heuristic to predict the likelihood of another's behavior happening. This shows that people are constantly simulating everything around them in order to be able to predict the likelihood of events around them. It is believed that people do this by mentally undoing events that they have experienced and then running mental simulations of the events with the corresponding input values of the altered model.<sup class="reference" id="cite_ref-33">[33]</sup></li>
<li>Social proof: also known as the informational social influence which was named by Robert Cialdini in his 1984 book <b>Influence</b>. It is where people copy the actions of others. It is more prominent when people are uncertain how to behave, especially in ambiguous social situations.<sup class="reference" id="cite_ref-34">[34]</sup></li>
<li>Working backward heuristic: when an individual assumes they have already solved a problem they work backwards in order to find how to achieve the solution they originally figured out.<sup class="reference" id="cite_ref-Dale_25-1">[25]</sup></li></ul>
<h3><span class="mw-headline" id="Formal_models_of_heuristics">Formal models of heuristics</span><span class="mw-editsection"></span></h3>
<ul><li>Elimination by aspects heuristic</li>
<li>Fast-and-frugal trees</li>
<li>Fluency heuristic</li>
<li>Gaze heuristic</li>
<li>Recognition heuristic</li>
<li>Satisficing</li>
<li>Similarity heuristic</li>
<li>Take-the-best heuristic</li></ul>
<h3><span class="mw-headline" id="Cognitive_maps">Cognitive maps</span><span class="mw-editsection"></span></h3>
<p>Heuristics were also found to be used in the manipulation and creation of cognitive maps.<sup class="reference" id="cite_ref-35">[35]</sup> <i>Cognitive maps</i> are internal representations of our physical environment, particularly associated with spatial relationships. These internal representations are used by our memory as a guide in our external environment. It was found that when questioned about maps imaging, distancing, etc., people commonly made distortions to images. These distortions took shape in the regularisation of images (i.e., images are represented as more like pure abstract geometric images, though they are irregular in shape).
</p><p>There are several ways that humans form and use cognitive maps, with visual intake being an especially key part of mapping: the first is by using <b>landmarks</b>, whereby a person uses a mental image to estimate a relationship, usually distance, between two objects. The second is <b>route-road</b> knowledge, and is generally developed after a person has performed a task and is relaying the information of that task to another person. The third is a <b>survey</b>, whereby a person estimates a distance based on a mental image that, to them, might appear like an actual map. This image is generally created when a person's brain begins making image corrections. These are presented in five ways:
</p>
<ol><li><b>Right-angle bias</b>: when a person straightens out an image, like mapping an intersection, and begins to give everything 90-degree angles, when in reality it may not be that way.</li>
<li><b>Symmetry heuristic</b>: when people tend to think of shapes, or buildings, as being more symmetrical than they really are.</li>
<li><b>Rotation heuristic</b>: when a person takes a naturally (realistically) distorted image and straightens it out for their mental image.</li>
<li><b>Alignment heuristic</b>: similar to the previous, where people align objects mentally to make them straighter than they really are.</li>
<li><b>Relative-position heuristic</b>: people do not accurately distance landmarks in their mental image based on how well they remember them.</li></ol>
<p>Another method of creating cognitive maps is by means of auditory intake based on verbal descriptions. Using the mapping based from a person's visual intake, another person can create a mental image, such as directions to a certain location.<sup class="reference" id="cite_ref-36">[36]</sup>
</p>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<h2><span class="mw-headline" id="Philosophy">Philosophy</span><span class="mw-editsection"></span></h2>
<p>A <b>heuristic device</b> is used when an entity <i>X</i> exists to enable understanding of, or knowledge concerning, some other entity <i>Y</i>.
</p><p>A good example is a model that, as it is never identical with what it models, is a heuristic device to enable understanding of what it models. Stories, metaphors, etc., can also be termed heuristic in this sense. A classic example is the notion of utopia as described in Plato's best-known work, <i>The Republic</i>. This means that the "ideal city" as depicted in <i>The Republic</i> is not given as something to be pursued, or to present an orientation-point for development. Rather, it shows how things would have to be connected, and how one thing would lead to another (often with highly problematic results), if one opted for certain principles and carried them through rigorously.
</p><p><i>Heuristic</i> is also often used as a noun to describe a rule-of-thumb, procedure, or method.<sup class="reference" id="cite_ref-37">[37]</sup> Philosophers of science have emphasised the importance of heuristics in creative thought and the construction of scientific theories.<sup class="reference" id="cite_ref-38">[38]</sup> Seminal works include Karl Popper's <i>The Logic of Scientific Discovery</i> and others by Imre Lakatos,<sup class="reference" id="cite_ref-39">[39]</sup> Lindley Darden, and William C. Wimsatt.
</p>
<h2><span class="mw-headline" id="Law">Law</span><span class="mw-editsection"></span></h2>
<p>In legal theory, especially in the theory of law and economics, heuristics are used in the law when case-by-case analysis would be impractical, insofar as "practicality" is defined by the interests of a governing body.<sup class="reference" id="cite_ref-40">[40]</sup>
</p><p>The present securities regulation regime largely assumes that all investors act as perfectly rational persons.
In truth, actual investors face cognitive limitations from biases, heuristics, and framing effects. For instance, in all states in the United States the legal drinking age for unsupervised persons is 21 years, because it is argued that people need to be mature enough to make decisions involving the risks of alcohol consumption. However, assuming people mature at different rates, the specific age of 21 would be too late for some and too early for others. In this case, the somewhat arbitrary deadline is used because it is impossible or impractical to tell whether an individual is sufficiently mature for society to trust them with that kind of responsibility. Some proposed changes, however, have included the completion of an alcohol education course rather than the attainment of 21 years of age as the criterion for legal alcohol possession. This would put youth alcohol policy more on a case-by-case basis and less on a heuristic one, since the completion of such a course would presumably be voluntary and not uniform across the population.
</p><p>The same reasoning applies to patent law. Patents are justified on the grounds that inventors must be protected so they have incentive to invent. It is therefore argued that it is in society's best interest that inventors receive a temporary government-granted monopoly on their idea, so that they can recoup investment costs and make economic profit for a limited period. In the United States, the length of this temporary monopoly is 20 years from the date the patent application was filed, though the monopoly does not actually begin until the application has matured into a patent. However, like the drinking-age problem above, the specific length of time would need to be different for every product to be efficient. A 20-year term is used because it is difficult to tell what the number should be for any individual patent. More recently, some, including University of North Dakota law professor Eric E. Johnson, have argued that patents in different kinds of industries – such as software patents – should be protected for different lengths of time.<sup class="reference" id="cite_ref-41">[41]</sup>
</p>
<h2><span class="mw-headline" id="Stereotyping">Stereotyping</span><span class="mw-editsection"></span></h2>
<p>Stereotyping is a type of heuristic that people use to form opinions or make judgements about things they have never seen or experienced.<sup class="reference" id="cite_ref-42">[42]</sup> They work as a mental shortcut to assess everything from the social status of a person (based on their actions),<sup class="reference" id="cite_ref-conceptually_2-1">[2]</sup> to whether a plant is a tree based on the assumption that it is tall, has a trunk and has leaves (even though the person making the evaluation might never have seen that particular type of tree before).
</p><p>Stereotypes, as first described by journalist Walter Lippmann in his book <i>Public Opinion</i> (1922), are the pictures we have in our heads that are built around experiences as well as what we are told about the world.<sup class="reference" id="cite_ref-43">[43]</sup><sup class="reference" id="cite_ref-44">[44]</sup>
</p>
<h2><span class="mw-headline" id="Artificial_intelligence">Artificial intelligence</span><span class="mw-editsection"></span></h2>
<p>A heuristic can be used in artificial intelligence systems while searching a solution space. The heuristic is derived by using some function that is put into the system by the designer, or by adjusting the weight of branches based on how likely each branch is to lead to a goal node.
</p>
<link href="mw-data:TemplateStyles:r1033289096" rel="mw-deduplicated-inline-style"/>
<h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1097025294">.mw-parser-output .side-box{margin:4px 0;box-sizing:border-box;border:1px solid #aaa;font-size:88%;line-height:1.25em;background-color:#f9f9f9}.mw-parser-output .side-box-abovebelow,.mw-parser-output .side-box-text{padding:0.25em 0.9em}.mw-parser-output .side-box-image{padding:2px 0 2px 0.9em;text-align:center}.mw-parser-output .side-box-imageright{padding:2px 0.9em 2px 0;text-align:center}@media(min-width:500px){.mw-parser-output .side-box-flex{display:flex;align-items:center}.mw-parser-output .side-box-text{flex:1}}@media(min-width:720px){.mw-parser-output .side-box{width:238px}.mw-parser-output .side-box-right{clear:right;float:right;margin-left:1em}.mw-parser-output .side-box-left{margin-right:1em}}</style>
<link href="mw-data:TemplateStyles:r1097025294" rel="mw-deduplicated-inline-style"/>
<ul><li>Algorithm</li>
<li>Behavioral economics</li>
<li>Failure mode and effects analysis</li>
<li>Heuristics in judgment and decision-making</li>
<li>Ideal type</li>
<li>List of biases in judgment and decision making</li>
<li>Neuroheuristics</li>
<li>Predictive coding</li>
<li>Priority heuristic</li>
<li>Social heuristics</li>
<li>Thought experiment</li></ul>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<h2><span class="mw-headline" id="Further_reading">Further reading</span><span class="mw-editsection"></span></h2>
<ul><li><i>How To Solve It: Modern Heuristics</i>, Zbigniew Michalewicz and David B. Fogel, Springer Verlag, 2000. <link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/>ISBN 3-540-66061-5</li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation cs2" id="CITEREFRussellNorvig2003">Russell, Stuart J.; Norvig, Peter (2003), <i>Artificial Intelligence: A Modern Approach</i> (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN <bdi>0-13-790395-2</bdi></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Artificial+Intelligence%3A+A+Modern+Approach&amp;rft.place=Upper+Saddle+River%2C+New+Jersey&amp;rft.edition=2nd&amp;rft.pub=Prentice+Hall&amp;rft.date=2003&amp;rft.isbn=0-13-790395-2&amp;rft.aulast=Russell&amp;rft.aufirst=Stuart+J.&amp;rft.au=Norvig%2C+Peter&amp;rft_id=http%3A%2F%2Faima.cs.berkeley.edu%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AHeuristic"></span></li>
<li>The Problem of Thinking Too Much, 11 December 2002, Persi Diaconis</li></ul>

<!-- 
NewPP limit report
Parsed by mw2336
Cached time: 20221223231628
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.493 seconds
Real time usage: 0.612 seconds
Preprocessor visited node count: 3567/1000000
Post‐expand include size: 103121/2097152 bytes
Template argument size: 2230/2097152 bytes
Highest expansion depth: 16/100
Expensive parser function count: 11/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 152334/5000000 bytes
Lua time usage: 0.319/10.000 seconds
Lua memory usage: 9489023/52428800 bytes
Number of Wikibase entities loaded: 1/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  543.868      1 -total
 54.86%  298.343      1 Template:Reflist
 23.63%  128.513     16 Template:Cite_book
 18.14%   98.658     24 Template:Cite_journal
 10.76%   58.512      1 Template:Authority_control
  9.37%   50.982      1 Template:Short_description
  5.20%   28.255      2 Template:Pagetype
  4.49%   24.444      1 Template:Etymology
  4.11%   22.350      3 Template:ISBN
  4.05%   22.033      1 Template:IPAc-en
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:63452-0!canonical and timestamp 20221223231627 and revision id 1124920880.
 -->
</div></body>
</html>