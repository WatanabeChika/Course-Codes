<!DOCTYPE html>
<html>
<head>
<title>self-organizing_list</title>
</head>
<body>
<div class="mw-parser-output"><p>A <b>self-organizing list</b> is a list that reorders its elements based on some self-organizing heuristic to improve average access time. The aim of a self-organizing list is to improve efficiency of linear search by moving more frequently accessed items towards the head of the list. A self-organizing list achieves near constant time for element access in the best case. A self-organizing list uses a reorganizing algorithm to adapt to various query distributions at runtime.
</p>

<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"></span></h2>
<p>The concept of self-organizing lists has its roots in the idea of activity organization<sup class="reference" id="cite_ref-1">[1]</sup> of records in files stored on disks or tapes. One frequently cited discussion of self-organizing files and lists is that of Knuth.<sup class="reference" id="cite_ref-2">[2]</sup> John McCabe gave the first algorithmic complexity analyses of the Move-to-Front (MTF) strategy where an item is moved to the front of the list after it is accessed.<sup class="reference" id="cite_ref-3">[3]</sup> He analyzed the average time needed for randomly ordered list to get in optimal order. The optimal ordering of a list is the one in which items are ordered in the list by the probability with which they will be needed, with the most accessed item first. The optimal ordering may not be known in advance, and may also change over time.
</p><p>McCabe introduced the transposition strategy in which an accessed item is exchanged with the item in front of it in the list. He made the conjecture that in the average case, transposition worked at least as well as MTF in approaching the optimal ordering of records in the limit. This conjecture was later proved by Rivest.<sup class="reference" id="cite_ref-4">[4]</sup> McCabe also noted that with either the transposition or MTF heuristic, the optimal ordering of records would be approached even if the heuristic was only applied every Nth access, and that a value of N might be chosen that would reflect the relative cost of relocating records with the value of approaching the optimal ordering more quickly. Further improvements were made, and algorithms suggested by researchers including: Rivest, Tenenbaum and Nemes, Knuth, and Bentley and McGeoch (e.g. Worst-case analyses for self-organizing sequential search heuristics).
</p>
<h2><span class="mw-headline" id="Introduction">Introduction</span><span class="mw-editsection"></span></h2>
<p>The simplest implementation of a self-organizing list is as a linked list and thus while being efficient in random node inserting and memory allocation, suffers from inefficient accesses to random nodes. A self-organizing list reduces the inefficiency by dynamically rearranging the nodes in the list based on access frequency.
</p>
<h3><span class="mw-headline" id="Inefficiency_of_linked_list_traversals">Inefficiency of linked list traversals</span><span class="mw-editsection"></span></h3>
<p>If a particular node is to be searched for in the list, each node in the list must be sequentially compared till the desired node is reached. In a linked list, retrieving the nth element is an O(n) operation. This is highly inefficient when compared to an array for example, where accessing the n<sup>th</sup> element is an O(1) operation.
</p>
<h3><span class="mw-headline" id="Efficiency_of_self-organizing_lists">Efficiency of self-organizing lists</span><span class="mw-editsection"></span></h3>
<p>A self organizing list rearranges the nodes keeping the most frequently accessed ones at the head of the list. Generally, in a particular query, the chances of accessing a node which has been accessed many times before are higher than the chances of accessing a node which historically has not been so frequently accessed. As a result, keeping the commonly accessed nodes at the head of the list results in reducing the number of comparisons required in an average case to reach the desired node. This leads to better efficiency and generally reduced query times.
</p>
<h2><span class="mw-headline" id="Implementation_of_a_self-organizing_list">Implementation of a self-organizing list</span><span class="mw-editsection"></span></h2>
<p>The implementation and methods of a self-organizing list are identical to those for a standard linked list. The linked list and the self-organizing list differ only in terms of the organization of the nodes; the interface remains the same.
</p>
<h2><span id="Analysis_of_running_times_for_access.2Fsearch_in_a_list"></span><span class="mw-headline" id="Analysis_of_running_times_for_access/search_in_a_list">Analysis of running times for access/search in a list</span><span class="mw-editsection"></span></h2>
<h3><span class="mw-headline" id="Average_case">Average case</span><span class="mw-editsection"></span></h3>
<p>It can be shown that in the average case, the time required to a search on a self-organizing list of size n is
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle Tavg=1*p(1)+2*p(2)+3*p(3)+...+n*p(n).}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>T</mi>
<mi>a</mi>
<mi>v</mi>
<mi>g</mi>
<mo>=</mo>
<mn>1</mn>
<mo>∗<!-- ∗ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mn>2</mn>
<mo>∗<!-- ∗ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mn>2</mn>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mn>3</mn>
<mo>∗<!-- ∗ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mn>3</mn>
<mo stretchy="false">)</mo>
<mo>+</mo>
<mo>.</mo>
<mo>.</mo>
<mo>.</mo>
<mo>+</mo>
<mi>n</mi>
<mo>∗<!-- ∗ --></mo>
<mi>p</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle Tavg=1*p(1)+2*p(2)+3*p(3)+...+n*p(n).}</annotation>
</semantics>
</math></span><img alt="Tavg=1*p(1)+2*p(2)+3*p(3)+...+n*p(n)." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4a965e54b5b61d5b74fa80e618902798d72196bd" style="vertical-align: -0.838ex; width:51.712ex; height:2.843ex;"/></span></dd></dl>
<p>where p(i) is the probability of accessing the ith element in the list, thus also called the access probability.
If the access probability of each element is the same (i.e. p(1) = p(2) = p(3) = ... = p(n) = 1/n) then the ordering of the elements is irrelevant and the average time complexity is given by
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle T(n)=1/n+2/n+3/n+...+n/n=(1+2+3+...+n)/n=(n+1)/2}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>T</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mn>1</mn>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mi>n</mi>
<mo>+</mo>
<mn>2</mn>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mi>n</mi>
<mo>+</mo>
<mn>3</mn>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mi>n</mi>
<mo>+</mo>
<mo>.</mo>
<mo>.</mo>
<mo>.</mo>
<mo>+</mo>
<mi>n</mi>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mi>n</mi>
<mo>=</mo>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo>+</mo>
<mn>2</mn>
<mo>+</mo>
<mn>3</mn>
<mo>+</mo>
<mo>.</mo>
<mo>.</mo>
<mo>.</mo>
<mo>+</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mi>n</mi>
<mo>=</mo>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo>+</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mn>2</mn>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle T(n)=1/n+2/n+3/n+...+n/n=(1+2+3+...+n)/n=(n+1)/2}</annotation>
</semantics>
</math></span><img alt="T(n)=1/n+2/n+3/n+...+n/n=(1+2+3+...+n)/n=(n+1)/2" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/519bb08b6fb18e167e723a8c904f1e75035f6299" style="vertical-align: -0.838ex; width:72.825ex; height:2.843ex;"/></span></dd></dl>
<p>and T(n) does not depend on the individual access probabilities of the elements in the list in this case.
However, in the case of searches on lists with non uniform record access probabilities (i.e. those lists in which the probability of accessing one element is different from another), the average time complexity can be reduced drastically by proper positioning of the elements contained in the list.
</p><p>This is done by pairing smaller i with larger access probabilities so as to reduce the overall average time complexity. This may be demonstrated as follows:
</p><p>Given List: A(0.1), B(0.1), C(0.3), D(0.1), E(0.4)<br/>Without rearranging, average search time required is:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle T(n)=1*0.1+2*0.1+3*0.3+4*0.1+5*0.4=3.6}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>T</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mn>1</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.1</mn>
<mo>+</mo>
<mn>2</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.1</mn>
<mo>+</mo>
<mn>3</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.3</mn>
<mo>+</mo>
<mn>4</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.1</mn>
<mo>+</mo>
<mn>5</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.4</mn>
<mo>=</mo>
<mn>3.6</mn>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle T(n)=1*0.1+2*0.1+3*0.3+4*0.1+5*0.4=3.6}</annotation>
</semantics>
</math></span><img alt="T(n)=1*0.1+2*0.1+3*0.3+4*0.1+5*0.4=3.6" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3ffa6892ddf9aeba51cc37d9ed0610a80d7ed97f" style="vertical-align: -0.838ex; width:57.015ex; height:2.843ex;"/></span></dd></dl>
<p>Now suppose the nodes are rearranged so that those nodes with highest probability of access are placed closest to the front so that the rearranged list is now:<br/>   E(0.4), C(0.3), D(0.1), A(0.1), B(0.1)<br/>
Here, average search time is:
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle T(n)=1*0.4+2*0.3+3*0.1+4*0.1+5*0.1=2.2}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>T</mi>
<mo stretchy="false">(</mo>
<mi>n</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mn>1</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.4</mn>
<mo>+</mo>
<mn>2</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.3</mn>
<mo>+</mo>
<mn>3</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.1</mn>
<mo>+</mo>
<mn>4</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.1</mn>
<mo>+</mo>
<mn>5</mn>
<mo>∗<!-- ∗ --></mo>
<mn>0.1</mn>
<mo>=</mo>
<mn>2.2</mn>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle T(n)=1*0.4+2*0.3+3*0.1+4*0.1+5*0.1=2.2}</annotation>
</semantics>
</math></span><img alt="T(n)=1*0.4+2*0.3+3*0.1+4*0.1+5*0.1=2.2" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0434d97fe912b142642c48de77e28d26d0a6896a" style="vertical-align: -0.838ex; width:57.015ex; height:2.843ex;"/></span></dd></dl>
<p>Thus the average time required for searching in an organized list is (in this case) around 40% less than the time required to search a randomly arranged list. This is the concept of the self-organized list in that the average speed of data retrieval is increased by rearranging the nodes according to access frequency.
</p>
<h3><span class="mw-headline" id="Worst_case">Worst case</span><span class="mw-editsection"></span></h3>
<p>In the worst case, the element to be located is at the very end of the list be it a normal list or a self-organized one and thus n comparisons must be made to reach it. Therefore, the worst case running time of a linear search on the list is O(n) independent of the type of list used.
Note that the expression for the average search time in the previous section is a probabilistic one. Keeping the commonly accessed elements at the head of the list simply reduces the probability of the worst case occurring but does not eliminate it completely. Even in a self-organizing list, if a lowest access probability element (obviously located at the end of the list) is to be accessed, the entire list must be traversed completely to retrieve it. This is the worst case search.
</p>
<h3><span class="mw-headline" id="Best_case">Best case</span><span class="mw-editsection"></span></h3>
<p>In the best case, the node to be searched is one which has been commonly accessed and has thus been identified by the list and kept at the head. This will result in a near constant time operation. In big-oh notation, in the best case, accessing an element is an O(1) operation.
</p>
<h2><span class="mw-headline" id="Techniques_for_rearranging_nodes">Techniques for rearranging nodes</span><span class="mw-editsection"></span></h2>
<p>While ordering the elements in the list, the access probabilities of the elements are not generally known in advance. This has led to the development of various heuristics to approximate optimal behavior. The basic heuristics used to reorder the elements in the list are:
</p>
<h3><span id="Move_to_front_method_.28MTF.29"></span><span class="mw-headline" id="Move_to_front_method_(MTF)">Move to front method (MTF)</span><span class="mw-editsection"></span></h3>
<p>This technique moves the element which is accessed to the head of the list. This has the advantage of being easily implemented and requiring no extra memory. This heuristic also adapts quickly to rapid changes in the query distribution. On the other hand, this method may prioritize infrequently accessed nodes — for example, if an uncommon node is accessed even once, it is moved to the head of the list and given maximum priority even if it is not going to be accessed frequently in the future. These 'over rewarded' nodes destroy the optimal ordering of the list and lead to slower access times for commonly accessed elements. Another disadvantage is that this method may become too flexible leading to access patterns that change too rapidly. This means that due to the very short memories of access patterns even an optimal arrangement of the list can be disturbed immediately by accessing an infrequent node in the list.
</p>

<pre>At the t-th item selection:
    <b>if</b> item i is selected:
        move item i to head of the list
</pre>
<h3><span class="mw-headline" id="Count_method">Count method</span><span class="mw-editsection"></span></h3>
<p>In this technique, the number of times each node was searched for is counted i.e. every node keeps a separate counter variable which is incremented every time it is called. The nodes are then rearranged according to decreasing count. Thus, the nodes of highest count i.e. most frequently accessed are kept at the head of the list. The primary advantage of this technique is that it generally is more realistic in representing the actual access pattern. However, there is an added memory requirement, that of maintaining a counter variable for each node in the list. Also, this technique does not adapt quickly to rapid changes in the access patterns. For example: if the count of the head element say A is 100 and for any node after it say B is 40, then even if B becomes the new most commonly accessed element, it must still be accessed at least (100 - 40 = 60) times before it can become the head element and thus make the list ordering optimal.
</p><p><br/>
</p>

<pre><b>init:</b> count(i) = 0 for each item i
At t-th item selection:
    <b>if</b> item i is searched:
        count(i) = count(i) + 1
        rearrange items based on count
</pre>
<h3><span class="mw-headline" id="Transpose_method">Transpose method</span><span class="mw-editsection"></span></h3>
<p>This technique involves swapping an accessed node with its predecessor. Therefore, if any node is accessed, it is swapped with the node in front unless it is the head node, thereby increasing its priority. This algorithm is again easy to implement and space efficient and is more likely to keep frequently accessed nodes at the front of the list. However, the transpose method is more cautious. i.e. it will take many accesses to move the element to the head of the list. This method also does not allow for rapid response to changes in the query distributions on the nodes in the list.
</p>


<h3><span class="mw-headline" id="Other_methods">Other methods</span><span class="mw-editsection"></span></h3>
<p>Research has been focused on fusing the above algorithms to achieve better efficiency.<sup class="reference" id="cite_ref-5">[5]</sup> Bitner's Algorithm uses MTF initially and then uses transpose method for finer rearrangements. Some algorithms are randomized and try to prevent the over-rewarding of infrequently accessed nodes that may occur in the MTF algorithm. Other techniques involve reorganizing the nodes based on the above algorithms after every n accesses on the list as a whole or after n accesses in a row on a particular node and so on. Some algorithms rearrange the nodes which are accessed based on their proximity to the head node, for example: Swap-With-Parent or Move-To-Parent algorithms. Another class of algorithms are used when the search pattern exhibits a property called locality of reference whereby in a given interval of time, only a smaller subset of the list is probabilistically most likely to be accessed. This is also referred to as dependent access where the probability of the access of a particular element depends on the probability of access of its neighboring elements. Such models are common in real world applications such as database or file systems and memory management and caching. A common framework for algorithms dealing with such dependent environments is to rearrange the list not only based on the record accessed but also on the records near it. This effectively involves reorganizing a sublist of the list to which the record belongs.
</p><p>Earlier literature on self-organizing lists have also shown other algorithms such as move-ahead-k, a more radical version of <i>transpose</i> that moves the visited node forward by <i>k</i> elements each time. Doing so would require a constant cost of storing last <i>k</i> pointers of the linked list.<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><span title="This claim has reliable sources with contradicting facts (January 2022)">disputed</span> <span class="metadata"> – discuss</span></i>]</sup> (If the "list" in question is instead an array undergoing linear search, the implementation becomes more trivial.)<sup class="reference" id="cite_ref-6">[6]</sup>
</p>
<h2><span class="mw-headline" id="Applications_of_self-organizing_lists">Applications of self-organizing lists</span><span class="mw-editsection"></span></h2>
<p>Language translators like compilers and interpreters use self-organizing lists to maintain symbol tables during compilation or interpretation of program source code. Currently<sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><span title="The time period mentioned near this tag is ambiguous. (September 2022)">when?</span></i>]</sup> research is underway to incorporate the self-organizing list data structure in embedded systems to reduce bus transition activity which leads to power dissipation in those circuits. These lists are also used in artificial intelligence and neural networks as well as self-adjusting programs. The algorithms used in self-organizing lists are also used as caching algorithms as in the case of LFU algorithm.
</p><p>The simple Move to Front and transpose methods are also applicable in real-world collections: for instance organising a spice drawer by replacing used items to the front of a drawer, or transposing a cleaning item with its front-most neighbour when it is used.
</p>
<h2><span class="mw-headline" id="Notes">Notes</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<ul><li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation cs2"><i>Self Organization</i> <span class="cs1-format">(PDF)</span>, 2004</cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Self+Organization&amp;rft.date=2004&amp;rft_id=http%3A%2F%2Fcourses.cs.vt.edu%2F~cs2604%2Fspring04%2FNotes%2FC16.SelfOrganizingLists.pdf&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASelf-organizing+list"></span></li>
<li>NIST DADS entry</li>
<li>A Drozdek, Data Structures and Algorithms in Java Third edition</li>
<li><link href="mw-data:TemplateStyles:r1067248974" rel="mw-deduplicated-inline-style"/><cite class="citation cs2" id="CITEREFAmerB._John_Oommen2006">Amer, Abdelrehman; B. John Oommen (2006), <i>Lists on Lists: A Framework for Self-organizing Lists in Environments with Locality of Reference</i>, Lecture Notes in Computer Science, vol. 4007, doi:10.1007/11764298, ISBN <bdi>978-3-540-34597-8</bdi></cite><span class="Z3988" title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Lists+on+Lists%3A+A+Framework+for+Self-organizing+Lists+in+Environments+with+Locality+of+Reference&amp;rft.series=Lecture+Notes+in+Computer+Science&amp;rft.date=2006&amp;rft_id=info%3Adoi%2F10.1007%2F11764298&amp;rft.isbn=978-3-540-34597-8&amp;rft.aulast=Amer&amp;rft.aufirst=Abdelrehman&amp;rft.au=B.+John+Oommen&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ASelf-organizing+list"></span></li></ul>

<!-- 
NewPP limit report
Parsed by mw2385
Cached time: 20221221013110
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.190 seconds
Real time usage: 0.334 seconds
Preprocessor visited node count: 839/1000000
Post‐expand include size: 29572/2097152 bytes
Template argument size: 1260/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 25499/5000000 bytes
Lua time usage: 0.111/10.000 seconds
Lua memory usage: 4237989/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  203.989      1 -total
 51.75%  105.569      1 Template:Reflist
 38.92%   79.390      6 Template:Citation
 22.56%   46.030      1 Template:Disputed_inline
 19.59%   39.956      2 Template:Fix
 18.56%   37.852      1 Template:Data_structures
 17.60%   35.892      1 Template:Navbox
 12.67%   25.846      3 Template:Category_handler
  3.90%    7.961      2 Template:Delink
  3.73%    7.614      1 Template:When
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:6213252-0!canonical and timestamp 20221221013109 and revision id 1113412261.
 -->
</div></body>
</html>