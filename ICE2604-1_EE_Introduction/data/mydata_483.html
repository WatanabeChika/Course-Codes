<!DOCTYPE html>
<html>
<head>
<title>incompressible_string</title>
</head>
<body>
<div class="mw-parser-output"><style data-mw-deduplicate="TemplateStyles:r1097763485">.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}</style><table class="box-More_citations_needed plainlinks metadata ambox ambox-content ambox-Refimprove" role="presentation"><tbody><tr><td class="mbox-image"></td><td class="mbox-text"></td></tr></tbody></table>
<p>An <b>incompressible string</b> is a string with Kolmogorov complexity equal to its length, so that it has no shorter encodings.<sup class="reference" id="cite_ref-1">[1]</sup>
</p>
<h2><span class="mw-headline" id="Example">Example</span><span class="mw-editsection"></span></h2>
<p>Suppose we have the string 12349999123499991234, and we are using a compression method that works by putting a special character into the string (say '@') followed by a value that points to an entry in a lookup table (or dictionary) of repeating values.  Let's imagine we have an algorithm that examines the string in 4 character chunks.  Looking at our string, our algorithm might pick out the values 1234 and 9999 to place into its dictionary.  Let's say 1234 is entry 0 and 9999 is entry 1. Now the string can become:
</p><p>@0@1@0@1@0
</p><p>Obviously, this is much shorter, although storing the dictionary itself will cost some space.  However, the more repeats there are in the string, the better the compression will be.
</p><p>Our algorithm can do better though, if it can view the string in chunks larger than 4 characters.  Then it can put 12349999 and 1234 into the dictionary, giving us:
</p><p>@0@0@1
</p><p>Even shorter.  Now consider another string:
</p><p>1234999988884321
</p><p>This string is incompressible by our algorithm. The only repeats that occur are 88 and 99.  If we were to store 88 and 99 in our dictionary, we would produce:
</p><p>1234@1@1@0@04321
</p><p>Unfortunately this is just as long as the original string, because our placeholders for items in the dictionary are 2 characters long, and the items they replace are the same length.  Hence, this string is incompressible by our algorithm.
</p>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>

<!-- 
NewPP limit report
Parsed by mw2270
Cached time: 20221219101555
Cache expiry: 1814400
Reduced expiry: false
Complications: []
CPU time usage: 0.068 seconds
Real time usage: 0.100 seconds
Preprocessor visited node count: 103/1000000
Post‐expand include size: 9529/2097152 bytes
Template argument size: 9/2097152 bytes
Highest expansion depth: 9/100
Expensive parser function count: 1/500
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 2043/5000000 bytes
Lua time usage: 0.043/10.000 seconds
Lua memory usage: 1179078/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%   84.942      1 Template:Refimprove
100.00%   84.942      1 -total
 81.89%   69.555      1 Template:Ambox
 15.84%   13.459      1 Template:Find_sources_mainspace
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:6495416-0!canonical and timestamp 20221219101555 and revision id 997077473.
 -->
</div></body>
</html>