<!DOCTYPE html>
<html>
<head>
<title>single_program_multiple_data</title>
</head>
<body>
<div class="mw-parser-output">
<style data-mw-deduplicate="TemplateStyles:r1097763485">.mw-parser-output .ambox{border:1px solid #a2a9b1;border-left:10px solid #36c;background-color:#fbfbfb;box-sizing:border-box}.mw-parser-output .ambox+link+.ambox,.mw-parser-output .ambox+link+style+.ambox,.mw-parser-output .ambox+link+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+style+.ambox,.mw-parser-output .ambox+.mw-empty-elt+link+link+.ambox{margin-top:-1px}html body.mediawiki .mw-parser-output .ambox.mbox-small-left{margin:4px 1em 4px 0;overflow:hidden;width:238px;border-collapse:collapse;font-size:88%;line-height:1.25em}.mw-parser-output .ambox-speedy{border-left:10px solid #b32424;background-color:#fee7e6}.mw-parser-output .ambox-delete{border-left:10px solid #b32424}.mw-parser-output .ambox-content{border-left:10px solid #f28500}.mw-parser-output .ambox-style{border-left:10px solid #fc3}.mw-parser-output .ambox-move{border-left:10px solid #9932cc}.mw-parser-output .ambox-protection{border-left:10px solid #a2a9b1}.mw-parser-output .ambox .mbox-text{border:none;padding:0.25em 0.5em;width:100%}.mw-parser-output .ambox .mbox-image{border:none;padding:2px 0 2px 0.5em;text-align:center}.mw-parser-output .ambox .mbox-imageright{border:none;padding:2px 0.5em 2px 0;text-align:center}.mw-parser-output .ambox .mbox-empty-cell{border:none;padding:0;width:1px}.mw-parser-output .ambox .mbox-image-div{width:52px}html.client-js body.skin-minerva .mw-parser-output .mbox-text-span{margin-left:23px!important}@media(min-width:720px){.mw-parser-output .ambox{margin:0 10%}}</style><table class="box-Missing_information plainlinks metadata ambox ambox-content" role="presentation"><tbody><tr><td class="mbox-image"></td><td class="mbox-text"></td></tr></tbody></table>
<p>In computing, <b>single program, multiple data</b> (<b>SPMD</b>) is a technique employed to achieve parallelism; it is a subcategory of MIMD. Tasks are split up and run simultaneously on multiple processors with different input in order to obtain results faster. SPMD is the most common style of parallel programming.<sup class="reference" id="cite_ref-1">[1]</sup><sup class="noprint Inline-Template" style="white-space:nowrap;">[<i><span title="The material near this tag failed verification of its source citation(s). (June 2020)">failed verification</span></i>]</sup>  It is also a prerequisite for research concepts such as active messages and distributed shared memory.
</p>
<style data-mw-deduplicate="TemplateStyles:r1045330069">.mw-parser-output .sidebar{width:22em;float:right;clear:right;margin:0.5em 0 1em 1em;background:#f8f9fa;border:1px solid #aaa;padding:0.2em;text-align:center;line-height:1.4em;font-size:88%;border-collapse:collapse;display:table}body.skin-minerva .mw-parser-output .sidebar{display:table!important;float:right!important;margin:0.5em 0 1em 1em!important}.mw-parser-output .sidebar-subgroup{width:100%;margin:0;border-spacing:0}.mw-parser-output .sidebar-left{float:left;clear:left;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-none{float:none;clear:both;margin:0.5em 1em 1em 0}.mw-parser-output .sidebar-outer-title{padding:0 0.4em 0.2em;font-size:125%;line-height:1.2em;font-weight:bold}.mw-parser-output .sidebar-top-image{padding:0.4em}.mw-parser-output .sidebar-top-caption,.mw-parser-output .sidebar-pretitle-with-top-image,.mw-parser-output .sidebar-caption{padding:0.2em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-pretitle{padding:0.4em 0.4em 0;line-height:1.2em}.mw-parser-output .sidebar-title,.mw-parser-output .sidebar-title-with-pretitle{padding:0.2em 0.8em;font-size:145%;line-height:1.2em}.mw-parser-output .sidebar-title-with-pretitle{padding:0.1em 0.4em}.mw-parser-output .sidebar-image{padding:0.2em 0.4em 0.4em}.mw-parser-output .sidebar-heading{padding:0.1em 0.4em}.mw-parser-output .sidebar-content{padding:0 0.5em 0.4em}.mw-parser-output .sidebar-content-with-subgroup{padding:0.1em 0.4em 0.2em}.mw-parser-output .sidebar-above,.mw-parser-output .sidebar-below{padding:0.3em 0.8em;font-weight:bold}.mw-parser-output .sidebar-collapse .sidebar-above,.mw-parser-output .sidebar-collapse .sidebar-below{border-top:1px solid #aaa;border-bottom:1px solid #aaa}.mw-parser-output .sidebar-navbar{text-align:right;font-size:115%;padding:0 0.4em 0.4em}.mw-parser-output .sidebar-list-title{padding:0 0.4em;text-align:left;font-weight:bold;line-height:1.6em;font-size:105%}.mw-parser-output .sidebar-list-title-c{padding:0 0.4em;text-align:center;margin:0 3.3em}@media(max-width:720px){body.mediawiki .mw-parser-output .sidebar{width:100%!important;clear:both;float:none!important;margin-left:0!important;margin-right:0!important}}</style><table class="sidebar nomobile nowraplinks hlist"><tbody><tr><th class="sidebar-title">Flynn's taxonomy</th></tr><tr><th class="sidebar-heading">
Single data stream</th></tr><tr><td class="sidebar-content">
<ul><li>SISD</li>
<li>MISD</li></ul></td>
</tr><tr><th class="sidebar-heading">
Multiple data streams</th></tr><tr><td class="sidebar-content">
<ul><li>SIMD</li>
<li>MIMD</li></ul></td>
</tr><tr><th class="sidebar-heading">
SIMD Subcategories<sup class="reference" id="cite_ref-flynn-1972_2-0">[2]</sup></th></tr><tr><td class="sidebar-content">
<ul><li>Array processing (SIMT)</li>
<li>Pipelined processing (packed SIMD)</li>
<li>Associative processing (predicated/masked SIMD)</li></ul></td>
</tr><tr><th class="sidebar-heading">
See also</th></tr><tr><td class="sidebar-content">
<ul><li>SPMD</li>
<li>MPMD</li></ul></td>
</tr></tbody></table>

<h2><span class="mw-headline" id="SPMD_vs_SIMD">SPMD vs SIMD</span><span class="mw-editsection"></span></h2>
<p>In SPMD, multiple autonomous processors simultaneously execute the same program at independent points, rather than in the lockstep that SIMD or SIMT imposes on different data. With SPMD, tasks can be executed on general purpose CPUs; SIMD requires vector processors to manipulate data streams. Note that the two are not mutually exclusive.
</p>
<h2><span class="mw-headline" id="Distributed_memory">Distributed memory</span><span class="mw-editsection"></span></h2>
<p>SPMD usually refers to message passing programming on distributed memory computer architectures. A distributed memory computer consists of a collection of independent computers, called nodes. Each node starts its own program and communicates with other nodes by sending and receiving messages, calling send/receive routines for that purpose. Barrier synchronization  may also be implemented by messages. The messages can be sent by a number of communication mechanisms, such as TCP/IP over Ethernet, or specialized high-speed interconnects such as Myrinet and Supercomputer Interconnect. Serial sections of the program are implemented by identical computation on all nodes rather than computing the result on one node and sending it to the others.
</p><p>Nowadays, the programmer is isolated from the details of the message passing by standard interfaces, such as PVM and MPI.
</p><p>Distributed memory is the programming style used on parallel supercomputers from homegrown Beowulf clusters to the largest clusters on the Teragrid.
</p>
<h2><span class="mw-headline" id="Shared_memory">Shared memory</span><span class="mw-editsection"></span></h2>
<p>On a shared memory machine (a computer with several CPUs that access the same memory space), messages can be sent by depositing their contents in a shared memory area. This is often the most efficient way to program shared memory computers with large number of processors, especially on NUMA machines, where memory is local to processors and accessing memory of another processor takes longer. SPMD on a shared memory machine is usually implemented by standard (heavyweight) processes.
</p><p>Unlike SPMD, shared memory multiprocessing (both symmetric multiprocessing, SMP, and non-uniform memory access, NUMA) presents the programmer with a common memory space and the possibility to parallelize execution by having the program take different paths on different processors. The program starts executing on one processor and the execution splits in a parallel region, which is started when parallel directives are encountered. In a parallel region, the processors execute a single program on different data. A typical example is the parallel DO loop, where different processors work on separate parts of the arrays involved in the loop. At the end of the loop, execution is synchronized, only one processor continues, and the others wait. The current standard interface for shared memory multiprocessing is OpenMP.  It is usually implemented by lightweight processes, called threads.
</p>
<h2><span class="mw-headline" id="Combination_of_levels_of_parallelism">Combination of levels of parallelism</span><span class="mw-editsection"></span></h2>
<p>Current computers allow exploiting of many parallel modes at the same time for maximum combined effect. A distributed memory program using MPI may run on a collection of nodes. Each node may be a shared memory computer and execute in parallel on multiple CPUs using OpenMP. Within each CPU, SIMD vector instructions (usually generated automatically by the compiler) and superscalar instruction execution (usually handled transparently by the CPU itself), such as pipelining and the use of multiple parallel functional units, are used for maximum single CPU speed.
</p>
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"></span></h2>
<p>SPMD was proposed first in 1983 by Michel Auguin (University of Nice Sophia-Antipolis) and Fran√ßois Larbey (Thomson/Sintra) in the OPSILA parallel computer<sup class="reference" id="cite_ref-3">[3]</sup> and next in 1984 by Frederica Darema at IBM for highly parallel machines like the RP3 (the IBM Research Parallel Processor Prototype), in an unpublished IBM memo.<sup class="reference" id="cite_ref-4">[4]</sup> By the late 1980s, there were many distributed computers with proprietary message passing libraries. The first SPMD standard was PVM. The current de facto standard is MPI.
</p><p>The Cray parallel directives were a direct predecessor of OpenMP.
</p>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>

<h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"></span></h2>
<ul><li>Parallel job management and message passing</li>
<li>Single Program Multiple Data stream</li>
<li>SPMD</li>
<li>Distributed-memory programming</li></ul>

<!-- 
NewPP limit report
Parsed by mw2283
Cached time: 20221224024258
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‚Äêrevision‚Äêsha1, show‚Äêtoc]
CPU time usage: 0.258 seconds
Real time usage: 0.375 seconds
Preprocessor visited node count: 661/1000000
Post‚Äêexpand include size: 33659/2097152 bytes
Template argument size: 1074/2097152 bytes
Highest expansion depth: 12/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‚Äêexpand size: 13584/5000000 bytes
Lua time usage: 0.157/10.000 seconds
Lua memory usage: 4225111/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  313.461      1 -total
 23.20%   72.738      1 Template:Cite_web
 21.38%   67.008      1 Template:Short_description
 18.72%   58.685      1 Template:Parallel_computing
 17.86%   55.996      1 Template:Navbox
 15.99%   50.122      1 Template:Missing_information
 14.13%   44.286      1 Template:Ambox
 11.00%   34.492      2 Template:Pagetype
  9.65%   30.234      1 Template:Flynn's_Taxonomy
  8.23%   25.808      1 Template:Sidebar
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:1081527-0!canonical and timestamp 20221224024258 and revision id 1094004240.
 -->
</div></body>
</html>