<!DOCTYPE html>
<html>
<head>
<title>work-depth_model</title>
</head>
<body>
<div class="mw-parser-output"><p>In computer science, the analysis of parallel algorithms is the process of finding the computational complexity of algorithms executed in parallel – the amount of time, storage, or other resources needed to execute them. In many respects, <b>analysis of parallel algorithms</b> is similar to the analysis of sequential algorithms, but is generally more involved because one must reason about the behavior of multiple cooperating threads of execution. One of the primary goals of parallel analysis is to understand how a parallel algorithm's use of resources (speed, space, etc.) changes as the number of processors is changed.
</p>

<h2><span class="mw-headline" id="Background">Background</span><span class="mw-editsection"></span></h2>
<p>A so-called work-time (WT) (sometimes called work-depth, or work-span) framework was originally introduced by Shiloach and Vishkin <sup class="reference" id="cite_ref-shiloach_1-0">[1]</sup>
for conceptualizing and describing parallel algorithms. 
In the WT framework, a parallel algorithm is first described in terms of parallel rounds. For each round, the operations to be performed are characterized, but several issues can be suppressed. For example, the number of operations at each round need not be clear, processors need not be mentioned and any information that may help with the assignment of processors to jobs need not be accounted for. Second, the suppressed information is provided. The inclusion of the suppressed information is guided by the proof of a scheduling theorem due to Brent,<sup class="reference" id="cite_ref-brent_2-0">[2]</sup> which is explained later in this article. The WT framework is useful since while it can greatly simplify the initial description of a parallel algorithm, inserting the details suppressed by that initial description is often not very difficult. For example, the WT framework was adopted as the basic presentation framework in the parallel algorithms books (for the Parallel random-access machine PRAM model) 
<sup class="reference" id="cite_ref-jaja_3-0">[3]</sup>
and, <sup class="reference" id="cite_ref-kkt_4-0">[4]</sup> 
as well as in the class notes 
.<sup class="reference" id="cite_ref-uv_5-0">[5]</sup> The overview below explains how the WT framework can be used for analyzing more general parallel algorithms, even when their description is not available within the WT framework.
</p>
<h2><span class="mw-headline" id="Definitions">Definitions</span><span class="mw-editsection"></span></h2>
<p>Suppose computations are executed on a machine that has <span class="texhtml mvar" style="font-style:italic;">p</span> processors. Let <span class="texhtml mvar" style="font-style:italic;">T<sub>p</sub></span> denote the time that expires between the start of the computation and its end. Analysis of the computation's running time focuses on the following notions:
</p>
<ul><li>The <i>work</i> of a computation executed by <span class="texhtml mvar" style="font-style:italic;">p</span> processors is the total number of primitive operations that the processors perform.<sup class="reference" id="cite_ref-casanova_6-0">[6]</sup> Ignoring communication overhead from synchronizing the processors, this is equal to the time used to run the computation on a single processor, denoted <span class="texhtml"><i>T</i><sub>1</sub></span>.</li>
<li>The <i>depth</i> or <i>span</i> is the length of the longest series of operations that have to be performed sequentially due to data dependencies (the <i>critical path</i>). The depth may also be called the <i>critical path length</i> of the computation.<sup class="reference" id="cite_ref-cacm_7-0">[7]</sup> Minimizing the depth/span is important in designing parallel algorithms, because the depth/span determines the shortest possible execution time.<sup class="reference" id="cite_ref-spp_8-0">[8]</sup> Alternatively, the span can be defined as the time <span class="texhtml"><i>T</i><sub>∞</sub></span> spent computing using an idealized machine with an infinite number of processors.<sup class="reference" id="cite_ref-clrs_9-0">[9]</sup></li>
<li>The <i>cost</i> of the computation is the quantity <span class="texhtml mvar" style="font-style:italic;">pT<sub>p</sub></span>. This expresses the total time spent, by all processors, in both computing and waiting.<sup class="reference" id="cite_ref-casanova_6-1">[6]</sup></li></ul>
<p>Several useful results follow from the definitions of work, span and cost:
</p>
<ul><li><i>Work law</i>. The cost is always at least the work: <span class="texhtml"><i>pT<sub>p</sub></i> ≥ <i>T</i><sub>1</sub></span>. This follows from the fact that <span class="texhtml mvar" style="font-style:italic;">p</span> processors can perform at most <span class="texhtml mvar" style="font-style:italic;">p</span> operations in parallel.<sup class="reference" id="cite_ref-casanova_6-2">[6]</sup><sup class="reference" id="cite_ref-clrs_9-1">[9]</sup></li>
<li><i>Span law</i>. A finite number <span class="texhtml mvar" style="font-style:italic;">p</span> of processors cannot outperform an infinite number, so that <span class="texhtml"><i>T<sub>p</sub></i> ≥ <i>T</i><sub>∞</sub></span>.<sup class="reference" id="cite_ref-clrs_9-2">[9]</sup></li></ul>
<p>Using these definitions and laws, the following measures of performance can be given:
</p>
<ul><li><i>Speedup</i> is the gain in speed made by parallel execution compared to sequential execution: <span class="texhtml"><i>S<sub>p</sub></i> = <i>T</i><sub>1</sub> / <i>T<sub>p</sub></i></span>. When the speedup is <span class="texhtml">Ω(<i>n</i>)</span> for input size <span class="texhtml mvar" style="font-style:italic;">n</span> (using big O notation), the speedup is linear, which is optimal in simple models of computation because the work law implies that <span class="texhtml"><i>T</i><sub>1</sub> / <i>T<sub>p</sub></i> ≤ <i>p</i></span> (super-linear speedup can occur in practice due to memory hierarchy effects). The situation <span class="texhtml"><i>T</i><sub>1</sub> / <i>T<sub>p</sub></i> = <i>p</i></span> is called perfect linear speedup.<sup class="reference" id="cite_ref-clrs_9-3">[9]</sup> An algorithm that exhibits linear speedup is said to be scalable.<sup class="reference" id="cite_ref-casanova_6-3">[6]</sup></li>
<li><i>Efficiency</i> is the speedup per processor, <span class="texhtml"><i>S<sub>p</sub></i> / <i>p</i></span>.<sup class="reference" id="cite_ref-casanova_6-4">[6]</sup></li>
<li><i>Parallelism</i> is the ratio <span class="texhtml"><i>T</i><sub>1</sub> / <i>T</i><sub>∞</sub></span>. It represents the maximum possible speedup on any number of processors. By the span law, the parallelism bounds the speedup: if <span class="texhtml"><i>p</i> &gt; <i>T</i><sub>1</sub> / <i>T<sub>∞</sub></i></span>, then:</li></ul>
<p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\frac {T_{1}}{T_{p}}}\leq {\frac {T_{1}}{T_{\infty }}}&lt;p}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>p</mi>
</mrow>
</msub>
</mfrac>
</mrow>
<mo>≤<!-- ≤ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">∞<!-- ∞ --></mi>
</mrow>
</msub>
</mfrac>
</mrow>
<mo>&lt;</mo>
<mi>p</mi>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\frac {T_{1}}{T_{p}}}\leq {\frac {T_{1}}{T_{\infty }}}&lt;p}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\frac {T_{1}}{T_{p}}}\leq {\frac {T_{1}}{T_{\infty }}}&lt;p}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/98c989727da6c5c20f340ce1e1267b9baf31d61d" style="vertical-align: -2.505ex; width:14.688ex; height:5.843ex;"/></span> .<sup class="reference" id="cite_ref-clrs_9-4">[9]</sup>
</p>
<ul><li>The <i>slackness</i> is <span class="texhtml"><i>T</i><sub>1</sub> / (<i>pT</i><sub>∞</sub>)</span>. A slackness less than one implies (by the span law) that perfect linear speedup is impossible on <span class="texhtml mvar" style="font-style:italic;">p</span> processors.<sup class="reference" id="cite_ref-clrs_9-5">[9]</sup></li></ul>
<h2><span class="mw-headline" id="Execution_on_a_limited_number_of_processors">Execution on a limited number of processors</span><span class="mw-editsection"></span></h2>
<p>Analysis of parallel algorithms is usually carried out under the assumption that an unbounded number of processors is available. This is unrealistic, but not a problem, since any computation that can run in parallel on <span class="texhtml mvar" style="font-style:italic;">N</span> processors can be executed on <span class="texhtml"><i>p</i> &lt; <i>N</i></span> processors by letting each processor execute multiple units of work. A result called <b>Brent's law</b> states that one can perform such a "simulation" in time <span class="texhtml mvar" style="font-style:italic;">T<sub>p</sub></span>, bounded by<sup class="reference" id="cite_ref-10">[10]</sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle T_{p}\leq T_{N}+{\frac {T_{1}-T_{N}}{p}},}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>p</mi>
</mrow>
</msub>
<mo>≤<!-- ≤ --></mo>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</msub>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<mrow>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mo>−<!-- − --></mo>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</msub>
</mrow>
<mi>p</mi>
</mfrac>
</mrow>
<mo>,</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle T_{p}\leq T_{N}+{\frac {T_{1}-T_{N}}{p}},}</annotation>
</semantics>
</math></span><img alt="T_{p}\leq T_{N}+{\frac  {T_{1}-T_{N}}{p}}," aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1994c6ddff5549b6ef85581b33a69ab50ad9e5dc" style="vertical-align: -2.338ex; width:21.189ex; height:5.676ex;"/></span></dd></dl>
<p>or, less precisely,<sup class="reference" id="cite_ref-casanova_6-5">[6]</sup>
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle T_{p}=O\left(T_{N}+{\frac {T_{1}}{p}}\right).}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>p</mi>
</mrow>
</msub>
<mo>=</mo>
<mi>O</mi>
<mrow>
<mo>(</mo>
<mrow>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</msub>
<mo>+</mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mi>p</mi>
</mfrac>
</mrow>
</mrow>
<mo>)</mo>
</mrow>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle T_{p}=O\left(T_{N}+{\frac {T_{1}}{p}}\right).}</annotation>
</semantics>
</math></span><img alt="T_{p}=O\left(T_{N}+{\frac  {T_{1}}{p}}\right)." aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/15b6adcc79c3affbc7dd1fd69cf37039e4665104" style="vertical-align: -2.505ex; width:21.268ex; height:6.176ex;"/></span></dd></dl>
<p>An alternative statement of the law bounds <span class="texhtml mvar" style="font-style:italic;">T<sub>p</sub></span> above and below by
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle {\frac {T_{1}}{p}}\leq T_{p}\leq {\frac {T_{1}}{p}}+T_{\infty }}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mi>p</mi>
</mfrac>
</mrow>
<mo>≤<!-- ≤ --></mo>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>p</mi>
</mrow>
</msub>
<mo>≤<!-- ≤ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mfrac>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>1</mn>
</mrow>
</msub>
<mi>p</mi>
</mfrac>
</mrow>
<mo>+</mo>
<msub>
<mi>T</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi mathvariant="normal">∞<!-- ∞ --></mi>
</mrow>
</msub>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle {\frac {T_{1}}{p}}\leq T_{p}\leq {\frac {T_{1}}{p}}+T_{\infty }}</annotation>
</semantics>
</math></span><img alt="{\displaystyle {\frac {T_{1}}{p}}\leq T_{p}\leq {\frac {T_{1}}{p}}+T_{\infty }}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/96e2bfb0f49aae6cfec33cb93472289ce8647910" style="vertical-align: -2.338ex; width:21.183ex; height:5.676ex;"/></span>.</dd></dl>
<p>showing that the span (depth) <span class="texhtml"><i>T</i><sub>∞</sub></span> and the work <span class="texhtml"><i>T</i><sub>1</sub></span> together provide reasonable bounds on the computation time.<sup class="reference" id="cite_ref-brent_2-1">[2]</sup>
</p>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>

<!-- 
NewPP limit report
Parsed by mw2268
Cached time: 20221220234529
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.281 seconds
Real time usage: 0.608 seconds
Preprocessor visited node count: 1581/1000000
Post‐expand include size: 45718/2097152 bytes
Template argument size: 1600/2097152 bytes
Highest expansion depth: 8/100
Expensive parser function count: 0/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 36602/5000000 bytes
Lua time usage: 0.150/10.000 seconds
Lua memory usage: 4315074/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  275.503      1 -total
 61.14%  168.447      1 Template:Reflist
 34.69%   95.575      3 Template:Cite_journal
 22.23%   61.252      1 Template:Parallel_Computing
 20.82%   57.349      1 Template:Navbox
 12.15%   33.476     15 Template:Math
 11.47%   31.606      6 Template:Cite_book
  4.30%   11.840      1 Template:Category-inline
  3.75%   10.324      1 Template:Icon
  3.24%    8.935      1 Template:Introduction_to_Algorithms
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:45209429-0!canonical and timestamp 20221220234529 and revision id 1070378063.
 -->
</div></body>
</html>