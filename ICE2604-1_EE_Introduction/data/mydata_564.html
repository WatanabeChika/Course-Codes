<!DOCTYPE html>
<html>
<head>
<title>linear_probing</title>
</head>
<body>
<div class="mw-parser-output"><img alt="This is a good article. Click here for more information." data-file-height="185" data-file-width="180" decoding="async" height="20" src="//upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/19px-Symbol_support_vote.svg.png" srcset="//upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/29px-Symbol_support_vote.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/39px-Symbol_support_vote.svg.png 2x" width="19"/></div><div class="mw-parser-output">
<p class="mw-empty-elt">
</p>

<p><b>Linear probing </b> is a scheme in computer programming for resolving collisions in hash tables, data structures for maintaining a collection of key–value pairs and looking up the value associated with a given key. It was invented in 1954 by Gene Amdahl, Elaine M. McGraw, and Arthur Samuel and first analyzed in 1963 by Donald Knuth.
</p><p>Along with quadratic probing and double hashing, linear probing is a form of open addressing. In these schemes, each cell of a hash table stores a single key–value pair. When the hash function causes a collision by mapping a new key to a cell of the hash table that is already occupied by another key, linear probing searches the table for the closest following free location and inserts the new key there. Lookups are performed in the same way, by searching the table sequentially starting at the position given by the hash function, until finding a cell with a matching key or an empty cell.
</p><p>As Thorup &amp; Zhang (2012) write, "Hash tables are the most commonly used nontrivial data structures, and the most popular implementation on standard hardware uses linear probing, which is both fast and simple."<sup class="reference" id="cite_ref-tz12_1-0">[1]</sup>
Linear probing can provide high performance because of its good locality of reference, but is more sensitive to the quality of its hash function than some other collision resolution schemes. It takes constant expected time per search, insertion, or deletion when implemented using a random hash function, a 5-independent hash function, or tabulation hashing. Good results can also be achieved in practice with other hash functions such as MurmurHash.<sup class="reference" id="cite_ref-richter15_2-0">[2]</sup>
</p>

<h2><span class="mw-headline" id="Operations">Operations</span><span class="mw-editsection"></span></h2>
<p>Linear probing is a component of open addressing schemes for using a hash table to solve the dictionary problem. In the dictionary problem, a data structure should maintain a collection of key–value pairs subject to operations that insert or delete pairs from the collection or that search for the value associated with a given key.
In open addressing solutions to this problem, the data structure is an array <span class="texhtml mvar" style="font-style:italic;">T</span> (the hash table) whose cells <span class="texhtml"><i>T</i>[<i>i</i>]</span> (when nonempty) each store a single key–value pair. A hash function is used to map each key into the cell of <span class="texhtml mvar" style="font-style:italic;">T</span> where that key should be stored, typically scrambling the keys so that keys with similar values are not placed near each other in the table. A hash collision occurs when the hash function maps a key into a cell that is already occupied by a different key. Linear probing is a strategy for resolving collisions, by placing the new key into the closest following empty cell.<sup class="reference" id="cite_ref-gt_3-0">[3]</sup><sup class="reference" id="cite_ref-morin_4-0">[4]</sup>
</p>
<h3><span class="mw-headline" id="Search">Search</span><span class="mw-editsection"></span></h3>
<p>To search for a given key <span class="texhtml mvar" style="font-style:italic;">x</span>, the cells of <span class="texhtml mvar" style="font-style:italic;">T</span> are examined, beginning with the cell at index <span class="texhtml"><i>h</i>(<i>x</i>)</span> (where <span class="texhtml mvar" style="font-style:italic;">h</span> is the hash function) and continuing to the adjacent cells <span class="texhtml"><i>h</i>(<i>x</i>) + 1</span>, <span class="texhtml"><i>h</i>(<i>x</i>) + 2</span>, ..., until finding either an empty cell or a cell whose stored key is <span class="texhtml mvar" style="font-style:italic;">x</span>.
If a cell containing the key is found, the search returns the value from that cell. Otherwise, if an empty cell is found, the key cannot be in the table, because it would have been placed in that cell in preference to any later cell that has not yet been searched. In this case, the search returns as its result that the key is not present in the dictionary.<sup class="reference" id="cite_ref-gt_3-1">[3]</sup><sup class="reference" id="cite_ref-morin_4-1">[4]</sup>
</p>
<h3><span class="mw-headline" id="Insertion">Insertion</span><span class="mw-editsection"></span></h3>
<p>To insert a key–value pair <span class="texhtml">(<i>x</i>,<i>v</i>)</span> into the table (possibly replacing any existing pair with the same key), the insertion algorithm follows the same sequence of cells that would be followed for a search, until finding either an empty cell or a cell whose stored key is <span class="texhtml mvar" style="font-style:italic;">x</span>.
The new key–value pair is then placed into that cell.<sup class="reference" id="cite_ref-gt_3-2">[3]</sup><sup class="reference" id="cite_ref-morin_4-2">[4]</sup>
</p><p>If the insertion would cause the load factor of the table (its fraction of occupied cells) to grow above some preset threshold, the whole table may be replaced by a new table, larger by a constant factor, with a new hash function, as in a dynamic array. Setting this threshold close to zero and using a high growth rate for the table size leads to faster hash table operations but greater memory usage than threshold values close to one and  low growth rates. A common choice would be to double the table size when the load factor would exceed 1/2, causing the load factor to stay between 1/4 and 1/2.<sup class="reference" id="cite_ref-5">[5]</sup>
</p>
<h3><span class="mw-headline" id="Deletion">Deletion</span><span class="mw-editsection"></span></h3>

<p>It is also possible to remove a key–value pair from the dictionary. However, it is not sufficient to do so by simply emptying its cell. This would affect searches for other keys that have a hash value earlier than the emptied cell, but that are stored in a position later than the emptied cell. The emptied cell would cause those searches to incorrectly report that the key is not present.
</p><p>Instead, when a cell <span class="texhtml mvar" style="font-style:italic;">i</span> is emptied, it is necessary to search forward through the following cells of the table until finding either another empty cell or a key that can be moved to cell <span class="texhtml mvar" style="font-style:italic;">i</span> (that is, a key whose hash value is equal to or earlier than <span class="texhtml mvar" style="font-style:italic;">i</span>). When an empty cell is found, then emptying cell <span class="texhtml mvar" style="font-style:italic;">i</span> is safe and the deletion process terminates. But, when the search finds a key that can be moved to cell <span class="texhtml mvar" style="font-style:italic;">i</span>, it performs this move. This has the effect of speeding up later searches for the moved key, but it also empties out another cell, later in the same block of occupied cells. The search for a movable key continues for the new emptied cell, in the same way, until it terminates by reaching a cell that was already empty. In this process of moving keys to earlier cells, each key is examined only once. Therefore, the time to complete the whole process is proportional to the length of the block of occupied cells containing the deleted key, matching the running time of the other hash table operations.<sup class="reference" id="cite_ref-gt_3-3">[3]</sup>
</p><p>Alternatively, it is possible to use a lazy deletion strategy in which a key–value pair is removed by replacing the value by a special flag value indicating a deleted key. However, these flag values will contribute to the load factor of the hash table. With this strategy, it may become necessary to clean the flag values out of the array and rehash all the remaining key–value pairs once too large a fraction of the array becomes occupied by deleted keys.<sup class="reference" id="cite_ref-gt_3-4">[3]</sup><sup class="reference" id="cite_ref-morin_4-3">[4]</sup>
</p>
<h2><span class="mw-headline" id="Properties">Properties</span><span class="mw-editsection"></span></h2>
<p>Linear probing provides good locality of reference, which causes it to require few uncached memory accesses per operation. Because of this, for low to moderate load factors, it can provide very high performance. However, compared to some other open addressing strategies, its performance degrades more quickly at high load factors because of primary clustering, a tendency for one collision to cause more nearby collisions.<sup class="reference" id="cite_ref-gt_3-5">[3]</sup> Additionally, achieving good performance with this method requires a higher-quality hash function than for some other collision resolution schemes.<sup class="reference" id="cite_ref-pt_6-0">[6]</sup> When used with low-quality hash functions that fail to eliminate nonuniformities in the input distribution, linear probing can be slower than other open-addressing strategies such as double hashing, which probes a sequence of cells whose separation is determined by a second hash function, or quadratic probing, where the size of each step varies depending on its position within the probe sequence.<sup class="reference" id="cite_ref-hl05_7-0">[7]</sup>
</p>
<h2><span class="mw-headline" id="Analysis">Analysis</span><span class="mw-editsection"></span></h2>
<p>Using linear probing, dictionary operations can be implemented in constant expected time. In other words, insert, remove and search operations can be implemented in O(1), as long as the load factor of the hash table is a constant strictly less than one.<sup class="reference" id="cite_ref-knuth_8-0">[8]</sup>
</p><p>In more detail, the time for any particular operation (a search, insertion, or deletion) is proportional to the length of the contiguous block of occupied cells at which the operation starts. If all starting cells are equally likely, in a hash table with <span class="texhtml mvar" style="font-style:italic;">N</span> cells, then a maximal block of <span class="texhtml mvar" style="font-style:italic;">k</span> occupied cells will have probability <span class="texhtml"><i>k</i>/<i>N</i></span> of containing the starting location of a search, and will take time <span class="texhtml"><i>O</i>(<i>k</i>)</span> whenever it is the starting location. Therefore, the expected time for an operation can be calculated as the product of these two terms, <span class="texhtml"><i>O</i>(<i>k</i><sup>2</sup>/<i>N</i>)</span>, summed over all of the maximal blocks of contiguous cells in the table. A similar sum of squared block lengths gives the expected time bound for a random hash function (rather than for a random starting location into a specific state of the hash table), by summing over all the blocks that could exist (rather than the ones that actually exist in a given state of the table), and multiplying the term for each potential block by the probability that the block is actually occupied. That is,
defining <span class="texhtml">Block(<i>i</i>,<i>k</i>)</span> to be the event that there is a maximal contiguous block of occupied cells of length <span class="texhtml mvar" style="font-style:italic;">k</span> beginning at index <span class="texhtml mvar" style="font-style:italic;">i</span>, the expected time per operation is
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle E[T]=O(1)+\sum _{i=1}^{N}\sum _{k=1}^{n}O(k^{2}/N)\operatorname {Pr} [\operatorname {Block} (i,k)].}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>E</mi>
<mo stretchy="false">[</mo>
<mi>T</mi>
<mo stretchy="false">]</mo>
<mo>=</mo>
<mi>O</mi>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>+</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>i</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>N</mi>
</mrow>
</munderover>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<mi>O</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>k</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mrow class="MJX-TeXAtom-ORD">
<mo>/</mo>
</mrow>
<mi>N</mi>
<mo stretchy="false">)</mo>
<mi>Pr</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<mi>Block</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">(</mo>
<mi>i</mi>
<mo>,</mo>
<mi>k</mi>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle E[T]=O(1)+\sum _{i=1}^{N}\sum _{k=1}^{n}O(k^{2}/N)\operatorname {Pr} [\operatorname {Block} (i,k)].}</annotation>
</semantics>
</math></span><img alt="{\displaystyle E[T]=O(1)+\sum _{i=1}^{N}\sum _{k=1}^{n}O(k^{2}/N)\operatorname {Pr} [\operatorname {Block} (i,k)].}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e8d627679f56340b4179de1a31e927cdc790d4cb" style="vertical-align: -3.005ex; width:47.342ex; height:7.343ex;"/></span></dd></dl>
<p>This formula can be simplified by replacing <span class="texhtml">Block(<i>i</i>,<i>k</i>)</span> by a simpler necessary condition <span class="texhtml">Full(<i>k</i>)</span>, the event that
at least <span class="texhtml mvar" style="font-style:italic;">k</span> elements have hash values that lie within a block of cells of length <span class="texhtml mvar" style="font-style:italic;">k</span>. After this replacement, the value within the sum no longer depends on <span class="texhtml mvar" style="font-style:italic;">i</span>, and the <span class="texhtml">1/<i>N</i></span> factor cancels the <span class="texhtml mvar" style="font-style:italic;">N</span> terms of the outer summation. These simplifications lead to the bound
</p>
<dl><dd><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle E[T]\leq O(1)+\sum _{k=1}^{n}O(k^{2})\operatorname {Pr} [\operatorname {Full} (k)].}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<mi>E</mi>
<mo stretchy="false">[</mo>
<mi>T</mi>
<mo stretchy="false">]</mo>
<mo>≤<!-- ≤ --></mo>
<mi>O</mi>
<mo stretchy="false">(</mo>
<mn>1</mn>
<mo stretchy="false">)</mo>
<mo>+</mo>
<munderover>
<mo>∑<!-- ∑ --></mo>
<mrow class="MJX-TeXAtom-ORD">
<mi>k</mi>
<mo>=</mo>
<mn>1</mn>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>n</mi>
</mrow>
</munderover>
<mi>O</mi>
<mo stretchy="false">(</mo>
<msup>
<mi>k</mi>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mi>Pr</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">[</mo>
<mi>Full</mi>
<mo>⁡<!-- ⁡ --></mo>
<mo stretchy="false">(</mo>
<mi>k</mi>
<mo stretchy="false">)</mo>
<mo stretchy="false">]</mo>
<mo>.</mo>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle E[T]\leq O(1)+\sum _{k=1}^{n}O(k^{2})\operatorname {Pr} [\operatorname {Full} (k)].}</annotation>
</semantics>
</math></span><img alt="{\displaystyle E[T]\leq O(1)+\sum _{k=1}^{n}O(k^{2})\operatorname {Pr} [\operatorname {Full} (k)].}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3e9c4905218ddf4e9f1b1d30edfb0b846fd14262" style="vertical-align: -3.005ex; width:36.926ex; height:6.843ex;"/></span></dd></dl>
<p>But by the multiplicative form of the Chernoff bound, when the load factor is bounded away from one, the probability that a block of length <span class="texhtml mvar" style="font-style:italic;">k</span> contains at least <span class="texhtml mvar" style="font-style:italic;">k</span> hashed values is exponentially small as a function of <span class="texhtml mvar" style="font-style:italic;">k</span>,
causing this sum to be bounded by a constant independent of <span class="texhtml mvar" style="font-style:italic;">n</span>.<sup class="reference" id="cite_ref-gt_3-6">[3]</sup> It is also possible to perform the same analysis using Stirling's approximation instead of the Chernoff bound to estimate the probability that a block contains exactly <span class="texhtml mvar" style="font-style:italic;">k</span> hashed values.<sup class="reference" id="cite_ref-morin_4-4">[4]</sup><sup class="reference" id="cite_ref-9">[9]</sup>
</p><p>In terms of the load factor <span class="texhtml mvar" style="font-style:italic;">α</span>, the expected time for a successful search is <span class="texhtml"><i>O</i>(1 + 1/(1 − <i>α</i>))</span>, and the expected time for an unsuccessful search (or the insertion of a new key) is <span class="texhtml"><i>O</i>(1 + 1/(1 − <i>α</i>)<sup>2</sup>)</span>.<sup class="reference" id="cite_ref-sedgewick_10-0">[10]</sup>
For constant load factors, with high probability, the longest probe sequence (among the probe sequences for all keys stored in the table) has logarithmic length.<sup class="reference" id="cite_ref-11">[11]</sup>
</p>
<h2><span class="mw-headline" id="Choice_of_hash_function">Choice of hash function</span><span class="mw-editsection"></span></h2>
<p>Because linear probing is especially sensitive to unevenly distributed hash values,<sup class="reference" id="cite_ref-hl05_7-1">[7]</sup> it is important to combine it with a high-quality hash function that does not produce such irregularities.
</p><p>The analysis above assumes that each key's hash is a random number independent of the hashes of all the other keys. This assumption is unrealistic for most applications of hashing.
However, random or pseudorandom hash values may be used when hashing objects by their identity rather than by their value. For instance, this is done using linear probing by the IdentityHashMap class of the Java collections framework.<sup class="reference" id="cite_ref-12">[12]</sup>
The hash value that this class associates with each object, its identityHashCode, is guaranteed to remain fixed for the lifetime of an object but is otherwise arbitrary.<sup class="reference" id="cite_ref-13">[13]</sup> Because the identityHashCode is constructed only once per object, and is not required to be related to the object's address or value, its construction may involve slower computations such as the call to a random or pseudorandom number generator. For instance, Java 8 uses an Xorshift pseudorandom number generator to construct these values.<sup class="reference" id="cite_ref-14">[14]</sup>
</p><p>For most applications of hashing, it is necessary to compute the hash function for each value every time that it is hashed, rather than once when its object is created. In such applications, random or pseudorandom numbers cannot be used as hash values, because then different objects with the same value would have different hashes. And cryptographic hash functions (which are designed to be computationally indistinguishable from truly random functions) are usually too slow to be used in hash tables.<sup class="reference" id="cite_ref-15">[15]</sup> Instead, other methods for constructing hash functions have been devised. These methods compute the hash function quickly, and can be proven to work well with linear probing. In particular, linear probing has been analyzed from the framework of <span class="texhtml mvar" style="font-style:italic;">k</span>-independent hashing, a class of hash functions that are initialized from a small random seed and that are equally likely to map any <span class="texhtml mvar" style="font-style:italic;">k</span>-tuple of distinct keys to any <span class="texhtml mvar" style="font-style:italic;">k</span>-tuple of indexes. The parameter <span class="texhtml mvar" style="font-style:italic;">k</span> can be thought of as a measure of hash function quality: the larger <span class="texhtml mvar" style="font-style:italic;">k</span> is, the more time it will take to compute the hash function but it will behave more similarly to completely random functions.
For linear probing, 5-independence is enough to guarantee constant expected time per operation,<sup class="reference" id="cite_ref-ppr09_16-0">[16]</sup>
while some 4-independent hash functions perform badly, taking up to logarithmic time per operation.<sup class="reference" id="cite_ref-pt_6-1">[6]</sup>
</p><p>Another method of constructing hash functions with both high quality and practical speed is tabulation hashing. In this method, the hash value for a key is computed by using each byte of the key as an index into a table of random numbers (with a different table for each byte position). The numbers from those table cells are then combined by a bitwise exclusive or operation. Hash functions constructed this way are only 3-independent. Nevertheless, linear probing using these hash functions takes constant expected time per operation.<sup class="reference" id="cite_ref-morin_4-5">[4]</sup><sup class="reference" id="cite_ref-pt11_17-0">[17]</sup> Both tabulation hashing and standard methods for generating 5-independent hash functions are limited to keys that have a fixed number of bits. To handle strings or other types of variable-length keys, it is possible to compose a simpler universal hashing technique that maps the keys to intermediate values and a higher quality (5-independent or tabulation) hash function that maps the intermediate values to hash table indices.<sup class="reference" id="cite_ref-tz12_1-1">[1]</sup><sup class="reference" id="cite_ref-18">[18]</sup>
</p><p>In an experimental comparison, Richter et al. found that the Multiply-Shift family of hash functions (defined as <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math alttext="{\displaystyle h_{z}(x)=(x\cdot z{\bmod {2}}^{w})\div 2^{w-d}}" xmlns="http://www.w3.org/1998/Math/MathML">
<semantics>
<mrow class="MJX-TeXAtom-ORD">
<mstyle displaystyle="true" scriptlevel="0">
<msub>
<mi>h</mi>
<mrow class="MJX-TeXAtom-ORD">
<mi>z</mi>
</mrow>
</msub>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo stretchy="false">)</mo>
<mo>=</mo>
<mo stretchy="false">(</mo>
<mi>x</mi>
<mo>⋅<!-- ⋅ --></mo>
<mi>z</mi>
<msup>
<mrow class="MJX-TeXAtom-ORD">
<mo lspace="thickmathspace" rspace="thickmathspace">mod</mo>
<mrow class="MJX-TeXAtom-ORD">
<mn>2</mn>
</mrow>
</mrow>
<mrow class="MJX-TeXAtom-ORD">
<mi>w</mi>
</mrow>
</msup>
<mo stretchy="false">)</mo>
<mo>÷<!-- ÷ --></mo>
<msup>
<mn>2</mn>
<mrow class="MJX-TeXAtom-ORD">
<mi>w</mi>
<mo>−<!-- − --></mo>
<mi>d</mi>
</mrow>
</msup>
</mstyle>
</mrow>
<annotation encoding="application/x-tex">{\displaystyle h_{z}(x)=(x\cdot z{\bmod {2}}^{w})\div 2^{w-d}}</annotation>
</semantics>
</math></span><img alt="{\displaystyle h_{z}(x)=(x\cdot z{\bmod {2}}^{w})\div 2^{w-d}}" aria-hidden="true" class="mwe-math-fallback-image-inline" src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2d0adb4dedea4b299e0951f70cdf6a20c95cea1c" style="vertical-align: -0.838ex; width:30.287ex; height:3.176ex;"/></span>) was "the fastest hash function when integrated with all hashing schemes, i.e., producing the highest throughputs and also of good quality" whereas tabulation hashing produced "the lowest throughput".<sup class="reference" id="cite_ref-richter15_2-1">[2]</sup>
They point out that each table look-up require several cycles, being more expensive than simple arithmetic operations. They also found MurmurHash to be superior than tabulation hashing: "By studying the results provided by Mult and Murmur, we think that the trade-off for by tabulation (...) is less attractive in practice".
</p>
<h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"></span></h2>
<p>The idea of an associative array that allows data to be accessed by its value rather than by its address dates back to the mid-1940s in the work of Konrad Zuse and Vannevar Bush,<sup class="reference" id="cite_ref-19">[19]</sup> but hash tables were not described until 1953, in an IBM memorandum by Hans Peter Luhn. Luhn used a different collision resolution method, chaining, rather than linear probing.<sup class="reference" id="cite_ref-20">[20]</sup>
</p><p>Knuth (1963) summarizes the early history of linear probing. It was the first open addressing method, and was originally synonymous with open addressing. According to Knuth, it was first used by Gene Amdahl, Elaine M. McGraw (née Boehme), and Arthur Samuel in 1954, in an assembler program for the IBM 701 computer.<sup class="reference" id="cite_ref-knuth_8-1">[8]</sup> The first published description of linear probing is by Peterson (1957),<sup class="reference" id="cite_ref-knuth_8-2">[8]</sup> who also credits Samuel, Amdahl, and Boehme but adds that "the system is so natural, that it very likely may have been conceived independently by others either before or since that time".<sup class="reference" id="cite_ref-21">[21]</sup> Another early publication of this method was by Soviet researcher Andrey Ershov, in 1958.<sup class="reference" id="cite_ref-22">[22]</sup>
</p><p>The first theoretical analysis of linear probing, showing that it takes constant expected time per operation with random hash functions, was given by Knuth.<sup class="reference" id="cite_ref-knuth_8-3">[8]</sup> Sedgewick calls Knuth's work "a landmark in the analysis of algorithms".<sup class="reference" id="cite_ref-sedgewick_10-1">[10]</sup> Significant later developments include a more detailed analysis of the probability distribution of the running time,<sup class="reference" id="cite_ref-23">[23]</sup><sup class="reference" id="cite_ref-24">[24]</sup> and the proof that linear probing runs in constant time per operation with practically usable hash functions rather than with the idealized random functions assumed by earlier analysis.<sup class="reference" id="cite_ref-ppr09_16-1">[16]</sup><sup class="reference" id="cite_ref-pt11_17-1">[17]</sup>
</p>
<h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"></span></h2>
<style data-mw-deduplicate="TemplateStyles:r1011085734">.mw-parser-output .reflist{font-size:90%;margin-bottom:0.5em;list-style-type:decimal}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style>
<!-- 
NewPP limit report
Parsed by mw2415
Cached time: 20221223234048
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.312 seconds
Real time usage: 0.423 seconds
Preprocessor visited node count: 2755/1000000
Post‐expand include size: 51924/2097152 bytes
Template argument size: 2082/2097152 bytes
Highest expansion depth: 10/100
Expensive parser function count: 0/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 78673/5000000 bytes
Lua time usage: 0.179/10.000 seconds
Lua memory usage: 7547547/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  334.064      1 -total
 54.94%  183.548      1 Template:Reflist
 45.94%  153.475     24 Template:Citation
 15.97%   53.347      1 Template:Short_description
 10.91%   36.447     18 Template:Main_other
 10.70%   35.756      2 Template:Harvtxt
  7.88%   26.332      2 Template:Pagetype
  5.93%   19.799      1 Template:Good_article
  5.42%   18.105      1 Template:Top_icon
  4.36%   14.551      1 Template:SDcat
-->
<!-- Saved in parser cache with key enwiki:pcache:idhash:1852304-0!canonical and timestamp 20221223234048 and revision id 1093122630.
 -->
</div></body>
</html>